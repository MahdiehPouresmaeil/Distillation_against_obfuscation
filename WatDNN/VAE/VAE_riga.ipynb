{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-17T09:12:01.452544057Z",
     "start_time": "2026-02-17T09:12:00.790917519Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import psutil\n",
    "\n",
    "\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, latent_dim=200):\n",
    "        super(VAE, self).__init__()\n",
    "\n",
    "        # Encoder: 4 Conv2d layers with stride=2, kernel=4, padding=1\n",
    "        # Input: (3, 64, 64) -> (32, 32, 32) -> (64, 16, 16) -> (128, 8, 8) -> (256, 4, 4)\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=4, stride=2, padding=1),    # 0\n",
    "            nn.ReLU(),                                                # 1\n",
    "            nn.Conv2d(32, 64, kernel_size=4, stride=2, padding=1),   # 2\n",
    "            nn.ReLU(),                                                # 3\n",
    "            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1),  # 4\n",
    "            nn.ReLU(),                                                # 5\n",
    "            nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1), # 6\n",
    "            nn.ReLU(),                                                # 7\n",
    "        )\n",
    "\n",
    "        # 256 * 4 * 4 = 4096\n",
    "        self.fc_mu = nn.Linear(4096, latent_dim)\n",
    "        self.fc_logvar = nn.Linear(4096, latent_dim)\n",
    "\n",
    "        # Decoder input\n",
    "        self.decoder_input = nn.Linear(latent_dim, 4096)\n",
    "\n",
    "        # Decoder: 4 ConvTranspose2d layers\n",
    "        # (256, 4, 4) -> (128, 8, 8) -> (64, 16, 16) -> (32, 32, 32) -> (3, 64, 64)\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1),  # 0\n",
    "            nn.ReLU(),                                                          # 1\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),   # 2\n",
    "            nn.ReLU(),                                                          # 3\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=4, stride=2, padding=1),    # 4\n",
    "            nn.ReLU(),                                                          # 5\n",
    "            nn.ConvTranspose2d(32, 3, kernel_size=4, stride=2, padding=1),     # 6\n",
    "            nn.Sigmoid(),                                                       # 7\n",
    "        )\n",
    "\n",
    "    def encode(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = x.view(x.size(0), -1)  # Flatten to (batch, 4096)\n",
    "        mu = self.fc_mu(x)\n",
    "        logvar = self.fc_logvar(x)\n",
    "        return mu, logvar\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def decode(self, z):\n",
    "        x = self.decoder_input(z)\n",
    "        x = x.view(x.size(0), 256, 4, 4)  # Reshape to (batch, 256, 4, 4)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        recon = self.decode(z)\n",
    "        return recon, mu, logvar\n"
   ],
   "id": "3bfd98f96e86a995",
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-17T09:12:02.296400740Z",
     "start_time": "2026-02-17T09:12:01.453488216Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from diffusers import DDPMPipeline, DDPMScheduler, UNet2DModel\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "from torch.optim import AdamW\n",
    "\n",
    "# --- Riga Extractor Network ---\n",
    "\n",
    "class RigaExtractor(nn.Module):\n",
    "    \"\"\"Extractor network that projects weights to watermark space.\"\"\"\n",
    "    def __init__(self, weight_size, watermark_len):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(weight_size, 100, bias=False)\n",
    "        self.fc2 = nn.Linear(100, watermark_len, bias=False)\n",
    "        self.sig = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.sig(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.sig(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "# --- Riga Detector Network ---\n",
    "\n",
    "class RigaDetector(nn.Module):\n",
    "    \"\"\"Detector network that distinguishes watermarked from non-watermarked weights.\"\"\"\n",
    "    def __init__(self, weight_size):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(weight_size, 100, bias=False)\n",
    "        self.fc2 = nn.Linear(100, 1, bias=False)\n",
    "        self.sig = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.sig(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.sig(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "# --- Classe Principale Riga DDPM ---\n",
    "\n",
    "class RigaVAE:\n",
    "    def __init__(self, model, device=\"cuda\"):\n",
    "        self.device = device\n",
    "        self.model = model\n",
    "\n",
    "\n",
    "        # Configuration par defaut\n",
    "        self.config = {\n",
    "            \"layer_name\": \"decoder.6.weight\",  # Couche cible\n",
    "            \"watermark_len\": 16,\n",
    "            \"lr\": 1e-4,\n",
    "            \"lr_det\": 1e-3,        # Learning rate for detector\n",
    "            \"lambda_1\": 1.0,       # Watermark loss weight\n",
    "            \"lambda_2\": 1.0,       # Adversarial loss weight\n",
    "            \"epochs\": 10,\n",
    "            \"clip_value\": 0.01,\n",
    "            \"beta_kl\":1.0# Weight clipping for detector (WGAN-style)\n",
    "        }\n",
    "\n",
    "        self.saved_keys = {}\n",
    "\n",
    "    def _get_target_weights(self, model):\n",
    "        \"\"\"Recupere le tenseur des poids de la couche cible.\"\"\"\n",
    "        for name, param in model.named_parameters():\n",
    "            if name == self.config[\"layer_name\"]:\n",
    "                return param\n",
    "        raise ValueError(f\"Parametre {self.config['layer_name']} introuvable.\")\n",
    "\n",
    "    def embed(self, dataloader):\n",
    "        \"\"\"\n",
    "        Incorpore la marque Riga pendant le finetuning.\n",
    "        Utilise un entrainement adversarial avec un detecteur.\n",
    "        \"\"\"\n",
    "        print(f\"--- Demarrage Embedding Riga ({self.config['layer_name']}) ---\")\n",
    "\n",
    "        watermarked_model = self.model\n",
    "        watermarked_model.train()\n",
    "\n",
    "        # 1. Get initial weights\n",
    "        target_weights = self._get_target_weights(watermarked_model)\n",
    "        with torch.no_grad():\n",
    "            init_w = torch.flatten(target_weights.mean(dim=0)).clone()\n",
    "            weight_size = len(init_w)\n",
    "\n",
    "        print(f\"Dimension vecteur poids : {weight_size} | Watermark : {self.config['watermark_len']} bits\")\n",
    "\n",
    "        # 2. Generate watermarks\n",
    "        watermark_target = torch.randint(0, 2, (self.config[\"watermark_len\"],)).float().to(self.device)\n",
    "        watermark_random = torch.randint(0, 2, (self.config[\"watermark_len\"],)).float().to(self.device)\n",
    "\n",
    "        # 3. Initialize networks\n",
    "        extractor = RigaExtractor(weight_size, self.config[\"watermark_len\"]).to(self.device)\n",
    "        detector = RigaDetector(weight_size).to(self.device)\n",
    "\n",
    "        # 4. Optimizers\n",
    "        optimizer = torch.optim.AdamW([\n",
    "            {'params': watermarked_model.parameters(), 'lr': self.config[\"lr\"]},\n",
    "            {'params': extractor.parameters(), 'lr': self.config[\"lr\"], 'betas': (0.5, 0.999)}\n",
    "        ])\n",
    "        optimizer_det = torch.optim.Adam(\n",
    "            detector.parameters(),\n",
    "            lr=self.config[\"lr_det\"],\n",
    "            betas=(0.5, 0.999)\n",
    "        )\n",
    "\n",
    "        mse_loss = nn.MSELoss()\n",
    "        bce_loss = nn.BCELoss()\n",
    "\n",
    "        # 5. Training loop\n",
    "        for epoch in range(self.config[\"epochs\"]):\n",
    "            pbar = tqdm(dataloader)\n",
    "            for clean_images, _ in pbar:\n",
    "                clean_images = clean_images.to(self.device)\n",
    "\n",
    "\n",
    "                # Get current weights\n",
    "                current_weights = self._get_target_weights(watermarked_model)\n",
    "                w = torch.flatten(current_weights.mean(dim=0))\n",
    "\n",
    "                # Sort weights for detector (as in original Riga)\n",
    "                w_sorted = torch.sort(w.detach())[0]\n",
    "                init_w_sorted = torch.sort(init_w.detach())[0]\n",
    "\n",
    "                # === A. Train Detector ===\n",
    "                optimizer_det.zero_grad()\n",
    "\n",
    "                # Detector should output 1 for non-watermarked, 0 for watermarked\n",
    "                out_det_wat = detector(w_sorted)\n",
    "                out_det_non = detector(init_w_sorted)\n",
    "\n",
    "                loss_det_non = bce_loss(out_det_non, torch.ones(1).to(self.device))\n",
    "                loss_det_wat = bce_loss(out_det_wat, torch.zeros(1).to(self.device))\n",
    "                loss_det = loss_det_non + loss_det_wat\n",
    "\n",
    "                loss_det.backward(retain_graph=True)\n",
    "                optimizer_det.step()\n",
    "\n",
    "                # Clip detector weights (WGAN-style)\n",
    "                with torch.no_grad():\n",
    "                    for param in detector.parameters():\n",
    "                        param.clamp_(-self.config[\"clip_value\"], self.config[\"clip_value\"])\n",
    "\n",
    "                # === B. Train VAE + Extractor ===\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "\n",
    "                recon, mu, logvar = watermarked_model(clean_images)\n",
    "\n",
    "                # Reconstruction loss\n",
    "                l_recon = F.mse_loss(recon, clean_images)\n",
    "\n",
    "                # KL divergence\n",
    "                l_kl = -0.5 * torch.mean(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "\n",
    "                # VAE total task loss\n",
    "                l_main = l_recon + self.config[\"beta_kl\"] * l_kl\n",
    "\n",
    "\n",
    "                # Watermark extraction loss\n",
    "                w_current = torch.flatten(self._get_target_weights(watermarked_model).mean(dim=0))\n",
    "                out_watermark = extractor(w_current)\n",
    "                init_out_watermark = extractor(init_w.detach())\n",
    "\n",
    "                loss_ext_wat = bce_loss(out_watermark, watermark_target)\n",
    "                loss_ext_init = bce_loss(init_out_watermark, watermark_random)\n",
    "\n",
    "                # Adversarial loss (fool detector - make it think watermarked is non-watermarked)\n",
    "                w_sorted_current = torch.sort(w_current.detach())[0]\n",
    "                out_det_current = detector(w_sorted_current)\n",
    "                loss_adv = bce_loss(out_det_current, torch.ones(1).to(self.device))\n",
    "\n",
    "                # Total loss\n",
    "                l_total = (l_main +\n",
    "                          self.config[\"lambda_1\"] * (loss_ext_wat + loss_ext_init) -\n",
    "                          self.config[\"lambda_2\"] * loss_adv)\n",
    "\n",
    "                l_total.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                # Metrics\n",
    "                ber = self._compute_ber(out_watermark, watermark_target)\n",
    "                pbar.set_description(\n",
    "                    f\"Epoch {epoch+1} | L_Main: {l_main:.3f} | L_Ext: {loss_ext_wat:.3f} | \"\n",
    "                    f\"L_Det: {loss_det:.3f} | BER: {ber:.2f}\"\n",
    "                )\n",
    "\n",
    "                # if ber == 0.0 and loss_ext_wat.item() < 0.01:\n",
    "                #     print(\"Convergence atteinte !\")\n",
    "                #     break\n",
    "            # if ber == 0.0:\n",
    "            #     break\n",
    "\n",
    "        # Save keys\n",
    "        self.saved_keys = {\n",
    "            \"watermark_target\": watermark_target,\n",
    "            \"watermarked_model\": watermarked_model,\n",
    "            \"extractor\": extractor,\n",
    "            \"detector\": detector,\n",
    "            \"init_w\": init_w,\n",
    "        }\n",
    "        torch.save(self.saved_keys, \"Riga_VAE_model_checkpoint.pt\")\n",
    "        return watermarked_model\n",
    "\n",
    "    def extract(self, model=None):\n",
    "        \"\"\"\n",
    "        Extrait la marque d'un modele suspect via le reseau extracteur.\n",
    "        \"\"\"\n",
    "        if model is None:\n",
    "            print('suspected is none')\n",
    "            model = self.saved_keys[\"watermarked_model\"]\n",
    "\n",
    "        extractor = self.saved_keys[\"extractor\"]\n",
    "        watermark_target = self.saved_keys[\"watermark_target\"]\n",
    "\n",
    "        extractor.eval()\n",
    "\n",
    "        # Get weights\n",
    "        try:\n",
    "            target_weights = self._get_target_weights(model)\n",
    "        except ValueError:\n",
    "            print(\"Couche cible introuvable dans le modele suspect.\")\n",
    "            return 1.0, None\n",
    "\n",
    "        # Extract watermark\n",
    "        with torch.no_grad():\n",
    "            w = torch.flatten(target_weights.mean(dim=0))\n",
    "            pred_wm = extractor(w)\n",
    "            ber = self._compute_ber(pred_wm, watermark_target)\n",
    "\n",
    "        print(f\"BER Extrait : {ber:.2f}\")\n",
    "        return ber, pred_wm\n",
    "\n",
    "    def detect(self, model=None):\n",
    "        \"\"\"\n",
    "        Detecte si un modele est watermarke via le reseau detecteur.\n",
    "        Returns: detection score (0 = watermarked, 1 = non-watermarked)\n",
    "        \"\"\"\n",
    "        if model is None:\n",
    "            print(\"suspected is none\")\n",
    "            model = self.saved_keys[\"watermarked_model\"]\n",
    "\n",
    "        detector = self.saved_keys[\"detector\"]\n",
    "        detector.eval()\n",
    "\n",
    "        try:\n",
    "            target_weights = self._get_target_weights(model)\n",
    "            print(\"ok\")\n",
    "        except ValueError:\n",
    "            print(\"error\")\n",
    "            return 0.5\n",
    "\n",
    "        with torch.no_grad():\n",
    "            w = torch.flatten(target_weights.mean(dim=0))\n",
    "            w_sorted = torch.sort(w)[0]\n",
    "            detection_score = detector(w_sorted).item()\n",
    "\n",
    "        print(f\"Detection score: {detection_score:.4f} (0=watermarked, 1=non-watermarked)\")\n",
    "        return detection_score\n",
    "\n",
    "    @staticmethod\n",
    "    def _compute_ber(pred, target):\n",
    "        return ((pred > 0.5).float() != target).float().mean().item()\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/latim/PycharmProjects/WatDNN/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-17T09:12:02.511706825Z",
     "start_time": "2026-02-17T09:12:02.357646722Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import gc\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# Load from Hugging Face (no Google Drive issues)\n",
    "print(\"Loading dataset...\")\n",
    "\n",
    "\n",
    "from datasets import load_from_disk\n",
    "hf_dataset = load_from_disk(\"celeba_local\")\n",
    "# os.makedirs(\"./celeba_images/all\", exist_ok=True)\n",
    "# for i, item in enumerate(hf_dataset):\n",
    "#     item['image'].save(f\"./celeba_images/all/{i:06d}.jpg\")\n",
    "# del hf_dataset\n",
    "\n",
    "\n",
    "class CelebAWrapper(torch.utils.data.Dataset):\n",
    "    def __init__(self, hf_dataset, transform):\n",
    "        self.dataset = hf_dataset\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.dataset[idx]['image']\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, 0\n",
    "\n",
    "dataset = CelebAWrapper(hf_dataset, transform)\n",
    "# del hf_dataset\n",
    "# gc.collect()\n",
    "# dataset = datasets.ImageFolder(\"./celeba_images\", transform=transform)\n",
    "print(\"Dataset loaded!\")\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "print(\"loader loaded!\")\n"
   ],
   "id": "1c737ebbf88195ad",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Dataset loaded!\n",
      "loader loaded!\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "embedding_cell",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-17T09:38:28.621645026Z",
     "start_time": "2026-02-17T09:12:02.512608658Z"
    }
   },
   "source": [
    "# --- EXEMPLE D'EXECUTION ---\n",
    "\n",
    "# 1. Setup Data\n",
    "latent_dim = 200\n",
    "\n",
    "# Initialize the model\n",
    "model = VAE(latent_dim=latent_dim)\n",
    "\n",
    "# Load the trained weights\n",
    "model_path = \"./vae_celeba_latent_200_epochs_10_batch_64_subset_80000.pth\"\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.to(device)\n",
    "\n",
    "# 2. Embedding Riga\n",
    "riga_defense = RigaVAE(model)\n",
    "watermarked_model = riga_defense.embed(dataloader)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Demarrage Embedding Riga (decoder.6.weight) ---\n",
      "Dimension vecteur poids : 48 | Watermark : 16 bits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 | L_Main: 0.329 | L_Ext: 0.008 | L_Det: 1.378 | BER: 0.00: 100%|██████████| 3166/3166 [01:30<00:00, 34.90it/s]\n",
      "Epoch 2 | L_Main: 0.336 | L_Ext: 0.001 | L_Det: 1.376 | BER: 0.00: 100%|██████████| 3166/3166 [02:06<00:00, 25.10it/s]\n",
      "Epoch 3 | L_Main: 0.309 | L_Ext: 0.000 | L_Det: 1.375 | BER: 0.00: 100%|██████████| 3166/3166 [03:26<00:00, 15.35it/s]\n",
      "Epoch 4 | L_Main: 0.314 | L_Ext: 0.000 | L_Det: 1.374 | BER: 0.00: 100%|██████████| 3166/3166 [03:52<00:00, 13.60it/s]\n",
      "Epoch 5 | L_Main: 0.299 | L_Ext: 0.000 | L_Det: 1.374 | BER: 0.00: 100%|██████████| 3166/3166 [04:52<00:00, 10.81it/s]\n",
      "Epoch 6 | L_Main: 0.280 | L_Ext: 0.000 | L_Det: 1.374 | BER: 0.00: 100%|██████████| 3166/3166 [01:26<00:00, 36.42it/s]\n",
      "Epoch 7 | L_Main: 0.294 | L_Ext: 0.000 | L_Det: 1.373 | BER: 0.00: 100%|██████████| 3166/3166 [01:37<00:00, 32.55it/s]\n",
      "Epoch 8 | L_Main: 0.355 | L_Ext: 0.000 | L_Det: 1.373 | BER: 0.00: 100%|██████████| 3166/3166 [02:15<00:00, 23.34it/s]\n",
      "Epoch 9 | L_Main: 0.289 | L_Ext: 0.000 | L_Det: 1.373 | BER: 0.00: 100%|██████████| 3166/3166 [02:39<00:00, 19.88it/s]\n",
      "Epoch 10 | L_Main: 0.325 | L_Ext: 0.000 | L_Det: 1.373 | BER: 0.00: 100%|██████████| 3166/3166 [02:37<00:00, 20.05it/s]\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "extraction_cell",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-17T09:38:28.744328634Z",
     "start_time": "2026-02-17T09:38:28.645541657Z"
    }
   },
   "source": [
    "# 3. Extraction (Test immediat)\n",
    "ber, _ = riga_defense.extract(watermarked_model)\n",
    "print(f\"\\nResultat final - BER: {ber:.2f}\")\n",
    "\n",
    "# 4. Detection\n",
    "print(\"\\n--- Detection Test ---\")\n",
    "print(\"Watermarked model:\")\n",
    "riga_defense.detect(watermarked_model)\n",
    "\n",
    "# Test with fresh model\n",
    "print(\"\\nFresh (non-watermarked) model:\")\n",
    "fresh_model = VAE(latent_dim=latent_dim)\n",
    "fresh_model.load_state_dict(torch.load(model_path))\n",
    "fresh_model.to(device)\n",
    "\n",
    "riga_defense.detect(fresh_model)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait : 0.00\n",
      "\n",
      "Resultat final - BER: 0.00\n",
      "\n",
      "--- Detection Test ---\n",
      "Watermarked model:\n",
      "ok\n",
      "Detection score: 0.4821 (0=watermarked, 1=non-watermarked)\n",
      "\n",
      "Fresh (non-watermarked) model:\n",
      "ok\n",
      "Detection score: 0.4891 (0=watermarked, 1=non-watermarked)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.48905032873153687"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "distillation_attack_cell",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-17T09:51:08.241229608Z",
     "start_time": "2026-02-17T09:51:08.230485487Z"
    }
   },
   "source": [
    "# --- Fonction de Distillation (Attaque) ---\n",
    "\n",
    "def run_distillation_attack_riga(riga_obj, dataloader, epochs=5, lr=1e-4):\n",
    "    \"\"\"\n",
    "    Tente de transferer la fonctionnalite du modele Riga vers un modele vierge.\n",
    "    Verifie si la marque et la detection survivent.\n",
    "    \"\"\"\n",
    "    device = riga_obj.device\n",
    "    checkpoint = torch.load(\"Riga_VAE_model_checkpoint.pt\", weights_only=False)\n",
    "    # 1. Teacher (Gele)\n",
    "    teacher = checkpoint[\"watermarked_model\"]\n",
    "    teacher.eval()\n",
    "    for p in teacher.parameters():\n",
    "        p.requires_grad = False\n",
    "\n",
    "    # 2. Student (Vierge - Meme architecture)\n",
    "    print(\"\\n--- Initialisation du Student ---\")\n",
    "    student=VAE(latent_dim=latent_dim)\n",
    "    student.load_state_dict(torch.load(model_path))\n",
    "    student.to(device)\n",
    "    student.train()\n",
    "\n",
    "    teacher_ber, _ = riga_obj.extract(teacher)\n",
    "    student_ber, _ = riga_obj.extract(student)\n",
    "    print(f\"[Check] BER Teacher: {teacher_ber:.2f}\")\n",
    "    print(f\"[Check] BER Student (Avant): {student_ber:.2f}\")\n",
    "\n",
    "    print(\"\\n[Check] Detection scores:\")\n",
    "    print(\"Teacher:\", end=\" \")\n",
    "    riga_obj.detect(teacher)\n",
    "    print(\"Student (before):\", end=\" \")\n",
    "    riga_obj.detect(student)\n",
    "\n",
    "    optimizer = AdamW(student.parameters(), lr=lr)\n",
    "\n",
    "    history = {\"loss\": [], \"ber\": [], \"detection\": []}\n",
    "\n",
    "    print(f\"\\n--- Distillation Riga ({epochs} epochs) ---\")\n",
    "    a=0\n",
    "    for epoch in range(epochs):\n",
    "        pbar = tqdm(dataloader, desc=f\"Epoch {epoch+1}\")\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for clean_images, _ in pbar:\n",
    "            clean_images = clean_images.to(device)\n",
    "\n",
    "\n",
    "            with torch.no_grad():\n",
    "                target_pred,_,_ = teacher(clean_images)\n",
    "\n",
    "            student_pred,_ ,_ = student(clean_images)\n",
    "\n",
    "            loss = F.mse_loss(student_pred, target_pred)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            pbar.set_postfix(Loss=loss.item())\n",
    "\n",
    "        # Check metrics\n",
    "        current_ber, pred_wm = riga_obj.extract(student)\n",
    "        detection_score = riga_obj.detect(student)\n",
    "\n",
    "        history[\"ber\"].append(current_ber)\n",
    "        history[\"loss\"].append(running_loss / len(dataloader))\n",
    "        history[\"detection\"].append(detection_score)\n",
    "\n",
    "        err_wat = nn.BCELoss()(pred_wm, checkpoint[\"watermark_target\"]).item() if pred_wm is not None else float('nan')\n",
    "        print(f\"Fin Epoch {epoch+1} | Loss: {history['loss'][-1]:.4f} | BER: {current_ber:.2f} | Detection: {detection_score:.4f}, err_wat: {nn.BCELoss()(pred_wm, checkpoint[\"watermark_target\"]).item()}\")\n",
    "        if current_ber==0.0 and a>=1:\n",
    "            print(\"✅ Marque récupérée avec succès par distillation !\")\n",
    "            break\n",
    "        elif current_ber==0.0 and a<1 :\n",
    "            a+=1\n",
    "        else:\n",
    "            a=0\n",
    "\n",
    "    return student, history\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "id": "run_attack_cell",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-17T10:59:52.621553442Z",
     "start_time": "2026-02-17T09:51:08.868570748Z"
    }
   },
   "source": [
    "# 5. Attaque par Distillation\n",
    "student_res, stats = run_distillation_attack_riga(riga_defense, dataloader, epochs=100)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Initialisation du Student ---\n",
      "BER Extrait : 0.00\n",
      "BER Extrait : 0.44\n",
      "[Check] BER Teacher: 0.00\n",
      "[Check] BER Student (Avant): 0.44\n",
      "\n",
      "[Check] Detection scores:\n",
      "Teacher: ok\n",
      "Detection score: 0.4821 (0=watermarked, 1=non-watermarked)\n",
      "Student (before): ok\n",
      "Detection score: 0.4891 (0=watermarked, 1=non-watermarked)\n",
      "\n",
      "--- Distillation Riga (100 epochs) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 3166/3166 [01:35<00:00, 33.29it/s, Loss=0.00805]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait : 0.44\n",
      "ok\n",
      "Detection score: 0.4890 (0=watermarked, 1=non-watermarked)\n",
      "Fin Epoch 1 | Loss: 0.0082 | BER: 0.44 | Detection: 0.4890, err_wat: 6.804908752441406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 3166/3166 [01:36<00:00, 32.73it/s, Loss=0.00512]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait : 0.44\n",
      "ok\n",
      "Detection score: 0.4889 (0=watermarked, 1=non-watermarked)\n",
      "Fin Epoch 2 | Loss: 0.0070 | BER: 0.44 | Detection: 0.4889, err_wat: 6.696590423583984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 3166/3166 [01:38<00:00, 32.26it/s, Loss=0.00715]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait : 0.44\n",
      "ok\n",
      "Detection score: 0.4889 (0=watermarked, 1=non-watermarked)\n",
      "Fin Epoch 3 | Loss: 0.0069 | BER: 0.44 | Detection: 0.4889, err_wat: 6.629148960113525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 3166/3166 [01:38<00:00, 32.13it/s, Loss=0.00762]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait : 0.44\n",
      "ok\n",
      "Detection score: 0.4889 (0=watermarked, 1=non-watermarked)\n",
      "Fin Epoch 4 | Loss: 0.0069 | BER: 0.44 | Detection: 0.4889, err_wat: 6.610177993774414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 3166/3166 [01:38<00:00, 32.30it/s, Loss=0.00679]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait : 0.44\n",
      "ok\n",
      "Detection score: 0.4889 (0=watermarked, 1=non-watermarked)\n",
      "Fin Epoch 5 | Loss: 0.0069 | BER: 0.44 | Detection: 0.4889, err_wat: 6.579821586608887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 3166/3166 [01:37<00:00, 32.35it/s, Loss=0.0063] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait : 0.44\n",
      "ok\n",
      "Detection score: 0.4889 (0=watermarked, 1=non-watermarked)\n",
      "Fin Epoch 6 | Loss: 0.0069 | BER: 0.44 | Detection: 0.4889, err_wat: 6.5444183349609375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 3166/3166 [01:27<00:00, 36.03it/s, Loss=0.006]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait : 0.44\n",
      "ok\n",
      "Detection score: 0.4889 (0=watermarked, 1=non-watermarked)\n",
      "Fin Epoch 7 | Loss: 0.0068 | BER: 0.44 | Detection: 0.4889, err_wat: 6.542362213134766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 3166/3166 [01:24<00:00, 37.34it/s, Loss=0.00669]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait : 0.44\n",
      "ok\n",
      "Detection score: 0.4889 (0=watermarked, 1=non-watermarked)\n",
      "Fin Epoch 8 | Loss: 0.0068 | BER: 0.44 | Detection: 0.4889, err_wat: 6.514590263366699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 3166/3166 [01:24<00:00, 37.34it/s, Loss=0.00618]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait : 0.44\n",
      "ok\n",
      "Detection score: 0.4889 (0=watermarked, 1=non-watermarked)\n",
      "Fin Epoch 9 | Loss: 0.0068 | BER: 0.44 | Detection: 0.4889, err_wat: 6.478653907775879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 3166/3166 [01:25<00:00, 37.24it/s, Loss=0.00548]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait : 0.44\n",
      "ok\n",
      "Detection score: 0.4889 (0=watermarked, 1=non-watermarked)\n",
      "Fin Epoch 10 | Loss: 0.0068 | BER: 0.44 | Detection: 0.4889, err_wat: 6.499850273132324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 3166/3166 [01:25<00:00, 37.07it/s, Loss=0.00655]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait : 0.44\n",
      "ok\n",
      "Detection score: 0.4889 (0=watermarked, 1=non-watermarked)\n",
      "Fin Epoch 11 | Loss: 0.0068 | BER: 0.44 | Detection: 0.4889, err_wat: 6.504090309143066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 3166/3166 [01:25<00:00, 37.08it/s, Loss=0.00514]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait : 0.44\n",
      "ok\n",
      "Detection score: 0.4889 (0=watermarked, 1=non-watermarked)\n",
      "Fin Epoch 12 | Loss: 0.0068 | BER: 0.44 | Detection: 0.4889, err_wat: 6.463783264160156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 3166/3166 [01:24<00:00, 37.33it/s, Loss=0.00482]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait : 0.44\n",
      "ok\n",
      "Detection score: 0.4889 (0=watermarked, 1=non-watermarked)\n",
      "Fin Epoch 13 | Loss: 0.0068 | BER: 0.44 | Detection: 0.4889, err_wat: 6.446440696716309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 3166/3166 [01:24<00:00, 37.56it/s, Loss=0.00611]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait : 0.44\n",
      "ok\n",
      "Detection score: 0.4889 (0=watermarked, 1=non-watermarked)\n",
      "Fin Epoch 14 | Loss: 0.0068 | BER: 0.44 | Detection: 0.4889, err_wat: 6.437909126281738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 3166/3166 [01:24<00:00, 37.53it/s, Loss=0.00741]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait : 0.44\n",
      "ok\n",
      "Detection score: 0.4889 (0=watermarked, 1=non-watermarked)\n",
      "Fin Epoch 15 | Loss: 0.0068 | BER: 0.44 | Detection: 0.4889, err_wat: 6.441375732421875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████| 3166/3166 [01:24<00:00, 37.53it/s, Loss=0.00647]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait : 0.44\n",
      "ok\n",
      "Detection score: 0.4889 (0=watermarked, 1=non-watermarked)\n",
      "Fin Epoch 16 | Loss: 0.0068 | BER: 0.44 | Detection: 0.4889, err_wat: 6.43500280380249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████| 3166/3166 [01:24<00:00, 37.41it/s, Loss=0.00647]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait : 0.44\n",
      "ok\n",
      "Detection score: 0.4889 (0=watermarked, 1=non-watermarked)\n",
      "Fin Epoch 17 | Loss: 0.0068 | BER: 0.44 | Detection: 0.4889, err_wat: 6.3971967697143555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████| 3166/3166 [01:24<00:00, 37.36it/s, Loss=0.0072] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait : 0.44\n",
      "ok\n",
      "Detection score: 0.4889 (0=watermarked, 1=non-watermarked)\n",
      "Fin Epoch 18 | Loss: 0.0068 | BER: 0.44 | Detection: 0.4889, err_wat: 6.396803379058838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 3166/3166 [01:24<00:00, 37.37it/s, Loss=0.00699]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait : 0.44\n",
      "ok\n",
      "Detection score: 0.4889 (0=watermarked, 1=non-watermarked)\n",
      "Fin Epoch 19 | Loss: 0.0068 | BER: 0.44 | Detection: 0.4889, err_wat: 6.410480499267578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|██████████| 3166/3166 [01:24<00:00, 37.43it/s, Loss=0.00708]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait : 0.44\n",
      "ok\n",
      "Detection score: 0.4889 (0=watermarked, 1=non-watermarked)\n",
      "Fin Epoch 20 | Loss: 0.0068 | BER: 0.44 | Detection: 0.4889, err_wat: 6.435699939727783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|██████████| 3166/3166 [01:41<00:00, 31.07it/s, Loss=0.00641]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait : 0.44\n",
      "ok\n",
      "Detection score: 0.4889 (0=watermarked, 1=non-watermarked)\n",
      "Fin Epoch 21 | Loss: 0.0068 | BER: 0.44 | Detection: 0.4889, err_wat: 6.4040374755859375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22: 100%|██████████| 3166/3166 [02:06<00:00, 24.94it/s, Loss=0.00563]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait : 0.44\n",
      "ok\n",
      "Detection score: 0.4889 (0=watermarked, 1=non-watermarked)\n",
      "Fin Epoch 22 | Loss: 0.0068 | BER: 0.44 | Detection: 0.4889, err_wat: 6.396872520446777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23: 100%|██████████| 3166/3166 [02:06<00:00, 25.05it/s, Loss=0.0082] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait : 0.44\n",
      "ok\n",
      "Detection score: 0.4889 (0=watermarked, 1=non-watermarked)\n",
      "Fin Epoch 23 | Loss: 0.0068 | BER: 0.44 | Detection: 0.4889, err_wat: 6.403104305267334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 3166/3166 [02:07<00:00, 24.84it/s, Loss=0.00801]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait : 0.44\n",
      "ok\n",
      "Detection score: 0.4889 (0=watermarked, 1=non-watermarked)\n",
      "Fin Epoch 24 | Loss: 0.0068 | BER: 0.44 | Detection: 0.4889, err_wat: 6.3895745277404785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25: 100%|██████████| 3166/3166 [02:31<00:00, 20.87it/s, Loss=0.00546]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait : 0.44\n",
      "ok\n",
      "Detection score: 0.4889 (0=watermarked, 1=non-watermarked)\n",
      "Fin Epoch 25 | Loss: 0.0068 | BER: 0.44 | Detection: 0.4889, err_wat: 6.351120948791504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26: 100%|██████████| 3166/3166 [03:02<00:00, 17.36it/s, Loss=0.00673]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait : 0.44\n",
      "ok\n",
      "Detection score: 0.4889 (0=watermarked, 1=non-watermarked)\n",
      "Fin Epoch 26 | Loss: 0.0068 | BER: 0.44 | Detection: 0.4889, err_wat: 6.33709192276001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27: 100%|██████████| 3166/3166 [03:23<00:00, 15.53it/s, Loss=0.00826]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait : 0.44\n",
      "ok\n",
      "Detection score: 0.4889 (0=watermarked, 1=non-watermarked)\n",
      "Fin Epoch 27 | Loss: 0.0068 | BER: 0.44 | Detection: 0.4889, err_wat: 6.363386154174805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28: 100%|██████████| 3166/3166 [03:38<00:00, 14.52it/s, Loss=0.00843]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait : 0.44\n",
      "ok\n",
      "Detection score: 0.4889 (0=watermarked, 1=non-watermarked)\n",
      "Fin Epoch 28 | Loss: 0.0068 | BER: 0.44 | Detection: 0.4889, err_wat: 6.36587381362915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 3166/3166 [03:43<00:00, 14.15it/s, Loss=0.00596]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait : 0.44\n",
      "ok\n",
      "Detection score: 0.4889 (0=watermarked, 1=non-watermarked)\n",
      "Fin Epoch 29 | Loss: 0.0068 | BER: 0.44 | Detection: 0.4889, err_wat: 6.353678226470947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30: 100%|██████████| 3166/3166 [03:42<00:00, 14.20it/s, Loss=0.00655]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait : 0.44\n",
      "ok\n",
      "Detection score: 0.4889 (0=watermarked, 1=non-watermarked)\n",
      "Fin Epoch 30 | Loss: 0.0068 | BER: 0.44 | Detection: 0.4889, err_wat: 6.35421895980835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31: 100%|██████████| 3166/3166 [03:39<00:00, 14.42it/s, Loss=0.00628]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait : 0.44\n",
      "ok\n",
      "Detection score: 0.4889 (0=watermarked, 1=non-watermarked)\n",
      "Fin Epoch 31 | Loss: 0.0068 | BER: 0.44 | Detection: 0.4889, err_wat: 6.353683948516846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32: 100%|██████████| 3166/3166 [03:41<00:00, 14.31it/s, Loss=0.0054] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait : 0.44\n",
      "ok\n",
      "Detection score: 0.4889 (0=watermarked, 1=non-watermarked)\n",
      "Fin Epoch 32 | Loss: 0.0068 | BER: 0.44 | Detection: 0.4889, err_wat: 6.335412979125977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33: 100%|██████████| 3166/3166 [03:42<00:00, 14.22it/s, Loss=0.00669]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait : 0.44\n",
      "ok\n",
      "Detection score: 0.4889 (0=watermarked, 1=non-watermarked)\n",
      "Fin Epoch 33 | Loss: 0.0068 | BER: 0.44 | Detection: 0.4889, err_wat: 6.336960792541504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34:   0%|          | 0/3166 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[13]\u001B[39m\u001B[32m, line 2\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;66;03m# 5. Attaque par Distillation\u001B[39;00m\n\u001B[32m----> \u001B[39m\u001B[32m2\u001B[39m student_res, stats = \u001B[43mrun_distillation_attack_riga\u001B[49m\u001B[43m(\u001B[49m\u001B[43mriga_defense\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdataloader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m100\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[12]\u001B[39m\u001B[32m, line 44\u001B[39m, in \u001B[36mrun_distillation_attack_riga\u001B[39m\u001B[34m(riga_obj, dataloader, epochs, lr)\u001B[39m\n\u001B[32m     41\u001B[39m pbar = tqdm(dataloader, desc=\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mEpoch \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepoch+\u001B[32m1\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m)\n\u001B[32m     42\u001B[39m running_loss = \u001B[32m0.0\u001B[39m\n\u001B[32m---> \u001B[39m\u001B[32m44\u001B[39m \u001B[43m\u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mclean_images\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m_\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mpbar\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m     45\u001B[39m \u001B[43m    \u001B[49m\u001B[43mclean_images\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mclean_images\u001B[49m\u001B[43m.\u001B[49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     48\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mwith\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mtorch\u001B[49m\u001B[43m.\u001B[49m\u001B[43mno_grad\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/WatDNN/venv/lib/python3.12/site-packages/tqdm/std.py:1181\u001B[39m, in \u001B[36mtqdm.__iter__\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m   1178\u001B[39m time = \u001B[38;5;28mself\u001B[39m._time\n\u001B[32m   1180\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1181\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mobj\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43miterable\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m   1182\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01myield\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mobj\u001B[49m\n\u001B[32m   1183\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;66;43;03m# Update and possibly print the progressbar.\u001B[39;49;00m\n\u001B[32m   1184\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001B[39;49;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/WatDNN/venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:732\u001B[39m, in \u001B[36m_BaseDataLoaderIter.__next__\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    729\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    730\u001B[39m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[32m    731\u001B[39m     \u001B[38;5;28mself\u001B[39m._reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m732\u001B[39m data = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    733\u001B[39m \u001B[38;5;28mself\u001B[39m._num_yielded += \u001B[32m1\u001B[39m\n\u001B[32m    734\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[32m    735\u001B[39m     \u001B[38;5;28mself\u001B[39m._dataset_kind == _DatasetKind.Iterable\n\u001B[32m    736\u001B[39m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m._IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m    737\u001B[39m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m._num_yielded > \u001B[38;5;28mself\u001B[39m._IterableDataset_len_called\n\u001B[32m    738\u001B[39m ):\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/WatDNN/venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:787\u001B[39m, in \u001B[36m_SingleProcessDataLoaderIter._next_data\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    786\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[32m--> \u001B[39m\u001B[32m787\u001B[39m     index = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_next_index\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[32m    788\u001B[39m     data = \u001B[38;5;28mself\u001B[39m._dataset_fetcher.fetch(index)  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[32m    789\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._pin_memory:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/WatDNN/venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:722\u001B[39m, in \u001B[36m_BaseDataLoaderIter._next_index\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    721\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_next_index\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[32m--> \u001B[39m\u001B[32m722\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mnext\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_sampler_iter\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/WatDNN/venv/lib/python3.12/site-packages/torch/utils/data/sampler.py:354\u001B[39m, in \u001B[36mBatchSampler.__iter__\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    352\u001B[39m         \u001B[38;5;28;01myield\u001B[39;00m [*batch_droplast]\n\u001B[32m    353\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m354\u001B[39m     batch = [*itertools.islice(sampler_iter, \u001B[38;5;28mself\u001B[39m.batch_size)]\n\u001B[32m    355\u001B[39m     \u001B[38;5;28;01mwhile\u001B[39;00m batch:\n\u001B[32m    356\u001B[39m         \u001B[38;5;28;01myield\u001B[39;00m batch\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/WatDNN/venv/lib/python3.12/site-packages/torch/utils/data/sampler.py:195\u001B[39m, in \u001B[36mRandomSampler.__iter__\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    193\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    194\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mself\u001B[39m.num_samples // n):\n\u001B[32m--> \u001B[39m\u001B[32m195\u001B[39m         \u001B[38;5;28;01myield from\u001B[39;00m \u001B[43mtorch\u001B[49m\u001B[43m.\u001B[49m\u001B[43mrandperm\u001B[49m\u001B[43m(\u001B[49m\u001B[43mn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgenerator\u001B[49m\u001B[43m=\u001B[49m\u001B[43mgenerator\u001B[49m\u001B[43m)\u001B[49m.tolist()\n\u001B[32m    196\u001B[39m     \u001B[38;5;28;01myield from\u001B[39;00m torch.randperm(n, generator=generator).tolist()[\n\u001B[32m    197\u001B[39m         : \u001B[38;5;28mself\u001B[39m.num_samples % n\n\u001B[32m    198\u001B[39m     ]\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "id": "plot_results_cell",
   "metadata": {},
   "source": [
    "# 6. Visualisation des resultats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "ax1.plot(stats[\"loss\"])\n",
    "ax1.set_xlabel(\"Epoch\")\n",
    "ax1.set_ylabel(\"Loss\")\n",
    "ax1.set_title(\"Distillation Loss\")\n",
    "\n",
    "ax2.plot(stats[\"ber\"])\n",
    "ax2.axhline(y=0.5, color='r', linestyle='--', label='Random (0.5)')\n",
    "ax2.set_xlabel(\"Epoch\")\n",
    "ax2.set_ylabel(\"BER\")\n",
    "ax2.set_title(\"BER Evolution During Distillation\")\n",
    "ax2.legend()\n",
    "\n",
    "ax3.plot(stats[\"detection\"])\n",
    "ax3.axhline(y=0.5, color='r', linestyle='--', label='Threshold')\n",
    "ax3.set_xlabel(\"Epoch\")\n",
    "ax3.set_ylabel(\"Detection Score\")\n",
    "ax3.set_title(\"Detection Score (0=watermarked, 1=clean)\")\n",
    "ax3.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "be7e00713921ce4e",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
