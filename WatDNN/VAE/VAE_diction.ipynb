{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-16T10:54:17.267053352Z",
     "start_time": "2026-02-16T10:54:16.640842181Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, latent_dim=200):\n",
    "        super(VAE, self).__init__()\n",
    "\n",
    "        # Encoder: 4 Conv2d layers with stride=2, kernel=4, padding=1\n",
    "        # Input: (3, 64, 64) -> (32, 32, 32) -> (64, 16, 16) -> (128, 8, 8) -> (256, 4, 4)\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=4, stride=2, padding=1),    # 0\n",
    "            nn.ReLU(),                                                # 1\n",
    "            nn.Conv2d(32, 64, kernel_size=4, stride=2, padding=1),   # 2\n",
    "            nn.ReLU(),                                                # 3\n",
    "            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1),  # 4\n",
    "            nn.ReLU(),                                                # 5\n",
    "            nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1), # 6\n",
    "            nn.ReLU(),                                                # 7\n",
    "        )\n",
    "\n",
    "        # 256 * 4 * 4 = 4096\n",
    "        self.fc_mu = nn.Linear(4096, latent_dim)\n",
    "        self.fc_logvar = nn.Linear(4096, latent_dim)\n",
    "\n",
    "        # Decoder input\n",
    "        self.decoder_input = nn.Linear(latent_dim, 4096)\n",
    "\n",
    "        # Decoder: 4 ConvTranspose2d layers\n",
    "        # (256, 4, 4) -> (128, 8, 8) -> (64, 16, 16) -> (32, 32, 32) -> (3, 64, 64)\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1),  # 0\n",
    "            nn.ReLU(),                                                          # 1\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),   # 2\n",
    "            nn.ReLU(),                                                          # 3\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=4, stride=2, padding=1),    # 4\n",
    "            nn.ReLU(),                                                          # 5\n",
    "            nn.ConvTranspose2d(32, 3, kernel_size=4, stride=2, padding=1),     # 6\n",
    "            nn.Sigmoid(),                                                       # 7\n",
    "        )\n",
    "\n",
    "    def encode(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = x.view(x.size(0), -1)  # Flatten to (batch, 4096)\n",
    "        mu = self.fc_mu(x)\n",
    "        logvar = self.fc_logvar(x)\n",
    "        return mu, logvar\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def decode(self, z):\n",
    "        x = self.decoder_input(z)\n",
    "        x = x.view(x.size(0), 256, 4, 4)  # Reshape to (batch, 256, 4, 4)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        recon = self.decode(z)\n",
    "        return recon, mu, logvar\n"
   ],
   "id": "69cb4bda69302c01",
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-02-16T10:54:18.141533457Z",
     "start_time": "2026-02-16T10:54:17.273658119Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from diffusers import DDPMPipeline, DDPMScheduler\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "\n",
    "# --- 1. Classes Utilitaires (Hooks & Projection) ---\n",
    "\n",
    "class FeatureHook:\n",
    "    \"\"\"Intercepte les activations d'une couche sp√©cifique.\"\"\"\n",
    "    def __init__(self, module):\n",
    "        self.hook = module.register_forward_hook(self.hook_fn)\n",
    "        self.features = None\n",
    "\n",
    "    def hook_fn(self, module, input, output):\n",
    "        self.features = output\n",
    "\n",
    "    def close(self):\n",
    "        self.hook.remove()\n",
    "\n",
    "class ProjectionNet(nn.Module):\n",
    "    \"\"\"\n",
    "    R√©seau l√©ger qui projette les features vers l'espace du watermark.\n",
    "    Structure: GAP -> Linear -> ReLU -> Linear -> Sigmoid\n",
    "    \"\"\"\n",
    "    def __init__(self, input_channels, watermark_len):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(input_channels, 256),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(256, watermark_len),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [Batch, Channels, H, W]\n",
    "        # Global Average Pooling pour r√©duire la dimension spatiale\n",
    "        if len(x.shape) == 4:\n",
    "            x = x.mean(dim=[2, 3])\n",
    "        return self.net(x)\n",
    "\n",
    "# --- 2. Classe Principale DICTION ---\n",
    "\n",
    "class DictionVAE:\n",
    "    def __init__(self, model, device=\"cuda\"):\n",
    "        self.device = device\n",
    "        self.model = model\n",
    "\n",
    "        # Configuration par d√©faut\n",
    "        self.config = {\n",
    "            \"layer_name\": \"decoder.6\", # Couche cible\n",
    "            \"trigger_size\": 64, # Nombre d'images dans le trigger set\n",
    "            \"lr\": 1e-4,\n",
    "            \"lambda_wat\": 1.0,\n",
    "            \"epochs\": 10,\n",
    "            \"beta_kl\":1.0,\n",
    "            \"watermark_len\":16,\n",
    "        }\n",
    "        self.saved_keys = {}\n",
    "\n",
    "    def _get_target_layer(self, model, layer_name):\n",
    "        \"\"\"R√©cup√®re le module PyTorch correspondant au nom.\"\"\"\n",
    "        for name, module in model.named_modules():\n",
    "            if name == layer_name:\n",
    "                return module\n",
    "        raise ValueError(f\"Couche {layer_name} introuvable.\")\n",
    "\n",
    "    def generate_trigger_set(self):\n",
    "        \"\"\"\n",
    "        G√©n√®re un Trigger Set persistant (bruit + timesteps fixes).\n",
    "        C'est ce qui servira d'entr√©e pour activer la marque.\n",
    "        \"\"\"\n",
    "        # shape = (self.config[\"trigger_size\"], 3, 32, 32) # CIFAR-10 shape\n",
    "        shape=(self.config[\"trigger_size\"],3,64,64) # CelebA-HQ shape\n",
    "\n",
    "        # Bruit fixe\n",
    "        trigger_set = torch.randn(shape).to(self.device)\n",
    "\n",
    "        return trigger_set\n",
    "\n",
    "    def embed(self, dataloader):\n",
    "        \"\"\"\n",
    "        Entra√Æne le mod√®le tatou√© et le r√©seau de projection.\n",
    "        Objectif :\n",
    "          - Features Original -> Random Watermark\n",
    "          - Features Tatou√© -> Target Watermark\n",
    "        \"\"\"\n",
    "        print(f\"--- start Embedding DICTION  in VAE({self.config['layer_name']}) ---\")\n",
    "\n",
    "        # 1. Pr√©paration des Mod√®les\n",
    "        original_model = deepcopy(self.model)\n",
    "        original_model.eval() # Le mod√®le original est gel√© (r√©f√©rence)\n",
    "        for p in original_model.parameters(): p.requires_grad = False\n",
    "\n",
    "        watermarked_model = self.model\n",
    "        watermarked_model.train()\n",
    "\n",
    "        # 2. G√©n√©ration des Cl√©s & Trigger Set\n",
    "        trigger_set = self.generate_trigger_set()\n",
    "\n",
    "        target_wm = torch.randint(0, 2, (self.config[\"watermark_len\"],)).float().to(self.device)\n",
    "        random_wm = torch.randint(0, 2, (self.config[\"watermark_len\"],)).float().to(self.device)\n",
    "\n",
    "        # 3. Initialisation ProjNet (Dimension dynamique)\n",
    "        # On fait un dummy pass pour avoir la taille des features\n",
    "        dummy_layer = self._get_target_layer(watermarked_model, self.config[\"layer_name\"])\n",
    "        dummy_hook = FeatureHook(dummy_layer)\n",
    "        with torch.no_grad():\n",
    "            _ = watermarked_model(trigger_set)\n",
    "        input_channels = dummy_hook.features.shape[1]\n",
    "        dummy_hook.close()\n",
    "\n",
    "        proj_net = ProjectionNet(input_channels, self.config[\"watermark_len\"]).to(self.device)\n",
    "        proj_net.train()\n",
    "\n",
    "        # 4. Optimiseur (Entra√Æne UNet + ProjNet)\n",
    "        optimizer = torch.optim.AdamW(\n",
    "            list(watermarked_model.parameters()) + list(proj_net.parameters()),\n",
    "            lr=self.config[\"lr\"]\n",
    "        )\n",
    "\n",
    "        mse_loss = nn.MSELoss()\n",
    "        bce_loss = nn.BCELoss()\n",
    "\n",
    "        # --- BOUCLE D'ENTRA√éNEMENT ---\n",
    "        for epoch in range(self.config[\"epochs\"]):\n",
    "            pbar = tqdm(dataloader)\n",
    "            for clean_images, _ in pbar:\n",
    "                clean_images = clean_images.to(self.device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                recon, mu, logvar = watermarked_model(clean_images)\n",
    "                # Reconstruction loss\n",
    "                l_recon = F.mse_loss(recon, clean_images)\n",
    "\n",
    "                # KL divergence\n",
    "                l_kl = -0.5 * torch.mean(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "\n",
    "                # VAE total task loss\n",
    "                l_main = l_recon + self.config[\"beta_kl\"] * l_kl\n",
    "\n",
    "\n",
    "\n",
    "                # B. T√¢che DICTION (Sur Trigger Set)\n",
    "\n",
    "                # 1. Extraire features ORIGINALES (Clean -> Random)\n",
    "                orig_layer = self._get_target_layer(original_model, self.config[\"layer_name\"])\n",
    "                hook_orig = FeatureHook(orig_layer)\n",
    "                with torch.no_grad():\n",
    "                    _ = original_model(trigger_set)\n",
    "                feat_orig = hook_orig.features\n",
    "                hook_orig.close()\n",
    "\n",
    "                # 2. Extraire features TATOU√âES (Watermarked -> Target)\n",
    "                wat_layer = self._get_target_layer(watermarked_model, self.config[\"layer_name\"])\n",
    "                hook_wat = FeatureHook(wat_layer)\n",
    "                # Important: On garde le gradient ici !\n",
    "                _ = watermarked_model(trigger_set)\n",
    "                feat_wat = hook_wat.features\n",
    "                hook_wat.close()\n",
    "\n",
    "                # 3. Projection & Loss\n",
    "                # Le ProjNet doit apprendre √† mapper Orig -> Random\n",
    "                pred_orig = proj_net(feat_orig.detach()) # Detach car on ne touche pas √† l'original\n",
    "                l_proj_clean = bce_loss(pred_orig.mean(dim=0), random_wm)\n",
    "\n",
    "                # Le ProjNet ET le UNet doivent apprendre Wat -> Target\n",
    "                pred_wat = proj_net(feat_wat)\n",
    "                l_proj_wat = bce_loss(pred_wat.mean(dim=0), target_wm)\n",
    "\n",
    "                # Loss Totale\n",
    "                l_wat = l_proj_clean + l_proj_wat\n",
    "                l_total = l_main + self.config[\"lambda_wat\"] * l_wat\n",
    "\n",
    "                l_total.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                # Metrics\n",
    "                ber = self._compute_ber(pred_wat.mean(dim=0), target_wm)\n",
    "                pbar.set_description(f\"epoch: {epoch} L_Main: {l_main:.3f} | L_Wat: {l_wat:.3f} | BER: {ber:.2f}\")\n",
    "\n",
    "                # if ber == 0.0 and l_wat.item() < 0.05:\n",
    "                #     print(\"‚úÖ Convergence atteinte !\")\n",
    "                #     break\n",
    "            # if ber == 0.0: break\n",
    "\n",
    "        # Sauvegarde des √©l√©ments n√©cessaires pour l'extraction\n",
    "        self.saved_keys = {\n",
    "            \"trigger_set\": trigger_set,\n",
    "            \"target_wm\": target_wm,\n",
    "            \"proj_net\": proj_net,\n",
    "            \"watermarked_model\": watermarked_model,\n",
    "            \"original_model\": original_model,\n",
    "        }\n",
    "        torch.save(self.saved_keys, \"Diction_VAE_model_checkpoint.pt\")\n",
    "\n",
    "        return watermarked_model\n",
    "\n",
    "    def extract(self,model=None):\n",
    "        \"\"\"\n",
    "        Extrait la marque d'un mod√®le suspect en utilisant les cl√©s sauvegard√©es.\n",
    "        \"\"\"\n",
    "        if model is None:\n",
    "            model = self.saved_keys[\"watermarked_model\"]\n",
    "\n",
    "        print(\"--- Extraction de la marque ---\")\n",
    "        model.eval()\n",
    "        proj_net = self.saved_keys[\"proj_net\"]\n",
    "        proj_net.eval()\n",
    "\n",
    "        trigger_set = self.saved_keys[\"trigger_set\"]\n",
    "\n",
    "        target_wm = self.saved_keys[\"target_wm\"]\n",
    "\n",
    "        # 1. Hook sur le mod√®le suspect\n",
    "        target_layer = self._get_target_layer(model, self.config[\"layer_name\"])\n",
    "        hook = FeatureHook(target_layer)\n",
    "\n",
    "        # 2. Passage du Trigger Set\n",
    "        with torch.no_grad():\n",
    "            _ = model(trigger_set)\n",
    "\n",
    "        features = hook.features\n",
    "        hook.close()\n",
    "\n",
    "        # 3. Projection & BER\n",
    "        wm_pred = proj_net(features).mean(dim=0)\n",
    "        ber = self._compute_ber(wm_pred, target_wm)\n",
    "\n",
    "        print(f\"BER Extrait : {ber:.2f}\")\n",
    "        return ber, wm_pred\n",
    "\n",
    "    @staticmethod\n",
    "    def _compute_ber(pred, target):\n",
    "        return ((pred > 0.5).float() != target).float().mean().item()\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/latim/PycharmProjects/WatDNN/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-16T10:54:20.140999339Z",
     "start_time": "2026-02-16T10:54:18.191689037Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- EXEMPLE D'UTILISATION ---\n",
    "\n",
    "# 1. Data Loader\n",
    "# transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "# dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "# dataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "import torch\n",
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# Load from Hugging Face (no Google Drive issues)\n",
    "print(\"Loading dataset...\")\n",
    "hf_dataset = load_dataset(\"nielsr/CelebA-faces\", split=\"train\")\n",
    "\n",
    "class CelebAWrapper(torch.utils.data.Dataset):\n",
    "    def __init__(self, hf_dataset, transform):\n",
    "        self.dataset = hf_dataset\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.dataset[idx]['image']\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, 0\n",
    "\n",
    "dataset = CelebAWrapper(hf_dataset, transform)\n",
    "print(\"Dataset loaded!\")\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "print(\"loader loaded!\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "df3aef93902dd9bd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Dataset loaded!\n",
      "loader loaded!\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-16T11:12:06.105685776Z",
     "start_time": "2026-02-16T10:54:20.186042672Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#load model\n",
    "latent_dim = 200\n",
    "\n",
    "# Initialize the model\n",
    "model = VAE(latent_dim=latent_dim)\n",
    "\n",
    "# Load the trained weights\n",
    "model_path = \"./vae_celeba_latent_200_epochs_10_batch_64_subset_80000.pth\"\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.to(device)\n",
    "# 2. Instanciation & Embedding\n",
    "diction = DictionVAE(model)\n",
    "# diction= DictionDDPM(\"google/ddpm-celebahq-256\")\n",
    "\n",
    "# Embed (Retourne le mod√®le tatou√©)\n",
    "watermarked_model = diction.embed(dataloader)\n",
    "\n",
    "# 3. Extraction (Test imm√©diat)\n",
    "ber, _ = diction.extract(watermarked_model)\n",
    "print(f\"BER sur le mod√®le tatou√© : {ber:.2f}\")"
   ],
   "id": "55ac0be77d51dbd3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- start Embedding DICTION  in VAE(decoder.6) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 0 L_Main: 0.297 | L_Wat: 0.005 | BER: 0.00: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3166/3166 [01:31<00:00, 34.63it/s]\n",
      "epoch: 1 L_Main: 0.315 | L_Wat: 0.001 | BER: 0.00: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3166/3166 [01:41<00:00, 31.25it/s]\n",
      "epoch: 2 L_Main: 0.306 | L_Wat: 0.000 | BER: 0.00: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3166/3166 [01:40<00:00, 31.48it/s]\n",
      "epoch: 3 L_Main: 0.273 | L_Wat: 0.000 | BER: 0.00: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3166/3166 [01:47<00:00, 29.52it/s]\n",
      "epoch: 4 L_Main: 0.300 | L_Wat: 0.000 | BER: 0.00: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3166/3166 [02:03<00:00, 25.63it/s]\n",
      "epoch: 5 L_Main: 0.293 | L_Wat: 0.000 | BER: 0.00: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3166/3166 [01:52<00:00, 28.20it/s]\n",
      "epoch: 6 L_Main: 0.279 | L_Wat: 0.000 | BER: 0.00: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3166/3166 [01:32<00:00, 34.11it/s]\n",
      "epoch: 7 L_Main: 0.344 | L_Wat: 0.000 | BER: 0.00: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3166/3166 [01:44<00:00, 30.39it/s]\n",
      "epoch: 8 L_Main: 0.301 | L_Wat: 0.000 | BER: 0.00: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3166/3166 [01:49<00:00, 28.79it/s]\n",
      "epoch: 9 L_Main: 0.329 | L_Wat: 0.000 | BER: 0.00: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3166/3166 [02:02<00:00, 25.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Extraction de la marque ---\n",
      "BER Extrait : 0.00\n",
      "BER sur le mod√®le tatou√© : 0.00\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-16T11:12:06.294913355Z",
     "start_time": "2026-02-16T11:12:06.243630283Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from diffusers import UNet2DModel, DDPMScheduler\n",
    "from torch.optim import AdamW\n",
    "from tqdm import tqdm\n",
    "import torch.optim as optim\n",
    "\n",
    "def run_distillation_attack(diction_obj, dataloader, epochs=5, lr=1e-3):\n",
    "    \"\"\"\n",
    "    Lance une distillation Black-Box (Output only) du Teacher tatou√© vers un Student vierge.\n",
    "    Monitore le BER (err_wat) √† chaque √©poque.\n",
    "    \"\"\"\n",
    "    device = diction_obj.device\n",
    "\n",
    "    # --- 1. R√©cup√©ration du Teacher (Gel√©) ---\n",
    "    checkpoint = torch.load(\"Diction_VAE_model_checkpoint.pt\", weights_only=False)\n",
    "    # teacher_pipeline = DDPMPipeline.from_pretrained(\"google/ddpm-cifar10-32\")\n",
    "    # teacher_pipeline = DDPMPipeline.from_pretrained(\"google/ddpm-celebahq-256\")\n",
    "    # teacher_unet = teacher_pipeline.unet.to(device)\n",
    "    teacher = checkpoint[\"watermarked_model\"]\n",
    "    teacher.eval()\n",
    "    for p in teacher.parameters(): p.requires_grad = False\n",
    "\n",
    "    # --- 2. Initialisation du Student (Vierge) ---\n",
    "    print(\"\\n--- Initialisation du Student ---\")\n",
    "    # On cr√©e un mod√®le avec la m√™me config mais des poids al√©atoires\n",
    "    # student_unet = UNet2DModel.from_config(teacher_unet.config).to(device)\n",
    "    # student_pipeline = DDPMPipeline.from_pretrained(\"google/ddpm-cifar10-32\")\n",
    "    student=VAE(latent_dim=latent_dim)\n",
    "    student.load_state_dict(torch.load(model_path))\n",
    "    student.to(device)\n",
    "    student.train()\n",
    "\n",
    "\n",
    "    # --- 3. V√©rifications Avant Distillation (Sanity Checks) ---\n",
    "    print(\"\\n[Check 1] V√©rification du Teacher (Doit √™tre ~0.0)\")\n",
    "    ber_teacher, _ = diction_obj.extract(teacher)\n",
    "    if ber_teacher > 0.05:\n",
    "        print(f\"‚ö†Ô∏è ATTENTION : Le Teacher n'est pas bien tatou√© (BER={ber_teacher:.2f})\")\n",
    "    else:\n",
    "        print(f\"‚úÖ Teacher OK (BER={ber_teacher:.2f})\")\n",
    "\n",
    "    print(\"\\n[Check 2] V√©rification du Student (Doit √™tre ~0.5 - Al√©atoire)\")\n",
    "    ber_student_start, _ = diction_obj.extract(student)\n",
    "    print(f\"‚ÑπÔ∏è Student avant distillation : BER={ber_student_start:.2f} (Normal pour un mod√®le vierge)\")\n",
    "\n",
    "    # --- 4. Configuration Distillation ---\n",
    "    optimizer = AdamW(student.parameters(), lr=lr)\n",
    "    scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[5], gamma=0.1)\n",
    "\n",
    "\n",
    "\n",
    "    history = {\"loss\": [], \"ber\": []}\n",
    "\n",
    "    print(f\"\\n--- D√©marrage de la Distillation ({epochs} epochs) ---\")\n",
    "    a=0\n",
    "    for epoch in range(epochs):\n",
    "        pbar = tqdm(dataloader, desc=f\"Epoch {epoch+1}/{epochs}\")\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for clean_images, _ in pbar:\n",
    "            clean_images = clean_images.to(device)\n",
    "\n",
    "            # B. Teacher Prediction (Cible) - BLACK BOX (Juste la sortie)\n",
    "            with torch.no_grad():\n",
    "                target_pred ,_,_= teacher(clean_images)\n",
    "            # C. Student Prediction\n",
    "            student_pred,_,_ = student(clean_images)\n",
    "\n",
    "            # D. Loss (MSE pure sur les sorties)\n",
    "            loss1 = F.mse_loss(student_pred, clean_images)\n",
    "\n",
    "            loss2 = F.mse_loss(student_pred, target_pred)\n",
    "            loss = 0.1* loss1 + 0.9 * loss2\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            pbar.set_postfix(Loss_Distill=loss.item())\n",
    "\n",
    "        # --- E. V√©rification du Transfert de Marque (err_wat) ---\n",
    "        # On utilise la m√©thode extract de diction sur le student actuel\n",
    "        # Elle utilise le Trigger Set et le ProjNet du Teacher (les cl√©s)\n",
    "        print(f\"\\nCalcul du BER (err_wat) pour l'√©poque {epoch+1}...\")\n",
    "        current_ber, wat_ext = diction_obj.extract(student)\n",
    "        scheduler.step()\n",
    "\n",
    "        history[\"loss\"].append(running_loss / len(dataloader))\n",
    "        history[\"ber\"].append(current_ber)\n",
    "\n",
    "        print(f\"üëâ Fin Epoch {epoch+1} | Loss: {history['loss'][-1]:.4f} | BER Student: {current_ber:.2f} | ext_wat: {nn.BCELoss()(wat_ext, checkpoint['target_wm']).item():.4f}\")\n",
    "\n",
    "        # Condition de succ√®s total (Si le student a parfaitement copi√© la marque)\n",
    "        if current_ber==0.0 and a>=1:\n",
    "            print(\"‚úÖ Marque r√©cup√©r√©e avec succ√®s par distillation !\")\n",
    "            break\n",
    "        elif current_ber==0.0 and a<1 :\n",
    "            a+=1\n",
    "        else:\n",
    "            a=0\n",
    "    return student, history\n",
    "\n"
   ],
   "id": "70c52864caa30280",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-16T11:19:01.051525721Z",
     "start_time": "2026-02-16T11:12:06.297811687Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- Lancement du test ---\n",
    "# diction est l'objet cr√©√© dans l'√©tape pr√©c√©dente\n",
    "# dataloader est votre chargeur CIFAR-10\n",
    "\n",
    "student_distilled, stats = run_distillation_attack(diction, dataloader, epochs=1000)"
   ],
   "id": "73ffea1114591cca",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Initialisation du Student ---\n",
      "\n",
      "[Check 1] V√©rification du Teacher (Doit √™tre ~0.0)\n",
      "--- Extraction de la marque ---\n",
      "BER Extrait : 0.00\n",
      "‚úÖ Teacher OK (BER=0.00)\n",
      "\n",
      "[Check 2] V√©rification du Student (Doit √™tre ~0.5 - Al√©atoire)\n",
      "--- Extraction de la marque ---\n",
      "BER Extrait : 0.25\n",
      "‚ÑπÔ∏è Student avant distillation : BER=0.25 (Normal pour un mod√®le vierge)\n",
      "\n",
      "--- D√©marrage de la Distillation (1000 epochs) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3166/3166 [01:22<00:00, 38.15it/s, Loss_Distill=0.0349]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calcul du BER (err_wat) pour l'√©poque 1...\n",
      "--- Extraction de la marque ---\n",
      "BER Extrait : 0.25\n",
      "üëâ Fin Epoch 1 | Loss: 0.0341 | BER Student: 0.25 | ext_wat: 0.7143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/1000: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3166/3166 [01:22<00:00, 38.31it/s, Loss_Distill=0.0312]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calcul du BER (err_wat) pour l'√©poque 2...\n",
      "--- Extraction de la marque ---\n",
      "BER Extrait : 0.00\n",
      "üëâ Fin Epoch 2 | Loss: 0.0338 | BER Student: 0.00 | ext_wat: 0.0302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/1000: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3166/3166 [01:22<00:00, 38.28it/s, Loss_Distill=0.0353]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calcul du BER (err_wat) pour l'√©poque 3...\n",
      "--- Extraction de la marque ---\n",
      "BER Extrait : 0.25\n",
      "üëâ Fin Epoch 3 | Loss: 0.0337 | BER Student: 0.25 | ext_wat: 1.4904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/1000: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3166/3166 [01:23<00:00, 38.09it/s, Loss_Distill=0.0307]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calcul du BER (err_wat) pour l'√©poque 4...\n",
      "--- Extraction de la marque ---\n",
      "BER Extrait : 0.00\n",
      "üëâ Fin Epoch 4 | Loss: 0.0337 | BER Student: 0.00 | ext_wat: 0.0003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/1000: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3166/3166 [01:23<00:00, 38.10it/s, Loss_Distill=0.0334]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calcul du BER (err_wat) pour l'√©poque 5...\n",
      "--- Extraction de la marque ---\n",
      "BER Extrait : 0.00\n",
      "üëâ Fin Epoch 5 | Loss: 0.0337 | BER Student: 0.00 | ext_wat: 0.0003\n",
      "‚úÖ Marque r√©cup√©r√©e avec succ√®s par distillation !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-16T11:19:01.146047976Z",
     "start_time": "2026-02-16T11:19:01.097346190Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "79fd816a650b5ae7",
   "outputs": [],
   "execution_count": 6
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
