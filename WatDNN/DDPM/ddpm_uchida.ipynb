{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-02-11T14:47:25.544483110Z",
     "start_time": "2026-02-11T14:47:23.923982846Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from diffusers import DDPMPipeline, DDPMScheduler, UNet2DModel\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import AdamW\n",
    "from datasets import load_dataset\n",
    "\n",
    "# --- Classe Principale Uchida ---\n",
    "\n",
    "class UchidaDDPM:\n",
    "    def __init__(self, model_id, device=\"cuda\"):\n",
    "        self.device = device\n",
    "        self.model_id = model_id\n",
    "\n",
    "        # Chargement du mod√®le\n",
    "        self.pipeline = DDPMPipeline.from_pretrained(model_id)\n",
    "        self.unet = self.pipeline.unet.to(device)\n",
    "        self.scheduler = self.pipeline.scheduler\n",
    "\n",
    "        # Configuration par d√©faut\n",
    "        self.config = {\n",
    "            \"layer_name\": \"mid_block.resnets.1.conv2.weight\", # Cible robuste\n",
    "            \"watermark_len\": 64,\n",
    "            \"lr\": 1e-4,\n",
    "            \"lambda_wat\": 1.0,\n",
    "            \"epochs\":30\n",
    "        }\n",
    "\n",
    "        self.saved_keys = {}\n",
    "\n",
    "    def _get_target_weights(self, model):\n",
    "        \"\"\"R√©cup√®re le tenseur des poids de la couche cible.\"\"\"\n",
    "        for name, param in model.named_parameters():\n",
    "            if name == self.config[\"layer_name\"]:\n",
    "                return param\n",
    "        raise ValueError(f\"Param√®tre {self.config['layer_name']} introuvable.\")\n",
    "\n",
    "    def embed(self, dataloader):\n",
    "        \"\"\"\n",
    "        Incorpore la marque Uchida (R√©gularisation des poids) pendant le finetuning.\n",
    "        \"\"\"\n",
    "        print(f\"--- D√©marrage Embedding UCHIDA ({self.config['layer_name']}) ---\")\n",
    "\n",
    "        watermarked_unet = self.unet\n",
    "        watermarked_unet.train()\n",
    "\n",
    "        # 1. G√©n√©ration des Cl√©s (Matrice A et Watermark binaire)\n",
    "        # On r√©cup√®re la dimension des poids pour initialiser A\n",
    "        target_weights = self._get_target_weights(watermarked_unet)\n",
    "\n",
    "        # Uchida : Moyenne sur l'axe des canaux de sortie (ou aplatissement total)\n",
    "        # Ici on suit la logique standard : mean(0) puis flatten\n",
    "        with torch.no_grad():\n",
    "            w_flat_dim = torch.flatten(target_weights.mean(dim=0)).shape[0]\n",
    "\n",
    "        print(f\"Dimension vecteur poids : {w_flat_dim} | Watermark : {self.config['watermark_len']} bits\")\n",
    "\n",
    "        matrix_a = torch.randn(w_flat_dim, self.config[\"watermark_len\"]).to(self.device)\n",
    "        watermark_target = torch.randint(0, 2, (self.config[\"watermark_len\"],)).float().to(self.device)\n",
    "\n",
    "        # 2. Optimiseur\n",
    "        optimizer = torch.optim.AdamW(watermarked_unet.parameters(), lr=self.config[\"lr\"])\n",
    "        mse_loss = nn.MSELoss()\n",
    "        bce_loss = nn.BCELoss()\n",
    "\n",
    "        # 3. Boucle d'entra√Ænement\n",
    "        for epoch in range(self.config[\"epochs\"]):\n",
    "            pbar = tqdm(dataloader)\n",
    "            for clean_images, _ in pbar:\n",
    "                clean_images = clean_images.to(self.device)\n",
    "                bs = clean_images.shape[0]\n",
    "\n",
    "                # A. Processus de Diffusion (Forward)\n",
    "                noise = torch.randn_like(clean_images).to(self.device)\n",
    "                timesteps = torch.randint(0, self.scheduler.config.num_train_timesteps, (bs,), device=self.device).long()\n",
    "                noisy_images = self.scheduler.add_noise(clean_images, noise, timesteps)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # B. Pr√©diction (Task Loss)\n",
    "                noise_pred = watermarked_unet(noisy_images, timesteps).sample\n",
    "                l_main = mse_loss(noise_pred, noise)\n",
    "\n",
    "                # C. Watermark Loss (Regularization)\n",
    "                # On projette les poids actuels vers le watermark\n",
    "                current_weights = self._get_target_weights(watermarked_unet)\n",
    "                w_flat = torch.flatten(current_weights.mean(dim=0))\n",
    "\n",
    "                pred_wm_prob = torch.sigmoid(w_flat @ matrix_a)\n",
    "                l_wat = bce_loss(pred_wm_prob, watermark_target)\n",
    "\n",
    "                # Loss Totale\n",
    "                l_total = l_main + self.config[\"lambda_wat\"] * l_wat\n",
    "\n",
    "                l_total.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                # Metrics\n",
    "                ber = self._compute_ber(pred_wm_prob, watermark_target)\n",
    "                pbar.set_description(f\" epochs: {epoch+1}  L_Main: {l_main:.3f} | L_Wat: {l_wat:.3f} | BER: {ber:.2f}\")\n",
    "\n",
    "                # if ber == 0.0 and l_wat.item() < 0.01:\n",
    "                #     print(\"‚úÖ Convergence atteinte !\")\n",
    "                #     break\n",
    "            if ber == 0.0 and epoch>=9: break\n",
    "\n",
    "        # Sauvegarde des cl√©s\n",
    "        self.saved_keys = {\n",
    "            \"matrix_a\": matrix_a,\n",
    "            \"watermark_target\": watermark_target,\n",
    "            \"watermarked_unet\": watermarked_unet\n",
    "        }\n",
    "        return watermarked_unet\n",
    "\n",
    "    def extract(self, suspect_unet=None):\n",
    "        \"\"\"\n",
    "        Extrait la marque d'un mod√®le suspect (lecture des poids).\n",
    "        \"\"\"\n",
    "        if suspect_unet is None:\n",
    "            suspect_unet = self.saved_keys[\"watermarked_unet\"]\n",
    "\n",
    "        matrix_a = self.saved_keys[\"matrix_a\"]\n",
    "        watermark_target = self.saved_keys[\"watermark_target\"]\n",
    "\n",
    "        # 1. R√©cup√©ration des poids\n",
    "        try:\n",
    "            target_weights = self._get_target_weights(suspect_unet)\n",
    "        except ValueError:\n",
    "            print(\"‚ö†Ô∏è Couche cible introuvable dans le mod√®le suspect.\")\n",
    "            return 1.0 # BER max\n",
    "\n",
    "        # 2. Projection\n",
    "        with torch.no_grad():\n",
    "            w_flat = torch.flatten(target_weights.mean(dim=0))\n",
    "            pred_wm_prob = torch.sigmoid(w_flat @ matrix_a)\n",
    "\n",
    "            ber = self._compute_ber(pred_wm_prob, watermark_target)\n",
    "\n",
    "        print(f\"BER Extrait : {ber:.2f}\")\n",
    "        return ber, pred_wm_prob\n",
    "\n",
    "    @staticmethod\n",
    "    def _compute_ber(pred, target):\n",
    "        return ((pred > 0.5).float() != target).float().mean().item()\n",
    "\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/latim/PycharmProjects/WatDNN/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-11T14:57:53.677479136Z",
     "start_time": "2026-02-11T14:47:25.554516043Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- EXEMPLE D'EX√âCUTION ---\n",
    "\n",
    "# 1. Setup Data\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "\n",
    "\n",
    "print(f\"Dataset loaded: \")\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=128, shuffle=True)\n",
    "print(\"dataloader ready\")\n",
    "# 2. Embedding Uchi\n",
    "uchida_defense = UchidaDDPM(\"google/ddpm-cifar10-32\")\n",
    "# uchida_defense = UchidaDDPM(\"google/ddpm-celebahq-256\")\n",
    "\n",
    "watermarked_model = uchida_defense.embed(dataloader)"
   ],
   "id": "c6b51ed1795a8918",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot initialize model with low cpu memory usage because `accelerate` was not found in the environment. Defaulting to `low_cpu_mem_usage=False`. It is strongly recommended to install `accelerate` for faster and less memory-intense model loading. You can do so with: \n",
      "```\n",
      "pip install accelerate\n",
      "```\n",
      ".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded: \n",
      "dataloader ready\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...:   0%|          | 0/2 [00:00<?, ?it/s]An error occurred while trying to fetch /home/latim/.cache/huggingface/hub/models--google--ddpm-cifar10-32/snapshots/267b167dc01f0e4e61923ea244e8b988f84deb80: Error no file named diffusion_pytorch_model.safetensors found in directory /home/latim/.cache/huggingface/hub/models--google--ddpm-cifar10-32/snapshots/267b167dc01f0e4e61923ea244e8b988f84deb80.\n",
      "Defaulting to unsafe serialization. Pass `allow_pickle=False` to raise an error instead.\n",
      "Loading pipeline components...: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00, 60.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- D√©marrage Embedding UCHIDA (mid_block.resnets.1.conv2.weight) ---\n",
      "Dimension vecteur poids : 2304 | Watermark : 64 bits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " epochs: 1  L_Main: 0.039 | L_Wat: 0.026 | BER: 0.00: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 391/391 [01:02<00:00,  6.25it/s]\n",
      " epochs: 2  L_Main: 0.024 | L_Wat: 0.009 | BER: 0.00: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 391/391 [01:02<00:00,  6.23it/s]\n",
      " epochs: 3  L_Main: 0.037 | L_Wat: 0.005 | BER: 0.00: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 391/391 [01:02<00:00,  6.23it/s]\n",
      " epochs: 4  L_Main: 0.032 | L_Wat: 0.003 | BER: 0.00: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 391/391 [01:02<00:00,  6.25it/s]\n",
      " epochs: 5  L_Main: 0.027 | L_Wat: 0.002 | BER: 0.00: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 391/391 [01:02<00:00,  6.24it/s]\n",
      " epochs: 6  L_Main: 0.031 | L_Wat: 0.001 | BER: 0.00: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 391/391 [01:02<00:00,  6.24it/s]\n",
      " epochs: 7  L_Main: 0.031 | L_Wat: 0.001 | BER: 0.00: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 391/391 [01:02<00:00,  6.22it/s]\n",
      " epochs: 8  L_Main: 0.014 | L_Wat: 0.001 | BER: 0.00: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 391/391 [01:02<00:00,  6.23it/s]\n",
      " epochs: 9  L_Main: 0.030 | L_Wat: 0.001 | BER: 0.00: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 391/391 [01:02<00:00,  6.23it/s]\n",
      " epochs: 10  L_Main: 0.020 | L_Wat: 0.000 | BER: 0.00: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 391/391 [01:02<00:00,  6.24it/s]\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-06T20:40:03.059172574Z",
     "start_time": "2026-02-05T10:55:29.914774021Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# from datasets import load_dataset\n",
    "# from torch.utils.data import DataLoader\n",
    "# import torch\n",
    "# from torchvision import transforms\n",
    "#\n",
    "#\n",
    "# import torch\n",
    "# import gc\n",
    "#\n",
    "# gc.collect()\n",
    "# torch.cuda.empty_cache()\n",
    "#\n",
    "# transform = transforms.Compose([\n",
    "#     transforms.Resize((256, 256)),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "# ])\n",
    "#\n",
    "# # Load from Hugging Face (no Google Drive issues)\n",
    "# print(\"Loading dataset...\")\n",
    "# hf_dataset = load_dataset(\"nielsr/CelebA-faces\", split=\"train\")\n",
    "#\n",
    "# class CelebAWrapper(torch.utils.data.Dataset):\n",
    "#     def __init__(self, hf_dataset, transform):\n",
    "#         self.dataset = hf_dataset\n",
    "#         self.transform = transform\n",
    "#\n",
    "#     def __len__(self):\n",
    "#         return len(self.dataset)\n",
    "#\n",
    "#     def __getitem__(self, idx):\n",
    "#         image = self.dataset[idx]['image']\n",
    "#         if self.transform:\n",
    "#             image = self.transform(image)\n",
    "#         return image, 0\n",
    "#\n",
    "# dataset = CelebAWrapper(hf_dataset, transform)\n",
    "# print(\"Dataset loaded!\")\n",
    "#\n",
    "# dataloader = DataLoader(dataset, batch_size=8, shuffle=True)\n",
    "# print(\"loader loaded!\")\n",
    "# # Continue with your code\n",
    "# uchida_defense = UchidaDDPM(\"google/ddpm-celebahq-256\")\n",
    "# print(\"Uchida defense loaded!\")\n",
    "# watermarked_model = uchida_defense.embed(dataloader)"
   ],
   "id": "a752da22669d4bf0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot initialize model with low cpu memory usage because `accelerate` was not found in the environment. Defaulting to `low_cpu_mem_usage=False`. It is strongly recommended to install `accelerate` for faster and less memory-intense model loading. You can do so with: \n",
      "```\n",
      "pip install accelerate\n",
      "```\n",
      ".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded!\n",
      "loader loaded!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...:   0%|          | 0/2 [00:00<?, ?it/s]An error occurred while trying to fetch /home/latim/.cache/huggingface/hub/models--google--ddpm-celebahq-256/snapshots/cd5c944777ea2668051904ead6cc120739b86c4d: Error no file named diffusion_pytorch_model.safetensors found in directory /home/latim/.cache/huggingface/hub/models--google--ddpm-celebahq-256/snapshots/cd5c944777ea2668051904ead6cc120739b86c4d.\n",
      "Defaulting to unsafe serialization. Pass `allow_pickle=False` to raise an error instead.\n",
      "Loading pipeline components...: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00, 40.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uchida defense loaded!\n",
      "--- D√©marrage Embedding UCHIDA (mid_block.resnets.0.conv1.weight) ---\n",
      "Dimension vecteur poids : 4608 | Watermark : 64 bits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "L_Main: 0.010 | L_Wat: 0.000 | BER: 0.00: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25325/25325 [2:49:38<00:00,  2.49it/s]  \n",
      "L_Main: 0.002 | L_Wat: 0.000 | BER: 0.00: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25325/25325 [2:50:36<00:00,  2.47it/s]  \n",
      "L_Main: 0.002 | L_Wat: 0.000 | BER: 0.00: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25325/25325 [2:47:50<00:00,  2.51it/s]  \n",
      "L_Main: 0.005 | L_Wat: 0.000 | BER: 0.00: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25325/25325 [2:47:28<00:00,  2.52it/s]  \n",
      "L_Main: 0.005 | L_Wat: 0.000 | BER: 0.00: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25325/25325 [2:47:48<00:00,  2.52it/s]  \n",
      "L_Main: 0.006 | L_Wat: 0.000 | BER: 0.00: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25325/25325 [2:48:09<00:00,  2.51it/s]  \n",
      "L_Main: 0.006 | L_Wat: 0.000 | BER: 0.00: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25325/25325 [2:48:10<00:00,  2.51it/s]  \n",
      "L_Main: 0.002 | L_Wat: 0.000 | BER: 0.00: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25325/25325 [2:49:35<00:00,  2.49it/s]  \n",
      "L_Main: 0.002 | L_Wat: 0.000 | BER: 0.00: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25325/25325 [2:50:18<00:00,  2.48it/s]  \n",
      "L_Main: 0.007 | L_Wat: 0.000 | BER: 0.00: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25325/25325 [2:49:13<00:00,  2.49it/s]  \n",
      "L_Main: 0.001 | L_Wat: 0.000 | BER: 0.00: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25325/25325 [2:47:58<00:00,  2.51it/s]  \n",
      "L_Main: 0.010 | L_Wat: 0.000 | BER: 0.00: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25325/25325 [2:47:41<00:00,  2.52it/s]  \n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-11T14:59:57.338099981Z",
     "start_time": "2026-02-11T14:59:57.288644076Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- Fonction de Distillation (Attaque) ---\n",
    "\n",
    "def run_distillation_attack_uchida(uchida_obj, dataloader, epochs=5, lr=1e-4):\n",
    "    \"\"\"\n",
    "    Tente de transf√©rer la fonctionnalit√© du mod√®le Uchida vers un mod√®le vierge.\n",
    "    V√©rifie si la marque (bas√©e sur les poids) survit.\n",
    "    \"\"\"\n",
    "    device = uchida_obj.device\n",
    "\n",
    "    # 1. Teacher (Gel√©)\n",
    "    teacher_unet = uchida_obj.saved_keys[\"watermarked_unet\"]\n",
    "    teacher_unet.eval()\n",
    "    for p in teacher_unet.parameters(): p.requires_grad = False\n",
    "\n",
    "    # 2. Student (Vierge - M√™me architecture)\n",
    "    print(\"\\n--- Initialisation du Student ---\")\n",
    "    # student_unet = UNet2DModel.from_config(teacher_unet.config).to(device)\n",
    "    student_pipeline = DDPMPipeline.from_pretrained(\"google/ddpm-cifar10-32\")\n",
    "    # student_pipeline = DDPMPipeline.from_pretrained(\"google/ddpm-celebahq-256\")\n",
    "\n",
    "    student_unet = student_pipeline.unet.to(device)\n",
    "    student_unet.train()\n",
    "\n",
    "    teacher_ber, _ = uchida_obj.extract(teacher_unet)\n",
    "    student_ber, _ = uchida_obj.extract(student_unet)\n",
    "    # Sanity Checks\n",
    "    print(f\"[Check] BER Teacher: {teacher_ber:.2f}\")\n",
    "    print(f\"[Check] BER Student (Avant): {student_ber:.2f}\")\n",
    "\n",
    "    optimizer = AdamW(student_unet.parameters(), lr=lr)\n",
    "    noise_scheduler = uchida_obj.scheduler\n",
    "    history = {\"loss\": [], \"ber\": []}\n",
    "\n",
    "    print(f\"\\n--- Distillation Uchida ({epochs} epochs) ---\")\n",
    "    a=0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        pbar = tqdm(dataloader, desc=f\"Epoch {epoch+1}\")\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for clean_images, _ in pbar:\n",
    "            clean_images = clean_images.to(device)\n",
    "            bs = clean_images.shape[0] #batch size\n",
    "\n",
    "            # A. Input Noise\n",
    "            noise = torch.randn_like(clean_images).to(device)\n",
    "            timesteps = torch.randint(0, noise_scheduler.config.num_train_timesteps, (bs,), device=device).long()\n",
    "            noisy_images = noise_scheduler.add_noise(clean_images, noise, timesteps)\n",
    "\n",
    "            # B. Distillation (Output Matching)\n",
    "            with torch.no_grad():\n",
    "                target_pred = teacher_unet(noisy_images, timesteps).sample\n",
    "\n",
    "            student_pred = student_unet(noisy_images, timesteps).sample\n",
    "\n",
    "            loss = F.mse_loss(student_pred, target_pred)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            pbar.set_postfix(Loss=loss.item())\n",
    "\n",
    "        # C. V√©rification : Est-ce que les poids se sont align√©s sur Uchida ?\n",
    "        current_ber, pred_wm_prob = uchida_obj.extract(student_unet)\n",
    "        history[\"ber\"].append(current_ber)\n",
    "\n",
    "        print(f\"üëâ Fin Epoch {epoch+1} | Loss: {loss.item():.4f} | BER Student: {current_ber:.2f} | err_wat: {nn.BCELoss()(pred_wm_prob, uchida_obj.saved_keys[\"watermark_target\"]) }\")\n",
    "        if current_ber==0.0 and a>=1:\n",
    "            print(\"‚úÖ Marque r√©cup√©r√©e avec succ√®s par distillation !\")\n",
    "            break\n",
    "        elif current_ber==0.0 and a<1 :\n",
    "            a+=1\n",
    "        else:\n",
    "            a=0\n",
    "\n",
    "    return student_unet, history\n",
    "\n"
   ],
   "id": "5954c8e14899f901",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "start_time": "2026-02-11T15:00:02.957315063Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 3. Attaque par Distillation\n",
    "student_res, stats = run_distillation_attack_uchida(uchida_defense, dataloader, epochs=1000)\n",
    "\n"
   ],
   "id": "e3c8d63d0b7e6775",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot initialize model with low cpu memory usage because `accelerate` was not found in the environment. Defaulting to `low_cpu_mem_usage=False`. It is strongly recommended to install `accelerate` for faster and less memory-intense model loading. You can do so with: \n",
      "```\n",
      "pip install accelerate\n",
      "```\n",
      ".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Initialisation du Student ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...:   0%|          | 0/2 [00:00<?, ?it/s]An error occurred while trying to fetch /home/latim/.cache/huggingface/hub/models--google--ddpm-cifar10-32/snapshots/267b167dc01f0e4e61923ea244e8b988f84deb80: Error no file named diffusion_pytorch_model.safetensors found in directory /home/latim/.cache/huggingface/hub/models--google--ddpm-cifar10-32/snapshots/267b167dc01f0e4e61923ea244e8b988f84deb80.\n",
      "Defaulting to unsafe serialization. Pass `allow_pickle=False` to raise an error instead.\n",
      "Loading pipeline components...: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00, 73.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait : 0.00\n",
      "BER Extrait : 0.53\n",
      "[Check] BER Teacher: 0.00\n",
      "[Check] BER Student (Avant): 0.53\n",
      "\n",
      "--- Distillation Uchida (1000 epochs) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 391/391 [01:21<00:00,  4.81it/s, Loss=0.000109]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait : 0.53\n",
      "üëâ Fin Epoch 1 | Loss: 0.0001 | BER Student: 0.53 | err_wat: 0.7818479537963867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 391/391 [01:22<00:00,  4.75it/s, Loss=7.04e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait : 0.53\n",
      "üëâ Fin Epoch 2 | Loss: 0.0001 | BER Student: 0.53 | err_wat: 0.7786175012588501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 391/391 [01:22<00:00,  4.73it/s, Loss=5.74e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait : 0.53\n",
      "üëâ Fin Epoch 3 | Loss: 0.0001 | BER Student: 0.53 | err_wat: 0.7744326591491699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 391/391 [01:22<00:00,  4.74it/s, Loss=4.05e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait : 0.53\n",
      "üëâ Fin Epoch 4 | Loss: 0.0000 | BER Student: 0.53 | err_wat: 0.7705144882202148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 391/391 [01:22<00:00,  4.72it/s, Loss=4.85e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait : 0.52\n",
      "üëâ Fin Epoch 5 | Loss: 0.0000 | BER Student: 0.52 | err_wat: 0.7658535838127136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 391/391 [01:22<00:00,  4.71it/s, Loss=4.44e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait : 0.52\n",
      "üëâ Fin Epoch 6 | Loss: 0.0000 | BER Student: 0.52 | err_wat: 0.7618365287780762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 391/391 [01:22<00:00,  4.73it/s, Loss=2.05e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait : 0.52\n",
      "üëâ Fin Epoch 7 | Loss: 0.0000 | BER Student: 0.52 | err_wat: 0.7574461698532104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 391/391 [01:22<00:00,  4.73it/s, Loss=3.82e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait : 0.52\n",
      "üëâ Fin Epoch 8 | Loss: 0.0000 | BER Student: 0.52 | err_wat: 0.7530932426452637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 391/391 [01:22<00:00,  4.75it/s, Loss=2.29e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait : 0.52\n",
      "üëâ Fin Epoch 9 | Loss: 0.0000 | BER Student: 0.52 | err_wat: 0.7484822273254395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 391/391 [01:22<00:00,  4.74it/s, Loss=2.85e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait : 0.52\n",
      "üëâ Fin Epoch 10 | Loss: 0.0000 | BER Student: 0.52 | err_wat: 0.7443736791610718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 391/391 [01:22<00:00,  4.74it/s, Loss=2.29e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait : 0.52\n",
      "üëâ Fin Epoch 11 | Loss: 0.0000 | BER Student: 0.52 | err_wat: 0.7405425906181335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 391/391 [01:22<00:00,  4.74it/s, Loss=3.79e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait : 0.52\n",
      "üëâ Fin Epoch 12 | Loss: 0.0000 | BER Student: 0.52 | err_wat: 0.7364248037338257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 391/391 [01:22<00:00,  4.73it/s, Loss=2.53e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait : 0.52\n",
      "üëâ Fin Epoch 13 | Loss: 0.0000 | BER Student: 0.52 | err_wat: 0.7318887114524841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 391/391 [01:22<00:00,  4.73it/s, Loss=2.63e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait : 0.52\n",
      "üëâ Fin Epoch 14 | Loss: 0.0000 | BER Student: 0.52 | err_wat: 0.7273105382919312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 391/391 [01:22<00:00,  4.74it/s, Loss=2.95e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait : 0.52\n",
      "üëâ Fin Epoch 15 | Loss: 0.0000 | BER Student: 0.52 | err_wat: 0.7236353754997253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 391/391 [01:22<00:00,  4.73it/s, Loss=3.65e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait : 0.52\n",
      "üëâ Fin Epoch 16 | Loss: 0.0000 | BER Student: 0.52 | err_wat: 0.7198149561882019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 391/391 [01:22<00:00,  4.74it/s, Loss=3.45e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait : 0.52\n",
      "üëâ Fin Epoch 17 | Loss: 0.0000 | BER Student: 0.52 | err_wat: 0.7157938480377197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 391/391 [01:22<00:00,  4.74it/s, Loss=3.44e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait : 0.52\n",
      "üëâ Fin Epoch 18 | Loss: 0.0000 | BER Student: 0.52 | err_wat: 0.712149977684021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 391/391 [01:22<00:00,  4.74it/s, Loss=2.04e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait : 0.52\n",
      "üëâ Fin Epoch 19 | Loss: 0.0000 | BER Student: 0.52 | err_wat: 0.7085870504379272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 391/391 [01:22<00:00,  4.74it/s, Loss=3.03e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait : 0.52\n",
      "üëâ Fin Epoch 20 | Loss: 0.0000 | BER Student: 0.52 | err_wat: 0.7046852111816406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 391/391 [01:22<00:00,  4.74it/s, Loss=3.04e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait : 0.52\n",
      "üëâ Fin Epoch 21 | Loss: 0.0000 | BER Student: 0.52 | err_wat: 0.7009975910186768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 391/391 [01:22<00:00,  4.73it/s, Loss=2.67e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait : 0.52\n",
      "üëâ Fin Epoch 22 | Loss: 0.0000 | BER Student: 0.52 | err_wat: 0.6973212957382202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 391/391 [01:22<00:00,  4.73it/s, Loss=3.12e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait : 0.52\n",
      "üëâ Fin Epoch 23 | Loss: 0.0000 | BER Student: 0.52 | err_wat: 0.6936590671539307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 391/391 [01:22<00:00,  4.73it/s, Loss=2.21e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait : 0.50\n",
      "üëâ Fin Epoch 24 | Loss: 0.0000 | BER Student: 0.50 | err_wat: 0.6902252435684204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 391/391 [01:22<00:00,  4.73it/s, Loss=4.63e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait : 0.50\n",
      "üëâ Fin Epoch 25 | Loss: 0.0000 | BER Student: 0.50 | err_wat: 0.6868228912353516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 391/391 [01:22<00:00,  4.74it/s, Loss=2.74e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait : 0.48\n",
      "üëâ Fin Epoch 26 | Loss: 0.0000 | BER Student: 0.48 | err_wat: 0.6831111907958984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 391/391 [01:22<00:00,  4.73it/s, Loss=3.97e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait : 0.48\n",
      "üëâ Fin Epoch 27 | Loss: 0.0000 | BER Student: 0.48 | err_wat: 0.6798273324966431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 391/391 [01:22<00:00,  4.76it/s, Loss=3.88e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait : 0.48\n",
      "üëâ Fin Epoch 28 | Loss: 0.0000 | BER Student: 0.48 | err_wat: 0.6761911511421204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 391/391 [01:21<00:00,  4.79it/s, Loss=3.08e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait : 0.48\n",
      "üëâ Fin Epoch 29 | Loss: 0.0000 | BER Student: 0.48 | err_wat: 0.6728768944740295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 391/391 [01:23<00:00,  4.70it/s, Loss=2.62e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait : 0.48\n",
      "üëâ Fin Epoch 30 | Loss: 0.0000 | BER Student: 0.48 | err_wat: 0.6694651246070862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 391/391 [01:24<00:00,  4.65it/s, Loss=2.72e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait : 0.48\n",
      "üëâ Fin Epoch 31 | Loss: 0.0000 | BER Student: 0.48 | err_wat: 0.6660390496253967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 391/391 [01:23<00:00,  4.70it/s, Loss=2.35e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait : 0.48\n",
      "üëâ Fin Epoch 32 | Loss: 0.0000 | BER Student: 0.48 | err_wat: 0.6630026698112488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 391/391 [01:23<00:00,  4.67it/s, Loss=5.27e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait : 0.48\n",
      "üëâ Fin Epoch 33 | Loss: 0.0001 | BER Student: 0.48 | err_wat: 0.6598191261291504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 391/391 [01:23<00:00,  4.67it/s, Loss=2.34e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait : 0.48\n",
      "üëâ Fin Epoch 34 | Loss: 0.0000 | BER Student: 0.48 | err_wat: 0.656674861907959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 391/391 [01:23<00:00,  4.66it/s, Loss=2.9e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait : 0.48\n",
      "üëâ Fin Epoch 35 | Loss: 0.0000 | BER Student: 0.48 | err_wat: 0.6540521383285522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 391/391 [01:23<00:00,  4.68it/s, Loss=2.78e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait : 0.45\n",
      "üëâ Fin Epoch 36 | Loss: 0.0000 | BER Student: 0.45 | err_wat: 0.651576817035675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 391/391 [01:23<00:00,  4.66it/s, Loss=2.96e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait : 0.45\n",
      "üëâ Fin Epoch 37 | Loss: 0.0000 | BER Student: 0.45 | err_wat: 0.6484321355819702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 391/391 [01:23<00:00,  4.69it/s, Loss=5.95e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait : 0.45\n",
      "üëâ Fin Epoch 38 | Loss: 0.0001 | BER Student: 0.45 | err_wat: 0.6454893350601196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 391/391 [01:23<00:00,  4.67it/s, Loss=2.45e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait : 0.45\n",
      "üëâ Fin Epoch 39 | Loss: 0.0000 | BER Student: 0.45 | err_wat: 0.6429237127304077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 391/391 [01:23<00:00,  4.67it/s, Loss=1.72e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait : 0.45\n",
      "üëâ Fin Epoch 40 | Loss: 0.0000 | BER Student: 0.45 | err_wat: 0.6403641104698181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 391/391 [01:24<00:00,  4.64it/s, Loss=3.43e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait : 0.45\n",
      "üëâ Fin Epoch 41 | Loss: 0.0000 | BER Student: 0.45 | err_wat: 0.6374017000198364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 391/391 [01:24<00:00,  4.65it/s, Loss=2.71e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait : 0.44\n",
      "üëâ Fin Epoch 42 | Loss: 0.0000 | BER Student: 0.44 | err_wat: 0.6351116895675659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 391/391 [01:23<00:00,  4.70it/s, Loss=2.65e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait : 0.42\n",
      "üëâ Fin Epoch 43 | Loss: 0.0000 | BER Student: 0.42 | err_wat: 0.632575273513794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 391/391 [01:23<00:00,  4.67it/s, Loss=2.07e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait : 0.42\n",
      "üëâ Fin Epoch 44 | Loss: 0.0000 | BER Student: 0.42 | err_wat: 0.6299071311950684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 391/391 [01:24<00:00,  4.64it/s, Loss=3.21e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait : 0.42\n",
      "üëâ Fin Epoch 45 | Loss: 0.0000 | BER Student: 0.42 | err_wat: 0.6269549131393433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 391/391 [01:24<00:00,  4.62it/s, Loss=4.1e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait : 0.41\n",
      "üëâ Fin Epoch 46 | Loss: 0.0000 | BER Student: 0.41 | err_wat: 0.6242820620536804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 391/391 [01:22<00:00,  4.72it/s, Loss=2.52e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait : 0.39\n",
      "üëâ Fin Epoch 47 | Loss: 0.0000 | BER Student: 0.39 | err_wat: 0.6216495037078857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 245/391 [00:52<00:32,  4.55it/s, Loss=3.53e-5]"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "3288268ed4c7a798"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
