{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-02T12:55:05.779093458Z",
     "start_time": "2026-02-02T12:55:05.729376834Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from diffusers import DDPMPipeline, DDPMScheduler, UNet2DModel\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "from torch.optim import AdamW\n",
    "\n",
    "# --- MappingNet (EncResistant) ---\n",
    "\n",
    "class EncResistantDDPM(nn.Module):\n",
    "    \"\"\"Mapping network that projects weights to watermark space.\"\"\"\n",
    "    def __init__(self, weight_size, watermark_len, expansion_factor=2):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(weight_size, 100, bias=True)\n",
    "        self.fc2 = nn.Linear(100, expansion_factor * weight_size, bias=True)\n",
    "        self.sig = nn.Sigmoid()\n",
    "        self.tanh = nn.Tanh()\n",
    "        # Secret projection matrix\n",
    "        self.register_buffer(\n",
    "            \"matrix_a\",\n",
    "            torch.randn(weight_size * expansion_factor, watermark_len)\n",
    "        )\n",
    "\n",
    "    def forward(self, theta_f):\n",
    "        out = self.fc1(theta_f)\n",
    "        out = self.tanh(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.tanh(out)\n",
    "        out = self.sig(out @ self.matrix_a)\n",
    "        return out\n",
    "\n",
    "\n",
    "# --- Classe Principale Res_Encrypt ---\n",
    "\n",
    "class ResEncryptDDPM:\n",
    "    def __init__(self, model_id, device=\"cuda\"):\n",
    "        self.device = device\n",
    "        self.model_id = model_id\n",
    "\n",
    "        # Chargement du modele\n",
    "        self.pipeline = DDPMPipeline.from_pretrained(model_id)\n",
    "        self.unet = self.pipeline.unet.to(device)\n",
    "        self.scheduler = self.pipeline.scheduler\n",
    "\n",
    "        # Configuration par defaut\n",
    "        self.config = {\n",
    "            \"layer_name\": \"mid_block.resnets.0.conv1.weight\",  # Couche cible\n",
    "            \"watermark_len\": 32,\n",
    "            \"expansion_factor\": 10,\n",
    "            \"lr\": 1e-4,\n",
    "            \"lr_mn\": 1e-3,  # Learning rate for MappingNet\n",
    "            \"lambda_1\": 1.0,   # Watermark loss weight\n",
    "            \"lambda_2\": 0.1,   # Original watermark loss weight\n",
    "            \"lambda_3\": 0.001, # L1 regularization weight\n",
    "            \"epochs\": 30,\n",
    "        }\n",
    "\n",
    "        self.saved_keys = {}\n",
    "\n",
    "    def _get_target_weights(self, model):\n",
    "        \"\"\"Recupere le tenseur des poids de la couche cible.\"\"\"\n",
    "        for name, param in model.named_parameters():\n",
    "            if name == self.config[\"layer_name\"]:\n",
    "                return param\n",
    "        raise ValueError(f\"Parametre {self.config['layer_name']} introuvable.\")\n",
    "\n",
    "    def _get_mean(self, weights):\n",
    "        \"\"\"Compute mean based on layer type.\"\"\"\n",
    "        if len(weights.shape) == 4:  # Conv layer\n",
    "            return weights.mean(dim=(0, 1))\n",
    "        elif len(weights.shape) == 2:  # Linear layer\n",
    "            return weights.mean(dim=0)\n",
    "        else:\n",
    "            raise NotImplementedError(\"Layer type not supported\")\n",
    "\n",
    "    def embed(self, dataloader):\n",
    "        \"\"\"\n",
    "        Incorpore la marque Res_Encrypt pendant le finetuning.\n",
    "        Utilise un MappingNet pour projeter les poids vers l'espace du watermark.\n",
    "        \"\"\"\n",
    "        print(f\"--- Demarrage Embedding Res_Encrypt ({self.config['layer_name']}) ---\")\n",
    "\n",
    "        # 1. Preparation des modeles\n",
    "        original_unet = deepcopy(self.unet)\n",
    "        original_unet.eval()\n",
    "        for p in original_unet.parameters():\n",
    "            p.requires_grad = False\n",
    "\n",
    "        watermarked_unet = self.unet\n",
    "        watermarked_unet.train()\n",
    "\n",
    "        # 2. Generation des Cles\n",
    "        target_weights = self._get_target_weights(watermarked_unet)\n",
    "        with torch.no_grad():\n",
    "            theta_f = torch.flatten(self._get_mean(target_weights))\n",
    "            weight_size = len(theta_f)\n",
    "\n",
    "        print(f\"Dimension vecteur poids : {weight_size} | Watermark : {self.config['watermark_len']} bits\")\n",
    "\n",
    "        # Watermarks\n",
    "        watermark_target = torch.randint(0, 2, (self.config[\"watermark_len\"],)).float().to(self.device)\n",
    "        watermark_random = torch.randint(0, 2, (self.config[\"watermark_len\"],)).float().to(self.device)\n",
    "\n",
    "        # MappingNet\n",
    "        mapping_net = EncResistantDDPM(\n",
    "            weight_size,\n",
    "            self.config[\"watermark_len\"],\n",
    "            self.config[\"expansion_factor\"]\n",
    "        ).to(self.device)\n",
    "\n",
    "        # Original weights (frozen)\n",
    "        orig_weights = self._get_target_weights(original_unet)\n",
    "        theta_fn = torch.flatten(self._get_mean(orig_weights)).detach()\n",
    "\n",
    "        # 3. Optimiseur (UNet + MappingNet)\n",
    "        optimizer = torch.optim.AdamW([\n",
    "            {'params': watermarked_unet.parameters(), 'lr': self.config[\"lr\"]},\n",
    "            {'params': mapping_net.parameters(), 'lr': self.config[\"lr_mn\"]}\n",
    "        ])\n",
    "\n",
    "        mse_loss = nn.MSELoss()\n",
    "        bce_loss = nn.BCELoss()\n",
    "\n",
    "        # 4. Boucle d'entrainement\n",
    "        for epoch in range(self.config[\"epochs\"]):\n",
    "            pbar = tqdm(dataloader)\n",
    "            for clean_images, _ in pbar:\n",
    "                clean_images = clean_images.to(self.device)\n",
    "                bs = clean_images.shape[0]\n",
    "\n",
    "                # A. Processus de Diffusion (Forward)\n",
    "                noise = torch.randn_like(clean_images).to(self.device)\n",
    "                timesteps = torch.randint(0, self.scheduler.config.num_train_timesteps, (bs,), device=self.device).long()\n",
    "                noisy_images = self.scheduler.add_noise(clean_images, noise, timesteps)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # B. Prediction (Task Loss)\n",
    "                noise_pred = watermarked_unet(noisy_images, timesteps).sample\n",
    "                l_main = mse_loss(noise_pred, noise)\n",
    "\n",
    "                # C. Watermark Losses (Res_Encrypt)\n",
    "                current_weights = self._get_target_weights(watermarked_unet)\n",
    "                theta_f = torch.flatten(self._get_mean(current_weights))\n",
    "\n",
    "                # Projection via MappingNet\n",
    "                matrix_g = mapping_net(theta_f.unsqueeze(0)).squeeze(0)\n",
    "                matrix_gn = mapping_net(theta_fn.unsqueeze(0)).squeeze(0)\n",
    "\n",
    "                # Loss: watermarked model -> target watermark\n",
    "                l_wat = bce_loss(matrix_g, watermark_target)\n",
    "                # Loss: original model -> random watermark (discriminative)\n",
    "                l_wat_orig = bce_loss(matrix_gn, watermark_random)\n",
    "                # L1 regularization on weights\n",
    "                l_l1_w = torch.norm(theta_f, p=1)\n",
    "\n",
    "                # Loss Totale\n",
    "                l_total = (l_main +\n",
    "                          self.config[\"lambda_1\"] * l_wat +\n",
    "                          self.config[\"lambda_2\"] * l_wat_orig +\n",
    "                          self.config[\"lambda_3\"] * l_l1_w)\n",
    "\n",
    "                l_total.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                # Metrics\n",
    "                ber = self._compute_ber(matrix_g, watermark_target)\n",
    "                pbar.set_description(\n",
    "                    f\"Epoch {epoch+1} | L_Main: {l_main:.3f} | L_Wat: {l_wat:.3f} | \"\n",
    "                    f\"L_Orig: {l_wat_orig:.3f} | BER: {ber:.2f}\"\n",
    "                )\n",
    "\n",
    "                # if ber == 0.0 and l_wat.item() < 0.01:\n",
    "                #     print(\"Convergence atteinte !\")\n",
    "                #     break\n",
    "            # if ber == 0.0:\n",
    "            #     break\n",
    "\n",
    "        # Sauvegarde des cles\n",
    "        self.saved_keys = {\n",
    "            \"watermark_target\": watermark_target,\n",
    "            \"watermarked_unet\": watermarked_unet,\n",
    "            \"mapping_net\": mapping_net,\n",
    "            \"original_unet\": original_unet,\n",
    "        }\n",
    "        return watermarked_unet\n",
    "\n",
    "    def extract(self, suspect_unet=None):\n",
    "        \"\"\"\n",
    "        Extrait la marque d'un modele suspect via le MappingNet.\n",
    "        \"\"\"\n",
    "        if suspect_unet is None:\n",
    "            suspect_unet = self.saved_keys[\"watermarked_unet\"]\n",
    "\n",
    "        mapping_net = self.saved_keys[\"mapping_net\"]\n",
    "        watermark_target = self.saved_keys[\"watermark_target\"]\n",
    "\n",
    "        mapping_net.eval()\n",
    "\n",
    "        # 1. Recuperation des poids\n",
    "        try:\n",
    "            target_weights = self._get_target_weights(suspect_unet)\n",
    "        except ValueError:\n",
    "            print(\"Couche cible introuvable dans le modele suspect.\")\n",
    "            return 1.0, None\n",
    "\n",
    "        # 2. Projection via MappingNet\n",
    "        with torch.no_grad():\n",
    "            theta_f = torch.flatten(self._get_mean(target_weights))\n",
    "            pred_wm_prob = mapping_net(theta_f.unsqueeze(0)).squeeze(0)\n",
    "            ber = self._compute_ber(pred_wm_prob, watermark_target)\n",
    "\n",
    "        print(f\"BER Extrait : {ber:.2f}\")\n",
    "        return ber, pred_wm_prob\n",
    "\n",
    "    @staticmethod\n",
    "    def _compute_ber(pred, target):\n",
    "        return ((pred > 0.5).float() != target).float().mean().item()\n"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "embedding_cell",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-02T14:04:53.279650274Z",
     "start_time": "2026-02-02T12:55:05.780018606Z"
    }
   },
   "source": [
    "# --- EXEMPLE D'EXECUTION ---\n",
    "\n",
    "# 1. Setup Data\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# 2. Embedding Res_Encrypt\n",
    "res_encrypt_defense = ResEncryptDDPM(\"google/ddpm-cifar10-32\")\n",
    "watermarked_model = res_encrypt_defense.embed(dataloader)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "extraction_cell",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-02T14:04:53.376022618Z",
     "start_time": "2026-02-02T14:04:53.324978664Z"
    }
   },
   "source": [
    "# 3. Extraction (Test immediat)\n",
    "ber, _ = res_encrypt_defense.extract(watermarked_model)\n",
    "print(f\"\\nResultat final - BER: {ber:.2f}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait : 0.00\n",
      "\n",
      "Resultat final - BER: 0.00\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "id": "distillation_attack_cell",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-03T13:23:04.354598928Z",
     "start_time": "2026-02-03T13:23:04.339356719Z"
    }
   },
   "source": [
    "# --- Fonction de Distillation (Attaque) ---\n",
    "\n",
    "def run_distillation_attack_res_encrypt(res_obj, dataloader, epochs=5, lr=1e-4):\n",
    "    \"\"\"\n",
    "    Tente de transferer la fonctionnalite du modele Res_Encrypt vers un modele vierge.\n",
    "    Verifie si la marque (basee sur les poids + MappingNet) survit.\n",
    "    \"\"\"\n",
    "    device = res_obj.device\n",
    "\n",
    "    # 1. Teacher (Gele)\n",
    "    teacher_unet = res_obj.saved_keys[\"watermarked_unet\"]\n",
    "    teacher_unet.eval()\n",
    "    for p in teacher_unet.parameters():\n",
    "        p.requires_grad = False\n",
    "\n",
    "    # 2. Student (Vierge - Meme architecture)\n",
    "    print(\"\\n--- Initialisation du Student ---\")\n",
    "    student_pipeline = DDPMPipeline.from_pretrained(\"google/ddpm-cifar10-32\")\n",
    "    student_unet = student_pipeline.unet.to(device)\n",
    "    student_unet.train()\n",
    "\n",
    "    teacher_ber, _ = res_obj.extract(teacher_unet)\n",
    "    student_ber, _ = res_obj.extract(student_unet)\n",
    "    # Sanity Checks\n",
    "    print(f\"[Check] BER Teacher: {teacher_ber:.2f}\")\n",
    "    print(f\"[Check] BER Student (Avant): {student_ber:.2f}\")\n",
    "\n",
    "    optimizer = AdamW(student_unet.parameters(), lr=lr)\n",
    "    noise_scheduler = res_obj.scheduler\n",
    "    history = {\"loss\": [], \"ber\": []}\n",
    "\n",
    "    print(f\"\\n--- Distillation Res_Encrypt ({epochs} epochs) ---\")\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        pbar = tqdm(dataloader, desc=f\"Epoch {epoch+1}\")\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for clean_images, _ in pbar:\n",
    "            clean_images = clean_images.to(device)\n",
    "            bs = clean_images.shape[0]\n",
    "\n",
    "            # A. Input Noise\n",
    "            noise = torch.randn_like(clean_images).to(device)\n",
    "            timesteps = torch.randint(0, noise_scheduler.config.num_train_timesteps, (bs,), device=device).long()\n",
    "            noisy_images = noise_scheduler.add_noise(clean_images, noise, timesteps)\n",
    "\n",
    "            # B. Distillation (Output Matching)\n",
    "            with torch.no_grad():\n",
    "                target_pred = teacher_unet(noisy_images, timesteps).sample\n",
    "\n",
    "            student_pred = student_unet(noisy_images, timesteps).sample\n",
    "\n",
    "            loss = F.mse_loss(student_pred, target_pred)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            pbar.set_postfix(Loss=loss.item())\n",
    "\n",
    "        # C. Verification : Est-ce que les poids se sont alignes ?\n",
    "        current_ber, pred_wm_prob = res_obj.extract(student_unet)\n",
    "        history[\"ber\"].append(current_ber)\n",
    "        history[\"loss\"].append(running_loss / len(dataloader))\n",
    "\n",
    "        err_wat = nn.BCELoss()(pred_wm_prob, res_obj.saved_keys[\"watermark_target\"]) if pred_wm_prob is not None else float('nan')\n",
    "        print(f\"Fin Epoch {epoch+1} | Loss: {history['loss'][-1]:.4f} | BER Student: {current_ber:.2f} | err_wat: {err_wat:.4f}\")\n",
    "\n",
    "    return student_unet, history\n"
   ],
   "outputs": [],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "id": "run_attack_cell",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-04T08:28:20.286317343Z",
     "start_time": "2026-02-03T13:23:05.284992114Z"
    }
   },
   "source": [
    "# 4. Attaque par Distillation\n",
    "student_res, stats = run_distillation_attack_res_encrypt(res_encrypt_defense, dataloader, epochs=1000)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 241:  68%|██████▊   | 528/782 [01:47<00:51,  4.97it/s, Loss=0.000124]"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "plot_results_cell",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-04T08:28:24.379809392Z",
     "start_time": "2026-02-04T08:28:24.193119931Z"
    }
   },
   "source": [
    "# 5. Visualisation des resultats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "ax1.plot(stats[\"loss\"])\n",
    "ax1.set_xlabel(\"Epoch\")\n",
    "ax1.set_ylabel(\"Loss\")\n",
    "ax1.set_title(\"Distillation Loss\")\n",
    "\n",
    "ax2.plot(stats[\"ber\"])\n",
    "ax2.axhline(y=0.5, color='r', linestyle='--', label='Random (0.5)')\n",
    "ax2.set_xlabel(\"Epoch\")\n",
    "ax2.set_ylabel(\"BER\")\n",
    "ax2.set_title(\"BER Evolution During Distillation\")\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 1
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
