{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-04T08:52:51.490793316Z",
     "start_time": "2026-02-04T08:52:37.668300425Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from diffusers import DDPMPipeline, DDPMScheduler, UNet2DModel\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "from torch.optim import AdamW\n",
    "from torch.distributions import Laplace\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# --- Classe Principale Laplacian DDPM ---\n",
    "\n",
    "class LaplacianDDPM:\n",
    "    def __init__(self, model_id, device=\"cuda\"):\n",
    "        self.device = device\n",
    "        self.model_id = model_id\n",
    "\n",
    "        # Chargement du mod√®le\n",
    "        self.pipeline = DDPMPipeline.from_pretrained(model_id)\n",
    "        self.unet = self.pipeline.unet.to(device)\n",
    "        self.scheduler = self.pipeline.scheduler\n",
    "\n",
    "        # Configuration par d√©faut\n",
    "        self.config = {\n",
    "            \"layer_name\": \"mid_block.resnets.0.conv1.weight\",  # Couche cible\n",
    "            \"watermark_size\": 32,       # Nombre de bits du watermark\n",
    "            \"spreading_factor\": 10,     # Facteur d'√©talement (S)\n",
    "            \"variance\": 1,            # Variance pour la distribution Laplacienne\n",
    "            \"lr\": 1e-4,\n",
    "            \"epochs\": 30\n",
    "        }\n",
    "\n",
    "        self.saved_keys = {}\n",
    "\n",
    "    def _get_target_layer(self, model):\n",
    "        \"\"\"R√©cup√®re le tenseur des poids de la couche cible.\"\"\"\n",
    "        for name, param in model.named_parameters():\n",
    "            if name == self.config[\"layer_name\"]:\n",
    "                return param\n",
    "        raise ValueError(f\"Param√®tre {self.config['layer_name']} introuvable.\")\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_rand_bits(size):\n",
    "        \"\"\"G√©n√®re une s√©quence binaire al√©atoire.\"\"\"\n",
    "        return [random.randint(0, 1) for _ in range(size)]\n",
    "\n",
    "    def keygen(self, watermark_size):\n",
    "        \"\"\"\n",
    "        G√©n√®re le watermark et les signes correspondants.\n",
    "        Returns:\n",
    "            wat_signs: Watermark en {-1, +1}\n",
    "            watermark: Watermark binaire en {0, 1}\n",
    "        \"\"\"\n",
    "        watermark = torch.tensor(self._get_rand_bits(watermark_size)).float().to(self.device)\n",
    "        wat_signs = torch.tensor([-1.0 if i == 0 else 1.0 for i in watermark], dtype=torch.float).to(self.device)\n",
    "        return wat_signs, watermark\n",
    "\n",
    "    def generate_laplacian_pseudo_sequence(self, s, l, loc=0.0, scale=1.0, seed=None):\n",
    "        \"\"\"\n",
    "        G√©n√®re une s√©quence pseudo-al√©atoire avec distribution Laplacienne.\n",
    "        \n",
    "        Args:\n",
    "            s: Spreading factor\n",
    "            l: Taille du watermark\n",
    "            loc: Param√®tre de localisation (moyenne)\n",
    "            scale: Param√®tre d'√©chelle (diversit√©)\n",
    "            seed: Graine al√©atoire pour la reproductibilit√©\n",
    "        \n",
    "        Returns:\n",
    "            torch.Tensor: S√©quence pseudo de taille (s * l,)\n",
    "        \"\"\"\n",
    "        if seed is not None:\n",
    "            torch.manual_seed(seed)\n",
    "            np.random.seed(seed)\n",
    "\n",
    "        total_size = s * l\n",
    "        laplace_dist = Laplace(loc=torch.tensor(loc), scale=torch.tensor(scale))\n",
    "        pseudo_seq = laplace_dist.sample((total_size,)).to(self.device)\n",
    "        \n",
    "        return pseudo_seq\n",
    "\n",
    "    def generate_weight_sequence(self, watermark_signs, pseudo_seq, S):\n",
    "        \"\"\"\n",
    "        G√©n√®re la s√©quence de poids avec le facteur d'√©talement S.\n",
    "        wm_j = u_i ¬∑ s_j\n",
    "        \"\"\"\n",
    "        l = len(watermark_signs)\n",
    "        n = len(pseudo_seq)\n",
    "\n",
    "        if n < l * S:\n",
    "            raise ValueError(f\"Spreading sequence length ({n}) must be >= l*S ({l * S})\")\n",
    "\n",
    "        weight_seq = torch.zeros(l * S, dtype=torch.float32).to(self.device)\n",
    "\n",
    "        for i in range(1, l + 1):\n",
    "            start_idx = (i - 1) * S\n",
    "            end_idx = i * S\n",
    "\n",
    "            for j in range(start_idx, end_idx):\n",
    "                weight_seq[j] = watermark_signs[i - 1] * pseudo_seq[j]\n",
    "\n",
    "        return weight_seq\n",
    "\n",
    "    def replace_weights(self, model, weight_sequence, selected_indices=None):\n",
    "        \"\"\"\n",
    "        Remplace les poids s√©lectionn√©s avec les valeurs du watermark.\n",
    "        \"\"\"\n",
    "        n = len(weight_sequence)\n",
    "        target_layer = self._get_target_layer(model)\n",
    "        \n",
    "        weight_tensor = target_layer.data\n",
    "        original_shape = weight_tensor.shape\n",
    "        flat_weights = weight_tensor.flatten()\n",
    "        total_weights = flat_weights.numel()\n",
    "\n",
    "        if n > total_weights:\n",
    "            raise ValueError(f\"Sequence length {n} exceeds total weights {total_weights}\")\n",
    "\n",
    "        if selected_indices is None:\n",
    "            selected_indices = random.sample(range(total_weights), n)\n",
    "\n",
    "        for i, idx in enumerate(selected_indices):\n",
    "            flat_weights[idx] = weight_sequence[i]\n",
    "\n",
    "        target_layer.data = flat_weights.reshape(original_shape)\n",
    "        return selected_indices\n",
    "\n",
    "    def pick_weights_by_indices(self, model, selected_indices):\n",
    "        \"\"\"\n",
    "        Extrait les poids s√©lectionn√©s d'une couche.\n",
    "        \"\"\"\n",
    "        target_layer = self._get_target_layer(model)\n",
    "        flat_weights = target_layer.data.flatten()\n",
    "        selected_weights = flat_weights[selected_indices]\n",
    "        return selected_weights\n",
    "\n",
    "    def calculate_watermark_bits(self, selected_weights, spreading_sequence, S):\n",
    "        \"\"\"\n",
    "        Calcule les bits du watermark √† partir des poids extraits.\n",
    "        \"\"\"\n",
    "        watermark_length = len(spreading_sequence) // S\n",
    "\n",
    "        if len(spreading_sequence) != watermark_length * S:\n",
    "            raise ValueError(f\"Spreading sequence length must be divisible by S\")\n",
    "\n",
    "        watermark_bits = torch.zeros(watermark_length, dtype=torch.float32).to(self.device)\n",
    "        correlation_sums = torch.zeros(watermark_length, dtype=torch.float32).to(self.device)\n",
    "\n",
    "        for i in range(1, watermark_length + 1):\n",
    "            start_idx = (i - 1) * S\n",
    "            end_idx = i * S\n",
    "\n",
    "            s_slice = spreading_sequence[start_idx:end_idx]\n",
    "            w_slice = selected_weights[start_idx:end_idx]\n",
    "\n",
    "            correlation_sum = torch.sum(s_slice * w_slice)\n",
    "            correlation_sums[i - 1] = correlation_sum\n",
    "\n",
    "            bit_value = 1.0 if correlation_sum >= 0 else 0.0\n",
    "            watermark_bits[i - 1] = bit_value\n",
    "\n",
    "        return watermark_bits, correlation_sums\n",
    "\n",
    "    @staticmethod\n",
    "    def _compute_ber(extracted, target):\n",
    "        \"\"\"Calcule le Bit Error Rate.\"\"\"\n",
    "        return (extracted != target).float().mean().item()\n",
    "\n",
    "    def embed(self, dataloader):\n",
    "        \"\"\"\n",
    "        Incorpore le watermark Laplacien pendant le finetuning.\n",
    "        \"\"\"\n",
    "        print(f\"--- D√©marrage Embedding LAPLACIAN ({self.config['layer_name']}) ---\")\n",
    "        print(f\"Watermark size: {self.config['watermark_size']} bits\")\n",
    "        print(f\"Spreading factor: {self.config['spreading_factor']}\")\n",
    "\n",
    "        watermarked_unet = self.unet\n",
    "        watermarked_unet.train()\n",
    "\n",
    "        # 1. G√©n√©ration des cl√©s\n",
    "        watermark_signs, watermark = self.keygen(self.config[\"watermark_size\"])\n",
    "        \n",
    "        # Calcul de gamma (scale parameter)\n",
    "        gamma = self.config[\"variance\"] / np.sqrt(2)\n",
    "        \n",
    "        # G√©n√©ration de la s√©quence pseudo-al√©atoire Laplacienne\n",
    "        pseudo_seq = self.generate_laplacian_pseudo_sequence(\n",
    "            s=self.config['spreading_factor'],\n",
    "            l=self.config['watermark_size'],\n",
    "            loc=0.0,\n",
    "            scale=gamma\n",
    "        )\n",
    "        \n",
    "        # G√©n√©ration de la s√©quence de poids\n",
    "        weight_seq = self.generate_weight_sequence(\n",
    "            watermark_signs=watermark_signs,\n",
    "            pseudo_seq=pseudo_seq,\n",
    "            S=self.config['spreading_factor']\n",
    "        )\n",
    "        \n",
    "        print(f\"Weight sequence length: {len(weight_seq)}\")\n",
    "\n",
    "        # 2. Remplacement initial des poids\n",
    "        selected_indices = self.replace_weights(watermarked_unet, weight_seq)\n",
    "        print(f\"Selected {len(selected_indices)} weight positions\")\n",
    "\n",
    "        # 3. Optimiseur\n",
    "        optimizer = torch.optim.AdamW(watermarked_unet.parameters(), lr=self.config[\"lr\"])\n",
    "        mse_loss = nn.MSELoss()\n",
    "\n",
    "        # 4. Boucle d'entra√Ænement\n",
    "        for epoch in range(self.config[\"epochs\"]):\n",
    "            pbar = tqdm(dataloader, desc=f\"Epoch {epoch+1}/{self.config['epochs']}\")\n",
    "            \n",
    "            for clean_images, _ in pbar:\n",
    "                clean_images = clean_images.to(self.device)\n",
    "                bs = clean_images.shape[0]\n",
    "\n",
    "                # A. Processus de Diffusion (Forward)\n",
    "                noise = torch.randn_like(clean_images).to(self.device)\n",
    "                timesteps = torch.randint(\n",
    "                    0, self.scheduler.config.num_train_timesteps, \n",
    "                    (bs,), device=self.device\n",
    "                ).long()\n",
    "                noisy_images = self.scheduler.add_noise(clean_images, noise, timesteps)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # B. Pr√©diction (Task Loss)\n",
    "                noise_pred = watermarked_unet(noisy_images, timesteps).sample\n",
    "                l_main = mse_loss(noise_pred, noise)\n",
    "\n",
    "                l_main.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                # C. Re-application du watermark (freeze weights)\n",
    "                self.replace_weights(\n",
    "                    model=watermarked_unet,\n",
    "                    weight_sequence=weight_seq,\n",
    "                    selected_indices=selected_indices\n",
    "                )\n",
    "\n",
    "                # D. Calcul du BER\n",
    "                extracted_weights = self.pick_weights_by_indices(watermarked_unet, selected_indices)\n",
    "                extracted_wm, _ = self.calculate_watermark_bits(\n",
    "                    extracted_weights, pseudo_seq, self.config['spreading_factor']\n",
    "                )\n",
    "                ber = self._compute_ber(extracted_wm, watermark)\n",
    "\n",
    "                pbar.set_postfix(L_Main=f\"{l_main.item():.4f}\", BER=f\"{ber:.4f}\")\n",
    "\n",
    "        # Sauvegarde des cl√©s\n",
    "        self.saved_keys = {\n",
    "            \"watermark\": watermark,\n",
    "            \"watermark_signs\": watermark_signs,\n",
    "            \"pseudo_seq\": pseudo_seq,\n",
    "            \"weight_seq\": weight_seq,\n",
    "            \"selected_indices\": selected_indices,\n",
    "            \"watermarked_unet\": watermarked_unet\n",
    "        }\n",
    "        \n",
    "        print(f\"\\n‚úÖ Embedding termin√©! BER final: {ber:.4f}\")\n",
    "        return watermarked_unet\n",
    "\n",
    "    def extract(self, suspect_unet=None):\n",
    "        \"\"\"\n",
    "        Extrait le watermark d'un mod√®le suspect.\n",
    "        \"\"\"\n",
    "        if suspect_unet is None:\n",
    "            suspect_unet = self.saved_keys[\"watermarked_unet\"]\n",
    "\n",
    "        watermark = self.saved_keys[\"watermark\"]\n",
    "        pseudo_seq = self.saved_keys[\"pseudo_seq\"]\n",
    "        selected_indices = self.saved_keys[\"selected_indices\"]\n",
    "\n",
    "        # 1. Extraction des poids\n",
    "        try:\n",
    "            extracted_weights = self.pick_weights_by_indices(suspect_unet, selected_indices)\n",
    "        except ValueError:\n",
    "            print(\"‚ö†Ô∏è Couche cible introuvable dans le mod√®le suspect.\")\n",
    "            return 1.0, None\n",
    "\n",
    "        # 2. Calcul du watermark extrait\n",
    "        extracted_wm, correlation_sums = self.calculate_watermark_bits(\n",
    "            extracted_weights, pseudo_seq, self.config['spreading_factor']\n",
    "        )\n",
    "\n",
    "        # 3. Calcul du BER\n",
    "        ber = self._compute_ber(extracted_wm, watermark)\n",
    "\n",
    "        print(f\"BER Extrait: {ber:.4f}\")\n",
    "        return ber, extracted_wm\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/latim/PycharmProjects/WatDNN/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "setup_data",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-04T09:24:24.391937012Z",
     "start_time": "2026-02-04T08:52:51.531262778Z"
    }
   },
   "source": [
    "# --- EXEMPLE D'EX√âCUTION ---\n",
    "\n",
    "# 1. Setup Data\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(), \n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# 2. Embedding Laplacian\n",
    "laplacian_defense = LaplacianDDPM(\"google/ddpm-cifar10-32\")\n",
    "\n",
    "# Configuration optionnelle\n",
    "laplacian_defense.config.update({\n",
    "    \"watermark_size\": 32,\n",
    "    \"spreading_factor\": 10,\n",
    "    \"variance\": 1, #0.025277,\n",
    "    \"epochs\": 30,\n",
    "    \"lr\": 1e-4\n",
    "})\n",
    "\n",
    "watermarked_model = laplacian_defense.embed(dataloader)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot initialize model with low cpu memory usage because `accelerate` was not found in the environment. Defaulting to `low_cpu_mem_usage=False`. It is strongly recommended to install `accelerate` for faster and less memory-intense model loading. You can do so with: \n",
      "```\n",
      "pip install accelerate\n",
      "```\n",
      ".\n",
      "Loading pipeline components...:   0%|          | 0/2 [00:00<?, ?it/s]An error occurred while trying to fetch /home/latim/.cache/huggingface/hub/models--google--ddpm-cifar10-32/snapshots/267b167dc01f0e4e61923ea244e8b988f84deb80: Error no file named diffusion_pytorch_model.safetensors found in directory /home/latim/.cache/huggingface/hub/models--google--ddpm-cifar10-32/snapshots/267b167dc01f0e4e61923ea244e8b988f84deb80.\n",
      "Defaulting to unsafe serialization. Pass `allow_pickle=False` to raise an error instead.\n",
      "Loading pipeline components...: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00,  2.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- D√©marrage Embedding LAPLACIAN (mid_block.resnets.0.conv1.weight) ---\n",
      "Watermark size: 32 bits\n",
      "Spreading factor: 10\n",
      "Weight sequence length: 320\n",
      "Selected 320 weight positions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/30: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:05<00:00, 12.03it/s, BER=0.0000, L_Main=0.0294]\n",
      "Epoch 2/30: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:02<00:00, 12.55it/s, BER=0.0000, L_Main=0.0498]\n",
      "Epoch 3/30: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:02<00:00, 12.61it/s, BER=0.0000, L_Main=0.0076]\n",
      "Epoch 4/30: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:02<00:00, 12.42it/s, BER=0.0000, L_Main=0.0169]\n",
      "Epoch 5/30: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:03<00:00, 12.40it/s, BER=0.0000, L_Main=0.0240]\n",
      "Epoch 6/30: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:03<00:00, 12.41it/s, BER=0.0000, L_Main=0.0112]\n",
      "Epoch 7/30: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:02<00:00, 12.42it/s, BER=0.0000, L_Main=0.0161]\n",
      "Epoch 8/30: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:02<00:00, 12.45it/s, BER=0.0000, L_Main=0.0296]\n",
      "Epoch 9/30: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:03<00:00, 12.37it/s, BER=0.0000, L_Main=0.0210]\n",
      "Epoch 10/30: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:03<00:00, 12.38it/s, BER=0.0000, L_Main=0.0233]\n",
      "Epoch 11/30: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:03<00:00, 12.41it/s, BER=0.0000, L_Main=0.0121]\n",
      "Epoch 12/30: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:03<00:00, 12.39it/s, BER=0.0000, L_Main=0.0325]\n",
      "Epoch 13/30: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:02<00:00, 12.46it/s, BER=0.0000, L_Main=0.0570]\n",
      "Epoch 14/30: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:02<00:00, 12.48it/s, BER=0.0000, L_Main=0.0218]\n",
      "Epoch 15/30: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:02<00:00, 12.51it/s, BER=0.0000, L_Main=0.0509]\n",
      "Epoch 16/30: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:02<00:00, 12.48it/s, BER=0.0000, L_Main=0.0196]\n",
      "Epoch 17/30: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:02<00:00, 12.48it/s, BER=0.0000, L_Main=0.0371]\n",
      "Epoch 18/30: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:02<00:00, 12.53it/s, BER=0.0000, L_Main=0.0125]\n",
      "Epoch 19/30: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:02<00:00, 12.47it/s, BER=0.0000, L_Main=0.0535]\n",
      "Epoch 20/30: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:02<00:00, 12.56it/s, BER=0.0000, L_Main=0.0253]\n",
      "Epoch 21/30: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:02<00:00, 12.46it/s, BER=0.0000, L_Main=0.0663]\n",
      "Epoch 22/30: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:03<00:00, 12.38it/s, BER=0.0000, L_Main=0.0348]\n",
      "Epoch 23/30: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:02<00:00, 12.46it/s, BER=0.0000, L_Main=0.0229]\n",
      "Epoch 24/30: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:03<00:00, 12.38it/s, BER=0.0000, L_Main=0.0072]\n",
      "Epoch 25/30: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:03<00:00, 12.41it/s, BER=0.0000, L_Main=0.0136]\n",
      "Epoch 26/30: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:03<00:00, 12.41it/s, BER=0.0000, L_Main=0.0137]\n",
      "Epoch 27/30: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:03<00:00, 12.29it/s, BER=0.0000, L_Main=0.0166]\n",
      "Epoch 28/30: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:03<00:00, 12.30it/s, BER=0.0000, L_Main=0.0232]\n",
      "Epoch 29/30: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:02<00:00, 12.42it/s, BER=0.0000, L_Main=0.0221]\n",
      "Epoch 30/30: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:03<00:00, 12.40it/s, BER=0.0000, L_Main=0.0309]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Embedding termin√©! BER final: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "extraction_test",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-04T09:24:24.553406858Z",
     "start_time": "2026-02-04T09:24:24.416827330Z"
    }
   },
   "source": [
    "# 3. Test d'extraction sur le mod√®le watermark√©\n",
    "print(\"\\n--- Test Extraction sur mod√®le watermark√© ---\")\n",
    "ber, extracted_wm = laplacian_defense.extract()\n",
    "print(f\"Watermark original: {laplacian_defense.saved_keys['watermark'][:10]}...\")\n",
    "print(f\"Watermark extrait:  {extracted_wm[:10]}...\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Test Extraction sur mod√®le watermark√© ---\n",
      "BER Extrait: 0.0000\n",
      "Watermark original: tensor([0., 1., 1., 0., 0., 1., 1., 0., 0., 1.], device='cuda:0')...\n",
      "Watermark extrait:  tensor([0., 1., 1., 0., 0., 1., 1., 0., 0., 1.], device='cuda:0')...\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "distillation_attack",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-04T09:24:24.614352706Z",
     "start_time": "2026-02-04T09:24:24.566150155Z"
    }
   },
   "source": [
    "# --- Fonction de Distillation (Attaque) ---\n",
    "\n",
    "def run_distillation_attack_laplacian(laplacian_obj, dataloader, epochs=5, lr=1e-4):\n",
    "    \"\"\"\n",
    "    Tente de transf√©rer la fonctionnalit√© du mod√®le Laplacian vers un mod√®le vierge.\n",
    "    V√©rifie si la marque (bas√©e sur les poids) survit.\n",
    "    \"\"\"\n",
    "    device = laplacian_obj.device\n",
    "\n",
    "    # 1. Teacher (Gel√©)\n",
    "    teacher_unet = laplacian_obj.saved_keys[\"watermarked_unet\"]\n",
    "    teacher_unet.eval()\n",
    "    for p in teacher_unet.parameters():\n",
    "        p.requires_grad = False\n",
    "\n",
    "    # 2. Student (Vierge - M√™me architecture)\n",
    "    print(\"\\n--- Initialisation du Student ---\")\n",
    "    student_pipeline = DDPMPipeline.from_pretrained(\"google/ddpm-cifar10-32\")\n",
    "    student_unet = student_pipeline.unet.to(device)\n",
    "    student_unet.train()\n",
    "\n",
    "    # Sanity Checks\n",
    "    teacher_ber, _ = laplacian_obj.extract(teacher_unet)\n",
    "    student_ber, _ = laplacian_obj.extract(student_unet)\n",
    "    print(f\"[Check] BER Teacher: {teacher_ber:.4f}\")\n",
    "    print(f\"[Check] BER Student (Avant): {student_ber:.4f}\")\n",
    "\n",
    "    optimizer = AdamW(student_unet.parameters(), lr=lr)\n",
    "    noise_scheduler = laplacian_obj.scheduler\n",
    "    history = {\"loss\": [], \"ber\": []}\n",
    "\n",
    "    print(f\"\\n--- Distillation Laplacian ({epochs} epochs) ---\")\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        pbar = tqdm(dataloader, desc=f\"Epoch {epoch+1}\")\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for clean_images, _ in pbar:\n",
    "            clean_images = clean_images.to(device)\n",
    "            bs = clean_images.shape[0]\n",
    "\n",
    "            # A. Input Noise\n",
    "            noise = torch.randn_like(clean_images).to(device)\n",
    "            timesteps = torch.randint(\n",
    "                0, noise_scheduler.config.num_train_timesteps, \n",
    "                (bs,), device=device\n",
    "            ).long()\n",
    "            noisy_images = noise_scheduler.add_noise(clean_images, noise, timesteps)\n",
    "\n",
    "            # B. Distillation (Output Matching)\n",
    "            with torch.no_grad():\n",
    "                target_pred = teacher_unet(noisy_images, timesteps).sample\n",
    "\n",
    "            student_pred = student_unet(noisy_images, timesteps).sample\n",
    "\n",
    "            loss = F.mse_loss(student_pred, target_pred)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            pbar.set_postfix(Loss=loss.item())\n",
    "\n",
    "        # C. V√©rification du BER apr√®s chaque epoch\n",
    "        current_ber, _ = laplacian_obj.extract(student_unet)\n",
    "        history[\"ber\"].append(current_ber)\n",
    "        history[\"loss\"].append(running_loss / len(dataloader))\n",
    "\n",
    "        print(f\"üëâ Fin Epoch {epoch+1} | Loss: {loss.item():.4f} | BER Student: {current_ber:.4f}\")\n",
    "\n",
    "    return student_unet, history"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "run_attack",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2026-02-04T09:24:24.615669226Z"
    }
   },
   "source": [
    "# 4. Attaque par Distillation\n",
    "student_model, attack_stats = run_distillation_attack_laplacian(\n",
    "    laplacian_defense, \n",
    "    dataloader, \n",
    "    epochs=1000\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot initialize model with low cpu memory usage because `accelerate` was not found in the environment. Defaulting to `low_cpu_mem_usage=False`. It is strongly recommended to install `accelerate` for faster and less memory-intense model loading. You can do so with: \n",
      "```\n",
      "pip install accelerate\n",
      "```\n",
      ".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Initialisation du Student ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...:   0%|          | 0/2 [00:00<?, ?it/s]An error occurred while trying to fetch /home/latim/.cache/huggingface/hub/models--google--ddpm-cifar10-32/snapshots/267b167dc01f0e4e61923ea244e8b988f84deb80: Error no file named diffusion_pytorch_model.safetensors found in directory /home/latim/.cache/huggingface/hub/models--google--ddpm-cifar10-32/snapshots/267b167dc01f0e4e61923ea244e8b988f84deb80.\n",
      "Defaulting to unsafe serialization. Pass `allow_pickle=False` to raise an error instead.\n",
      "Loading pipeline components...: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00, 21.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait: 0.0000\n",
      "BER Extrait: 0.3750\n",
      "[Check] BER Teacher: 0.0000\n",
      "[Check] BER Student (Avant): 0.3750\n",
      "\n",
      "--- Distillation Laplacian (1000 epochs) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:18<00:00, 10.01it/s, Loss=0.000204]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait: 0.3750\n",
      "üëâ Fin Epoch 1 | Loss: 0.0002 | BER Student: 0.3750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:17<00:00, 10.10it/s, Loss=0.0003]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait: 0.3750\n",
      "üëâ Fin Epoch 2 | Loss: 0.0003 | BER Student: 0.3750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:17<00:00, 10.09it/s, Loss=0.000204]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait: 0.3438\n",
      "üëâ Fin Epoch 3 | Loss: 0.0002 | BER Student: 0.3438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:17<00:00, 10.12it/s, Loss=0.000132]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait: 0.3438\n",
      "üëâ Fin Epoch 4 | Loss: 0.0001 | BER Student: 0.3438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:17<00:00, 10.06it/s, Loss=0.000146]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait: 0.3438\n",
      "üëâ Fin Epoch 5 | Loss: 0.0001 | BER Student: 0.3438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:17<00:00, 10.12it/s, Loss=7.68e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait: 0.3438\n",
      "üëâ Fin Epoch 6 | Loss: 0.0001 | BER Student: 0.3438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:17<00:00, 10.08it/s, Loss=0.000155]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait: 0.3125\n",
      "üëâ Fin Epoch 7 | Loss: 0.0002 | BER Student: 0.3125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:17<00:00, 10.07it/s, Loss=0.000112]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait: 0.2812\n",
      "üëâ Fin Epoch 8 | Loss: 0.0001 | BER Student: 0.2812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:17<00:00, 10.06it/s, Loss=0.000131]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait: 0.2812\n",
      "üëâ Fin Epoch 9 | Loss: 0.0001 | BER Student: 0.2812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:17<00:00, 10.08it/s, Loss=7.26e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait: 0.2500\n",
      "üëâ Fin Epoch 10 | Loss: 0.0001 | BER Student: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:16<00:00, 10.16it/s, Loss=0.000161]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait: 0.1875\n",
      "üëâ Fin Epoch 11 | Loss: 0.0002 | BER Student: 0.1875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:17<00:00, 10.09it/s, Loss=8.99e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait: 0.1250\n",
      "üëâ Fin Epoch 12 | Loss: 0.0001 | BER Student: 0.1250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:17<00:00, 10.09it/s, Loss=0.000155]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait: 0.1250\n",
      "üëâ Fin Epoch 13 | Loss: 0.0002 | BER Student: 0.1250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:17<00:00, 10.09it/s, Loss=7.36e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait: 0.1250\n",
      "üëâ Fin Epoch 14 | Loss: 0.0001 | BER Student: 0.1250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:17<00:00, 10.10it/s, Loss=8.85e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait: 0.1250\n",
      "üëâ Fin Epoch 15 | Loss: 0.0001 | BER Student: 0.1250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:17<00:00, 10.10it/s, Loss=0.000166]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait: 0.1250\n",
      "üëâ Fin Epoch 16 | Loss: 0.0002 | BER Student: 0.1250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:17<00:00, 10.09it/s, Loss=7.37e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait: 0.0938\n",
      "üëâ Fin Epoch 17 | Loss: 0.0001 | BER Student: 0.0938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:17<00:00, 10.05it/s, Loss=7.03e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait: 0.0938\n",
      "üëâ Fin Epoch 18 | Loss: 0.0001 | BER Student: 0.0938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:17<00:00, 10.07it/s, Loss=8.14e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait: 0.0938\n",
      "üëâ Fin Epoch 19 | Loss: 0.0001 | BER Student: 0.0938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:17<00:00, 10.07it/s, Loss=8.8e-5]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait: 0.0938\n",
      "üëâ Fin Epoch 20 | Loss: 0.0001 | BER Student: 0.0938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:17<00:00, 10.05it/s, Loss=7.24e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait: 0.0938\n",
      "üëâ Fin Epoch 21 | Loss: 0.0001 | BER Student: 0.0938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:17<00:00, 10.10it/s, Loss=0.000115]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait: 0.0938\n",
      "üëâ Fin Epoch 22 | Loss: 0.0001 | BER Student: 0.0938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:17<00:00, 10.04it/s, Loss=6.05e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait: 0.0938\n",
      "üëâ Fin Epoch 23 | Loss: 0.0001 | BER Student: 0.0938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:17<00:00, 10.07it/s, Loss=3.76e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait: 0.0938\n",
      "üëâ Fin Epoch 24 | Loss: 0.0000 | BER Student: 0.0938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:17<00:00, 10.06it/s, Loss=3.77e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait: 0.0938\n",
      "üëâ Fin Epoch 25 | Loss: 0.0000 | BER Student: 0.0938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:17<00:00, 10.07it/s, Loss=6.15e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait: 0.0938\n",
      "üëâ Fin Epoch 26 | Loss: 0.0001 | BER Student: 0.0938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:17<00:00, 10.05it/s, Loss=9.37e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait: 0.0625\n",
      "üëâ Fin Epoch 27 | Loss: 0.0001 | BER Student: 0.0625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:17<00:00, 10.04it/s, Loss=3.43e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait: 0.0625\n",
      "üëâ Fin Epoch 28 | Loss: 0.0000 | BER Student: 0.0625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:17<00:00, 10.04it/s, Loss=0.00012] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait: 0.0312\n",
      "üëâ Fin Epoch 29 | Loss: 0.0001 | BER Student: 0.0312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:17<00:00, 10.04it/s, Loss=8.27e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait: 0.0312\n",
      "üëâ Fin Epoch 30 | Loss: 0.0001 | BER Student: 0.0312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:17<00:00, 10.07it/s, Loss=5.92e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait: 0.0312\n",
      "üëâ Fin Epoch 31 | Loss: 0.0001 | BER Student: 0.0312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:17<00:00, 10.05it/s, Loss=0.000164]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait: 0.0312\n",
      "üëâ Fin Epoch 32 | Loss: 0.0002 | BER Student: 0.0312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:17<00:00, 10.04it/s, Loss=6.64e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait: 0.0312\n",
      "üëâ Fin Epoch 33 | Loss: 0.0001 | BER Student: 0.0312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:17<00:00, 10.05it/s, Loss=7.67e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait: 0.0312\n",
      "üëâ Fin Epoch 34 | Loss: 0.0001 | BER Student: 0.0312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:17<00:00, 10.06it/s, Loss=5.84e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait: 0.0312\n",
      "üëâ Fin Epoch 35 | Loss: 0.0001 | BER Student: 0.0312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:17<00:00, 10.03it/s, Loss=8.54e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait: 0.0312\n",
      "üëâ Fin Epoch 36 | Loss: 0.0001 | BER Student: 0.0312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:17<00:00, 10.04it/s, Loss=8.36e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait: 0.0312\n",
      "üëâ Fin Epoch 37 | Loss: 0.0001 | BER Student: 0.0312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:17<00:00, 10.03it/s, Loss=5.66e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait: 0.0312\n",
      "üëâ Fin Epoch 38 | Loss: 0.0001 | BER Student: 0.0312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:17<00:00, 10.06it/s, Loss=0.0001]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait: 0.0312\n",
      "üëâ Fin Epoch 39 | Loss: 0.0001 | BER Student: 0.0312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:17<00:00, 10.05it/s, Loss=3.37e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait: 0.0312\n",
      "üëâ Fin Epoch 40 | Loss: 0.0000 | BER Student: 0.0312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:17<00:00, 10.04it/s, Loss=8.12e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait: 0.0312\n",
      "üëâ Fin Epoch 41 | Loss: 0.0001 | BER Student: 0.0312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:24<00:00,  9.23it/s, Loss=3.49e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait: 0.0312\n",
      "üëâ Fin Epoch 42 | Loss: 0.0000 | BER Student: 0.0312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:28<00:00,  8.80it/s, Loss=7.2e-5]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait: 0.0312\n",
      "üëâ Fin Epoch 43 | Loss: 0.0001 | BER Student: 0.0312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:29<00:00,  8.77it/s, Loss=7.25e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait: 0.0312\n",
      "üëâ Fin Epoch 44 | Loss: 0.0001 | BER Student: 0.0312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:29<00:00,  8.75it/s, Loss=8.58e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait: 0.0312\n",
      "üëâ Fin Epoch 45 | Loss: 0.0001 | BER Student: 0.0312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:30<00:00,  8.68it/s, Loss=6.35e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait: 0.0312\n",
      "üëâ Fin Epoch 46 | Loss: 0.0001 | BER Student: 0.0312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:31<00:00,  8.54it/s, Loss=4.47e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait: 0.0312\n",
      "üëâ Fin Epoch 47 | Loss: 0.0000 | BER Student: 0.0312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:33<00:00,  8.38it/s, Loss=6.48e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait: 0.0312\n",
      "üëâ Fin Epoch 48 | Loss: 0.0001 | BER Student: 0.0312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49:   9%|‚ñä         | 68/782 [00:08<01:21,  8.72it/s, Loss=5.73e-5] "
     ]
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "plot_results",
   "metadata": {},
   "source": [
    "# 5. Visualisation des r√©sultats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# BER over epochs\n",
    "axes[0].plot(attack_stats[\"ber\"], marker='o')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('BER')\n",
    "axes[0].set_title('BER Evolution During Distillation Attack')\n",
    "axes[0].axhline(y=0.5, color='r', linestyle='--', label='Random guess (0.5)')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True)\n",
    "\n",
    "# Loss over epochs\n",
    "axes[1].plot(attack_stats[\"loss\"], marker='s', color='orange')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Loss')\n",
    "axes[1].set_title('Distillation Loss Over Epochs')\n",
    "axes[1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "final_comparison",
   "metadata": {},
   "source": [
    "# 6. Comparaison finale\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"R√âSUM√â FINAL\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "teacher_ber, _ = laplacian_defense.extract(laplacian_defense.saved_keys[\"watermarked_unet\"])\n",
    "student_ber, _ = laplacian_defense.extract(student_model)\n",
    "\n",
    "print(f\"\\nBER Teacher (watermark√©): {teacher_ber:.4f}\")\n",
    "print(f\"BER Student (apr√®s distillation): {student_ber:.4f}\")\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "SqlCellData": {
     "variableName$1": "df_sql1"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "%%sql\n",
   "id": "9336bfadaccfbe27"
  },
  {
   "metadata": {
    "SqlCellData": {
     "variableName$1": "df_sql2"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "%%sql\n",
   "id": "5d7c90bec3ed3e8c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
