{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-28T12:00:39.927618467Z",
     "start_time": "2026-01-28T12:00:38.138543302Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from diffusers import DDPMPipeline, DDPMScheduler, UNet2DModel\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "from torch.optim import AdamW\n",
    "\n",
    "# --- Classe Principale STDM ---\n",
    "\n",
    "class StdmDDPM:\n",
    "    def __init__(self, model_id, device=\"cuda\"):\n",
    "        self.device = device\n",
    "        self.model_id = model_id\n",
    "\n",
    "        # Chargement du modele\n",
    "        self.pipeline = DDPMPipeline.from_pretrained(model_id)\n",
    "        self.unet = self.pipeline.unet.to(device)\n",
    "        self.scheduler = self.pipeline.scheduler\n",
    "\n",
    "        # Configuration par defaut\n",
    "        self.config = {\n",
    "            \"layer_name\": \"mid_block.resnets.0.conv1.weight\",  # Couche cible\n",
    "            \"watermark_len\": 64,\n",
    "            \"lr\": 1e-4,\n",
    "            \"lambda_wat\": 1.0,\n",
    "            \"epochs\": 5,\n",
    "            \"alpha\": 10.0,  # Parametre STDM\n",
    "            \"beta\": 0.1,    # Parametre STDM\n",
    "        }\n",
    "\n",
    "        self.saved_keys = {}\n",
    "\n",
    "    def _get_target_weights(self, model):\n",
    "        \"\"\"Recupere le tenseur des poids de la couche cible.\"\"\"\n",
    "        for name, param in model.named_parameters():\n",
    "            if name == self.config[\"layer_name\"]:\n",
    "                return param\n",
    "        raise ValueError(f\"Parametre {self.config['layer_name']} introuvable.\")\n",
    "\n",
    "    @staticmethod\n",
    "    def _theta(x, alpha_, beta_):\n",
    "        \"\"\"Fonction theta de STDM.\"\"\"\n",
    "        numerator = torch.exp(alpha_ * torch.sin(torch.tensor(beta_) * x))\n",
    "        denominator = 1 + torch.exp(alpha_ * torch.sin(torch.tensor(beta_) * x))\n",
    "        return numerator / denominator\n",
    "\n",
    "    def embed(self, dataloader):\n",
    "        \"\"\"\n",
    "        Incorpore la marque STDM (Spread Transform Dither Modulation) pendant le finetuning.\n",
    "        \"\"\"\n",
    "        print(f\"--- Demarrage Embedding STDM ({self.config['layer_name']}) ---\")\n",
    "\n",
    "        watermarked_unet = self.unet\n",
    "        watermarked_unet.train()\n",
    "\n",
    "        # 1. Generation des Cles (Matrice A normalisee L2 et Watermark binaire)\n",
    "        target_weights = self._get_target_weights(watermarked_unet)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            w_flat_dim = torch.flatten(target_weights.mean(dim=0)).shape[0]\n",
    "\n",
    "        print(f\"Dimension vecteur poids : {w_flat_dim} | Watermark : {self.config['watermark_len']} bits\")\n",
    "\n",
    "        # Matrice A normalisee L2 sur les colonnes (specifique STDM)\n",
    "        matrix_a = torch.randn(w_flat_dim, self.config[\"watermark_len\"]).to(self.device)\n",
    "        matrix_a = F.normalize(matrix_a, p=2, dim=0)\n",
    "\n",
    "        watermark_target = torch.randint(0, 2, (self.config[\"watermark_len\"],)).float().to(self.device)\n",
    "\n",
    "        # 2. Optimiseur\n",
    "        optimizer = torch.optim.AdamW(watermarked_unet.parameters(), lr=self.config[\"lr\"])\n",
    "        mse_loss = nn.MSELoss()\n",
    "        bce_loss = nn.BCELoss()\n",
    "\n",
    "        alpha_ = self.config[\"alpha\"]\n",
    "        beta_ = self.config[\"beta\"]\n",
    "\n",
    "        # 3. Boucle d'entrainement\n",
    "        for epoch in range(self.config[\"epochs\"]):\n",
    "            pbar = tqdm(dataloader)\n",
    "            for clean_images, _ in pbar:\n",
    "                clean_images = clean_images.to(self.device)\n",
    "                bs = clean_images.shape[0]\n",
    "\n",
    "                # A. Processus de Diffusion (Forward)\n",
    "                noise = torch.randn_like(clean_images).to(self.device)\n",
    "                timesteps = torch.randint(0, self.scheduler.config.num_train_timesteps, (bs,), device=self.device).long()\n",
    "                noisy_images = self.scheduler.add_noise(clean_images, noise, timesteps)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # B. Prediction (Task Loss)\n",
    "                noise_pred = watermarked_unet(noisy_images, timesteps).sample\n",
    "                l_main = mse_loss(noise_pred, noise)\n",
    "\n",
    "                # C. Watermark Loss (STDM avec fonction theta)\n",
    "                current_weights = self._get_target_weights(watermarked_unet)\n",
    "                w_flat = torch.flatten(current_weights.mean(dim=0))\n",
    "\n",
    "                # Projection avec fonction theta (specifique STDM)\n",
    "                pred_wm_prob = self._theta(w_flat @ matrix_a, alpha_, beta_)\n",
    "                l_wat = bce_loss(pred_wm_prob, watermark_target)\n",
    "\n",
    "                # Loss Totale\n",
    "                l_total = l_main + self.config[\"lambda_wat\"] * l_wat\n",
    "\n",
    "                l_total.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                # Metrics\n",
    "                ber = self._compute_ber(pred_wm_prob, watermark_target)\n",
    "                pbar.set_description(f\"Epoch {epoch+1} | L_Main: {l_main:.3f} | L_Wat: {l_wat:.3f} | BER: {ber:.2f}\")\n",
    "\n",
    "                if ber == 0.0 and l_wat.item() < 0.01:\n",
    "                    print(\"Convergence atteinte !\")\n",
    "                    break\n",
    "            if ber == 0.0:\n",
    "                break\n",
    "\n",
    "        # Sauvegarde des cles\n",
    "        self.saved_keys = {\n",
    "            \"matrix_a\": matrix_a,\n",
    "            \"watermark_target\": watermark_target,\n",
    "            \"watermarked_unet\": watermarked_unet,\n",
    "            \"alpha\": alpha_,\n",
    "            \"beta\": beta_,\n",
    "        }\n",
    "        return watermarked_unet\n",
    "\n",
    "    def extract(self, suspect_unet=None):\n",
    "        \"\"\"\n",
    "        Extrait la marque d'un modele suspect (lecture des poids).\n",
    "        \"\"\"\n",
    "        if suspect_unet is None:\n",
    "            suspect_unet = self.saved_keys[\"watermarked_unet\"]\n",
    "\n",
    "        matrix_a = self.saved_keys[\"matrix_a\"]\n",
    "        watermark_target = self.saved_keys[\"watermark_target\"]\n",
    "        alpha_ = self.saved_keys[\"alpha\"]\n",
    "        beta_ = self.saved_keys[\"beta\"]\n",
    "\n",
    "        # 1. Recuperation des poids\n",
    "        try:\n",
    "            target_weights = self._get_target_weights(suspect_unet)\n",
    "        except ValueError:\n",
    "            print(\"Couche cible introuvable dans le modele suspect.\")\n",
    "            return 1.0, None  # BER max\n",
    "\n",
    "        # 2. Projection avec theta\n",
    "        with torch.no_grad():\n",
    "            w_flat = torch.flatten(target_weights.mean(dim=0))\n",
    "            pred_wm_prob = self._theta(w_flat @ matrix_a, alpha_, beta_)\n",
    "\n",
    "            ber = self._compute_ber(pred_wm_prob, watermark_target)\n",
    "\n",
    "        print(f\"BER Extrait : {ber:.2f}\")\n",
    "        return ber, pred_wm_prob\n",
    "\n",
    "    @staticmethod\n",
    "    def _compute_ber(pred, target):\n",
    "        return ((pred > 0.5).float() != target).float().mean().item()\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "embedding_cell",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-28T12:01:57.714672283Z",
     "start_time": "2026-01-28T12:00:42.524927311Z"
    }
   },
   "source": [
    "# --- EXEMPLE D'EXECUTION ---\n",
    "\n",
    "# 1. Setup Data\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# 2. Embedding STDM\n",
    "stdm_defense = StdmDDPM(\"google/ddpm-cifar10-32\")\n",
    "watermarked_model = stdm_defense.embed(dataloader)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/2 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bfc3c8c9c9ed41519eedade9a8a10396"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "An error occurred while trying to fetch /home/carbure/.cache/huggingface/hub/models--google--ddpm-cifar10-32/snapshots/267b167dc01f0e4e61923ea244e8b988f84deb80: Error no file named diffusion_pytorch_model.safetensors found in directory /home/carbure/.cache/huggingface/hub/models--google--ddpm-cifar10-32/snapshots/267b167dc01f0e4e61923ea244e8b988f84deb80.\n",
      "Defaulting to unsafe serialization. Pass `allow_pickle=False` to raise an error instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Demarrage Embedding STDM (mid_block.resnets.0.conv1.weight) ---\n",
      "Dimension vecteur poids : 2304 | Watermark : 64 bits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 | L_Main: 0.019 | L_Wat: 0.532 | BER: 0.00: 100%|██████████| 782/782 [01:14<00:00, 10.55it/s]\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "extraction_cell",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-28T12:02:34.372568372Z",
     "start_time": "2026-01-28T12:02:34.304011891Z"
    }
   },
   "source": [
    "# 3. Extraction (Test immediat)\n",
    "ber, _ = stdm_defense.extract(watermarked_model)\n",
    "print(f\"\\nResultat final - BER: {ber:.2f}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait : 0.00\n",
      "\n",
      "Resultat final - BER: 0.00\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "distillation_attack_cell",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-28T12:02:38.147653521Z",
     "start_time": "2026-01-28T12:02:38.099035357Z"
    }
   },
   "source": [
    "# --- Fonction de Distillation (Attaque) ---\n",
    "\n",
    "def run_distillation_attack_stdm(stdm_obj, dataloader, epochs=5, lr=1e-4):\n",
    "    \"\"\"\n",
    "    Tente de transferer la fonctionnalite du modele STDM vers un modele vierge.\n",
    "    Verifie si la marque (basee sur les poids) survit.\n",
    "    \"\"\"\n",
    "    device = stdm_obj.device\n",
    "\n",
    "    # 1. Teacher (Gele)\n",
    "    teacher_unet = stdm_obj.saved_keys[\"watermarked_unet\"]\n",
    "    teacher_unet.eval()\n",
    "    for p in teacher_unet.parameters():\n",
    "        p.requires_grad = False\n",
    "\n",
    "    # 2. Student (Vierge - Meme architecture)\n",
    "    print(\"\\n--- Initialisation du Student ---\")\n",
    "    student_pipeline = DDPMPipeline.from_pretrained(\"google/ddpm-cifar10-32\")\n",
    "    student_unet = student_pipeline.unet.to(device)\n",
    "    student_unet.train()\n",
    "\n",
    "    teacher_ber, _ = stdm_obj.extract(teacher_unet)\n",
    "    student_ber, _ = stdm_obj.extract(student_unet)\n",
    "    # Sanity Checks\n",
    "    print(f\"[Check] BER Teacher: {teacher_ber:.2f}\")\n",
    "    print(f\"[Check] BER Student (Avant): {student_ber:.2f}\")\n",
    "\n",
    "    optimizer = AdamW(student_unet.parameters(), lr=lr)\n",
    "    noise_scheduler = stdm_obj.scheduler\n",
    "    history = {\"loss\": [], \"ber\": []}\n",
    "\n",
    "    print(f\"\\n--- Distillation STDM ({epochs} epochs) ---\")\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        pbar = tqdm(dataloader, desc=f\"Epoch {epoch+1}\")\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for clean_images, _ in pbar:\n",
    "            clean_images = clean_images.to(device)\n",
    "            bs = clean_images.shape[0]\n",
    "\n",
    "            # A. Input Noise\n",
    "            noise = torch.randn_like(clean_images).to(device)\n",
    "            timesteps = torch.randint(0, noise_scheduler.config.num_train_timesteps, (bs,), device=device).long()\n",
    "            noisy_images = noise_scheduler.add_noise(clean_images, noise, timesteps)\n",
    "\n",
    "            # B. Distillation (Output Matching)\n",
    "            with torch.no_grad():\n",
    "                target_pred = teacher_unet(noisy_images, timesteps).sample\n",
    "\n",
    "            student_pred = student_unet(noisy_images, timesteps).sample\n",
    "\n",
    "            loss = F.mse_loss(student_pred, target_pred)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            pbar.set_postfix(Loss=loss.item())\n",
    "\n",
    "        # C. Verification : Est-ce que les poids se sont alignes sur STDM ?\n",
    "        current_ber, pred_wm_prob = stdm_obj.extract(student_unet)\n",
    "        history[\"ber\"].append(current_ber)\n",
    "        history[\"loss\"].append(running_loss / len(dataloader))\n",
    "\n",
    "        err_wat = nn.BCELoss()(pred_wm_prob, stdm_obj.saved_keys[\"watermark_target\"]) if pred_wm_prob is not None else float('nan')\n",
    "        print(f\"Fin Epoch {epoch+1} | Loss: {history['loss'][-1]:.4f} | BER Student: {current_ber:.2f} | err_wat: {err_wat:.4f}\")\n",
    "\n",
    "    return student_unet, history\n"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "run_attack_cell",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-28T12:57:58.251268414Z",
     "start_time": "2026-01-28T12:02:42.738642668Z"
    }
   },
   "source": [
    "# 4. Attaque par Distillation\n",
    "student_res, stats = run_distillation_attack_stdm(stdm_defense, dataloader, epochs=100)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Initialisation du Student ---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/2 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "be65c93d2dde4e5989404724ae07f924"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "An error occurred while trying to fetch /home/carbure/.cache/huggingface/hub/models--google--ddpm-cifar10-32/snapshots/267b167dc01f0e4e61923ea244e8b988f84deb80: Error no file named diffusion_pytorch_model.safetensors found in directory /home/carbure/.cache/huggingface/hub/models--google--ddpm-cifar10-32/snapshots/267b167dc01f0e4e61923ea244e8b988f84deb80.\n",
      "Defaulting to unsafe serialization. Pass `allow_pickle=False` to raise an error instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait : 0.00\n",
      "BER Extrait : 0.58\n",
      "[Check] BER Teacher: 0.00\n",
      "[Check] BER Student (Avant): 0.58\n",
      "\n",
      "--- Distillation STDM (100 epochs) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 782/782 [01:31<00:00,  8.56it/s, Loss=6e-5]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait : 0.55\n",
      "Fin Epoch 1 | Loss: 0.0001 | BER Student: 0.55 | err_wat: 0.6941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 782/782 [01:33<00:00,  8.41it/s, Loss=5.16e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait : 0.52\n",
      "Fin Epoch 2 | Loss: 0.0000 | BER Student: 0.52 | err_wat: 0.6934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 782/782 [01:30<00:00,  8.60it/s, Loss=3.73e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait : 0.48\n",
      "Fin Epoch 3 | Loss: 0.0001 | BER Student: 0.48 | err_wat: 0.6927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 782/782 [01:30<00:00,  8.64it/s, Loss=5.01e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait : 0.45\n",
      "Fin Epoch 4 | Loss: 0.0001 | BER Student: 0.45 | err_wat: 0.6921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 782/782 [01:30<00:00,  8.63it/s, Loss=7.07e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait : 0.41\n",
      "Fin Epoch 5 | Loss: 0.0001 | BER Student: 0.41 | err_wat: 0.6915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 782/782 [01:30<00:00,  8.62it/s, Loss=6.37e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait : 0.38\n",
      "Fin Epoch 6 | Loss: 0.0001 | BER Student: 0.38 | err_wat: 0.6910\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 782/782 [01:30<00:00,  8.63it/s, Loss=3.36e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait : 0.36\n",
      "Fin Epoch 7 | Loss: 0.0001 | BER Student: 0.36 | err_wat: 0.6904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 782/782 [01:30<00:00,  8.62it/s, Loss=3.98e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait : 0.36\n",
      "Fin Epoch 8 | Loss: 0.0001 | BER Student: 0.36 | err_wat: 0.6899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 782/782 [01:30<00:00,  8.63it/s, Loss=5.83e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait : 0.34\n",
      "Fin Epoch 9 | Loss: 0.0001 | BER Student: 0.34 | err_wat: 0.6894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 782/782 [01:30<00:00,  8.65it/s, Loss=8.22e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait : 0.31\n",
      "Fin Epoch 10 | Loss: 0.0001 | BER Student: 0.31 | err_wat: 0.6890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 782/782 [01:30<00:00,  8.63it/s, Loss=4.53e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait : 0.28\n",
      "Fin Epoch 11 | Loss: 0.0001 | BER Student: 0.28 | err_wat: 0.6885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 782/782 [01:30<00:00,  8.61it/s, Loss=4.14e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait : 0.27\n",
      "Fin Epoch 12 | Loss: 0.0001 | BER Student: 0.27 | err_wat: 0.6881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 782/782 [01:30<00:00,  8.64it/s, Loss=3.7e-5]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait : 0.27\n",
      "Fin Epoch 13 | Loss: 0.0001 | BER Student: 0.27 | err_wat: 0.6876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 782/782 [01:30<00:00,  8.63it/s, Loss=9.81e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait : 0.25\n",
      "Fin Epoch 14 | Loss: 0.0001 | BER Student: 0.25 | err_wat: 0.6871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 782/782 [01:30<00:00,  8.63it/s, Loss=4.46e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait : 0.25\n",
      "Fin Epoch 15 | Loss: 0.0001 | BER Student: 0.25 | err_wat: 0.6867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████| 782/782 [01:30<00:00,  8.65it/s, Loss=5.71e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait : 0.25\n",
      "Fin Epoch 16 | Loss: 0.0001 | BER Student: 0.25 | err_wat: 0.6863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████| 782/782 [01:30<00:00,  8.63it/s, Loss=5.53e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait : 0.20\n",
      "Fin Epoch 17 | Loss: 0.0001 | BER Student: 0.20 | err_wat: 0.6858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████| 782/782 [01:30<00:00,  8.64it/s, Loss=2.82e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait : 0.19\n",
      "Fin Epoch 18 | Loss: 0.0001 | BER Student: 0.19 | err_wat: 0.6855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 782/782 [01:30<00:00,  8.62it/s, Loss=7.86e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait : 0.17\n",
      "Fin Epoch 19 | Loss: 0.0001 | BER Student: 0.17 | err_wat: 0.6851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|██████████| 782/782 [01:30<00:00,  8.64it/s, Loss=6.65e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait : 0.17\n",
      "Fin Epoch 20 | Loss: 0.0001 | BER Student: 0.17 | err_wat: 0.6847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|██████████| 782/782 [01:30<00:00,  8.63it/s, Loss=7.29e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait : 0.14\n",
      "Fin Epoch 21 | Loss: 0.0001 | BER Student: 0.14 | err_wat: 0.6843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22: 100%|██████████| 782/782 [01:30<00:00,  8.64it/s, Loss=4.08e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait : 0.14\n",
      "Fin Epoch 22 | Loss: 0.0001 | BER Student: 0.14 | err_wat: 0.6839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23: 100%|██████████| 782/782 [01:30<00:00,  8.62it/s, Loss=5.48e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait : 0.14\n",
      "Fin Epoch 23 | Loss: 0.0001 | BER Student: 0.14 | err_wat: 0.6835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 782/782 [01:30<00:00,  8.62it/s, Loss=7.53e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait : 0.12\n",
      "Fin Epoch 24 | Loss: 0.0001 | BER Student: 0.12 | err_wat: 0.6831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25: 100%|██████████| 782/782 [01:30<00:00,  8.62it/s, Loss=4.89e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait : 0.11\n",
      "Fin Epoch 25 | Loss: 0.0001 | BER Student: 0.11 | err_wat: 0.6828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26: 100%|██████████| 782/782 [01:30<00:00,  8.61it/s, Loss=2.99e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait : 0.09\n",
      "Fin Epoch 26 | Loss: 0.0001 | BER Student: 0.09 | err_wat: 0.6824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27: 100%|██████████| 782/782 [01:30<00:00,  8.63it/s, Loss=9.03e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait : 0.09\n",
      "Fin Epoch 27 | Loss: 0.0001 | BER Student: 0.09 | err_wat: 0.6821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28: 100%|██████████| 782/782 [01:31<00:00,  8.59it/s, Loss=6.92e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait : 0.09\n",
      "Fin Epoch 28 | Loss: 0.0001 | BER Student: 0.09 | err_wat: 0.6817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 782/782 [01:30<00:00,  8.60it/s, Loss=9.2e-5]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait : 0.09\n",
      "Fin Epoch 29 | Loss: 0.0001 | BER Student: 0.09 | err_wat: 0.6814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30: 100%|██████████| 782/782 [01:30<00:00,  8.62it/s, Loss=1.93e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait : 0.09\n",
      "Fin Epoch 30 | Loss: 0.0001 | BER Student: 0.09 | err_wat: 0.6810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31: 100%|██████████| 782/782 [01:30<00:00,  8.60it/s, Loss=4.6e-5]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait : 0.09\n",
      "Fin Epoch 31 | Loss: 0.0001 | BER Student: 0.09 | err_wat: 0.6807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32: 100%|██████████| 782/782 [01:30<00:00,  8.60it/s, Loss=3.12e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait : 0.08\n",
      "Fin Epoch 32 | Loss: 0.0001 | BER Student: 0.08 | err_wat: 0.6803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33: 100%|██████████| 782/782 [01:30<00:00,  8.62it/s, Loss=0.000119]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait : 0.08\n",
      "Fin Epoch 33 | Loss: 0.0001 | BER Student: 0.08 | err_wat: 0.6800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 782/782 [01:30<00:00,  8.62it/s, Loss=3.06e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait : 0.08\n",
      "Fin Epoch 34 | Loss: 0.0001 | BER Student: 0.08 | err_wat: 0.6797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35: 100%|██████████| 782/782 [01:32<00:00,  8.49it/s, Loss=1.37e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait : 0.06\n",
      "Fin Epoch 35 | Loss: 0.0001 | BER Student: 0.06 | err_wat: 0.6794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36: 100%|██████████| 782/782 [01:27<00:00,  8.89it/s, Loss=2.62e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER Extrait : 0.06\n",
      "Fin Epoch 36 | Loss: 0.0001 | BER Student: 0.06 | err_wat: 0.6791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37:  54%|█████▍    | 426/782 [00:48<00:40,  8.82it/s, Loss=6.48e-5] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[5]\u001B[39m\u001B[32m, line 2\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;66;03m# 4. Attaque par Distillation\u001B[39;00m\n\u001B[32m----> \u001B[39m\u001B[32m2\u001B[39m student_res, stats = \u001B[43mrun_distillation_attack_stdm\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstdm_defense\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdataloader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m100\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[4]\u001B[39m\u001B[32m, line 59\u001B[39m, in \u001B[36mrun_distillation_attack_stdm\u001B[39m\u001B[34m(stdm_obj, dataloader, epochs, lr)\u001B[39m\n\u001B[32m     56\u001B[39m     loss.backward()\n\u001B[32m     57\u001B[39m     optimizer.step()\n\u001B[32m---> \u001B[39m\u001B[32m59\u001B[39m     running_loss += \u001B[43mloss\u001B[49m\u001B[43m.\u001B[49m\u001B[43mitem\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     60\u001B[39m     pbar.set_postfix(Loss=loss.item())\n\u001B[32m     62\u001B[39m \u001B[38;5;66;03m# C. Verification : Est-ce que les poids se sont alignes sur STDM ?\u001B[39;00m\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "plot_results_cell",
   "metadata": {},
   "source": [
    "# 5. Visualisation des resultats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "ax1.plot(stats[\"loss\"])\n",
    "ax1.set_xlabel(\"Epoch\")\n",
    "ax1.set_ylabel(\"Loss\")\n",
    "ax1.set_title(\"Distillation Loss\")\n",
    "\n",
    "ax2.plot(stats[\"ber\"])\n",
    "ax2.axhline(y=0.5, color='r', linestyle='--', label='Random (0.5)')\n",
    "ax2.set_xlabel(\"Epoch\")\n",
    "ax2.set_ylabel(\"BER\")\n",
    "ax2.set_title(\"BER Evolution During Distillation\")\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
