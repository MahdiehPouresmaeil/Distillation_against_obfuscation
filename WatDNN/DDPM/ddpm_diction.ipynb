{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-01-27T16:16:29.583332748Z",
     "start_time": "2026-01-27T16:16:29.523366906Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from diffusers import DDPMPipeline, DDPMScheduler\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "\n",
    "# --- 1. Classes Utilitaires (Hooks & Projection) ---\n",
    "\n",
    "class FeatureHook:\n",
    "    \"\"\"Intercepte les activations d'une couche sp√©cifique.\"\"\"\n",
    "    def __init__(self, module):\n",
    "        self.hook = module.register_forward_hook(self.hook_fn)\n",
    "        self.features = None\n",
    "\n",
    "    def hook_fn(self, module, input, output):\n",
    "        self.features = output\n",
    "\n",
    "    def close(self):\n",
    "        self.hook.remove()\n",
    "\n",
    "class ProjectionNet(nn.Module):\n",
    "    \"\"\"\n",
    "    R√©seau l√©ger qui projette les features vers l'espace du watermark.\n",
    "    Structure: GAP -> Linear -> ReLU -> Linear -> Sigmoid\n",
    "    \"\"\"\n",
    "    def __init__(self, input_channels, watermark_len):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(input_channels, 256),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(256, watermark_len),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [Batch, Channels, H, W]\n",
    "        # Global Average Pooling pour r√©duire la dimension spatiale\n",
    "        if len(x.shape) == 4:\n",
    "            x = x.mean(dim=[2, 3])\n",
    "        return self.net(x)\n",
    "\n",
    "# --- 2. Classe Principale DICTION ---\n",
    "\n",
    "class DictionDDPM:\n",
    "    def __init__(self, model_id, device=\"cuda\"):\n",
    "        self.device = device\n",
    "        self.model_id = model_id\n",
    "\n",
    "        # Chargement du mod√®le\n",
    "        self.pipeline = DDPMPipeline.from_pretrained(model_id)\n",
    "        self.unet = self.pipeline.unet.to(device)\n",
    "        self.scheduler = self.pipeline.scheduler\n",
    "\n",
    "        # Configuration par d√©faut\n",
    "        self.config = {\n",
    "            \"layer_name\": \"mid_block.resnets.1.conv2\", # Couche cible\n",
    "            \"watermark_len\": 64,\n",
    "            \"trigger_size\": 32, # Nombre d'images dans le trigger set\n",
    "            \"lr\": 1e-4,\n",
    "            \"lambda_wat\": 1.0,\n",
    "            \"epochs\": 5\n",
    "        }\n",
    "\n",
    "    def _get_target_layer(self, model, layer_name):\n",
    "        \"\"\"R√©cup√®re le module PyTorch correspondant au nom.\"\"\"\n",
    "        for name, module in model.named_modules():\n",
    "            if name == layer_name:\n",
    "                return module\n",
    "        raise ValueError(f\"Couche {layer_name} introuvable.\")\n",
    "\n",
    "    def generate_trigger_set(self):\n",
    "        \"\"\"\n",
    "        G√©n√®re un Trigger Set persistant (bruit + timesteps fixes).\n",
    "        C'est ce qui servira d'entr√©e pour activer la marque.\n",
    "        \"\"\"\n",
    "        # shape = (self.config[\"trigger_size\"], 3, 32, 32) # CIFAR-10 shape\n",
    "        shape=(self.config[\"trigger_size\"],3,256,256) # CelebA-HQ shape\n",
    "\n",
    "        # Bruit fixe\n",
    "        trigger_noise = torch.randn(shape).to(self.device)\n",
    "\n",
    "        # Timesteps fixes (choisis al√©atoirement une fois)\n",
    "        trigger_timesteps = torch.randint(\n",
    "            0, self.scheduler.config.num_train_timesteps,\n",
    "            (self.config[\"trigger_size\"],),\n",
    "            device=self.device\n",
    "        ).long()\n",
    "\n",
    "        return trigger_noise, trigger_timesteps\n",
    "\n",
    "    def embed(self, dataloader):\n",
    "        \"\"\"\n",
    "        Entra√Æne le mod√®le tatou√© et le r√©seau de projection.\n",
    "        Objectif :\n",
    "          - Features Original -> Random Watermark\n",
    "          - Features Tatou√© -> Target Watermark\n",
    "        \"\"\"\n",
    "        print(f\"--- D√©marrage Embedding DICTION ({self.config['layer_name']}) ---\")\n",
    "\n",
    "        # 1. Pr√©paration des Mod√®les\n",
    "        original_unet = deepcopy(self.unet)\n",
    "        original_unet.eval() # Le mod√®le original est gel√© (r√©f√©rence)\n",
    "        for p in original_unet.parameters(): p.requires_grad = False\n",
    "\n",
    "        watermarked_unet = self.unet\n",
    "        watermarked_unet.train()\n",
    "\n",
    "        # 2. G√©n√©ration des Cl√©s & Trigger Set\n",
    "        trigger_noise, trigger_timesteps = self.generate_trigger_set()\n",
    "\n",
    "        target_wm = torch.randint(0, 2, (self.config[\"watermark_len\"],)).float().to(self.device)\n",
    "        random_wm = torch.randint(0, 2, (self.config[\"watermark_len\"],)).float().to(self.device)\n",
    "\n",
    "        # 3. Initialisation ProjNet (Dimension dynamique)\n",
    "        # On fait un dummy pass pour avoir la taille des features\n",
    "        dummy_layer = self._get_target_layer(watermarked_unet, self.config[\"layer_name\"])\n",
    "        dummy_hook = FeatureHook(dummy_layer)\n",
    "        with torch.no_grad():\n",
    "            _ = watermarked_unet(trigger_noise[:1], trigger_timesteps[:1]).sample\n",
    "        input_channels = dummy_hook.features.shape[1]\n",
    "        dummy_hook.close()\n",
    "\n",
    "        proj_net = ProjectionNet(input_channels, self.config[\"watermark_len\"]).to(self.device)\n",
    "        proj_net.train()\n",
    "\n",
    "        # 4. Optimiseur (Entra√Æne UNet + ProjNet)\n",
    "        optimizer = torch.optim.AdamW(\n",
    "            list(watermarked_unet.parameters()) + list(proj_net.parameters()),\n",
    "            lr=self.config[\"lr\"]\n",
    "        )\n",
    "\n",
    "        mse_loss = nn.MSELoss()\n",
    "        bce_loss = nn.BCELoss()\n",
    "\n",
    "        # --- BOUCLE D'ENTRA√éNEMENT ---\n",
    "        for epoch in range(self.config[\"epochs\"]):\n",
    "            pbar = tqdm(dataloader)\n",
    "            for clean_images, _ in pbar:\n",
    "                clean_images = clean_images.to(self.device)\n",
    "                bs = clean_images.shape[0]\n",
    "\n",
    "                # A. T√¢che Principale (Fidelity) sur Batch al√©atoire\n",
    "                noise = torch.randn_like(clean_images).to(self.device)\n",
    "                timesteps = torch.randint(0, self.scheduler.config.num_train_timesteps, (bs,), device=self.device).long()\n",
    "                noisy_images = self.scheduler.add_noise(clean_images, noise, timesteps)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                noise_pred = watermarked_unet(noisy_images, timesteps).sample\n",
    "                l_main = mse_loss(noise_pred, noise)\n",
    "\n",
    "                # B. T√¢che DICTION (Sur Trigger Set)\n",
    "\n",
    "                # 1. Extraire features ORIGINALES (Clean -> Random)\n",
    "                orig_layer = self._get_target_layer(original_unet, self.config[\"layer_name\"])\n",
    "                hook_orig = FeatureHook(orig_layer)\n",
    "                with torch.no_grad():\n",
    "                    _ = original_unet(trigger_noise, trigger_timesteps).sample\n",
    "                feat_orig = hook_orig.features\n",
    "                hook_orig.close()\n",
    "\n",
    "                # 2. Extraire features TATOU√âES (Watermarked -> Target)\n",
    "                wat_layer = self._get_target_layer(watermarked_unet, self.config[\"layer_name\"])\n",
    "                hook_wat = FeatureHook(wat_layer)\n",
    "                # Important: On garde le gradient ici !\n",
    "                _ = watermarked_unet(trigger_noise, trigger_timesteps).sample\n",
    "                feat_wat = hook_wat.features\n",
    "                hook_wat.close()\n",
    "\n",
    "                # 3. Projection & Loss\n",
    "                # Le ProjNet doit apprendre √† mapper Orig -> Random\n",
    "                pred_orig = proj_net(feat_orig.detach()) # Detach car on ne touche pas √† l'original\n",
    "                l_proj_clean = bce_loss(pred_orig.mean(dim=0), random_wm)\n",
    "\n",
    "                # Le ProjNet ET le UNet doivent apprendre Wat -> Target\n",
    "                pred_wat = proj_net(feat_wat)\n",
    "                l_proj_wat = bce_loss(pred_wat.mean(dim=0), target_wm)\n",
    "\n",
    "                # Loss Totale\n",
    "                l_wat = l_proj_clean + l_proj_wat\n",
    "                l_total = l_main + self.config[\"lambda_wat\"] * l_wat\n",
    "\n",
    "                l_total.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                # Metrics\n",
    "                ber = self._compute_ber(pred_wat.mean(dim=0), target_wm)\n",
    "                pbar.set_description(f\"L_Main: {l_main:.3f} | L_Wat: {l_wat:.3f} | BER: {ber:.2f}\")\n",
    "\n",
    "                # if ber == 0.0 and l_wat.item() < 0.05:\n",
    "                #     print(\"‚úÖ Convergence atteinte !\")\n",
    "                #     break\n",
    "            # if ber == 0.0: break\n",
    "\n",
    "        # Sauvegarde des √©l√©ments n√©cessaires pour l'extraction\n",
    "        self.saved_keys = {\n",
    "            \"trigger_noise\": trigger_noise,\n",
    "            \"trigger_timesteps\": trigger_timesteps,\n",
    "            \"target_wm\": target_wm,\n",
    "            \"proj_net\": proj_net,\n",
    "            \"watermarked_unet\": watermarked_unet,\n",
    "            \"original_unet\": original_unet,\n",
    "        }\n",
    "        return watermarked_unet\n",
    "\n",
    "    def extract(self, suspect_unet=None):\n",
    "        \"\"\"\n",
    "        Extrait la marque d'un mod√®le suspect en utilisant les cl√©s sauvegard√©es.\n",
    "        \"\"\"\n",
    "        if suspect_unet is None:\n",
    "            suspect_unet = self.saved_keys[\"watermarked_unet\"]\n",
    "\n",
    "        print(\"--- Extraction de la marque ---\")\n",
    "        suspect_unet.eval()\n",
    "        proj_net = self.saved_keys[\"proj_net\"]\n",
    "        proj_net.eval()\n",
    "\n",
    "        trigger_noise = self.saved_keys[\"trigger_noise\"]\n",
    "        trigger_timesteps = self.saved_keys[\"trigger_timesteps\"]\n",
    "        target_wm = self.saved_keys[\"target_wm\"]\n",
    "\n",
    "        # 1. Hook sur le mod√®le suspect\n",
    "        target_layer = self._get_target_layer(suspect_unet, self.config[\"layer_name\"])\n",
    "        hook = FeatureHook(target_layer)\n",
    "\n",
    "        # 2. Passage du Trigger Set\n",
    "        with torch.no_grad():\n",
    "            _ = suspect_unet(trigger_noise, trigger_timesteps).sample\n",
    "\n",
    "        features = hook.features\n",
    "        hook.close()\n",
    "\n",
    "        # 3. Projection & BER\n",
    "        wm_pred = proj_net(features).mean(dim=0)\n",
    "        ber = self._compute_ber(wm_pred, target_wm)\n",
    "\n",
    "        print(f\"BER Extrait : {ber:.2f}\")\n",
    "        return ber, wm_pred\n",
    "\n",
    "    @staticmethod\n",
    "    def _compute_ber(pred, target):\n",
    "        return ((pred > 0.5).float() != target).float().mean().item()\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-27T16:24:50.588609984Z",
     "start_time": "2026-01-27T16:16:36.107741171Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- EXEMPLE D'UTILISATION ---\n",
    "\n",
    "# 1. Data Loader\n",
    "# transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "# dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "# dataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "import torch\n",
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# Load from Hugging Face (no Google Drive issues)\n",
    "print(\"Loading dataset...\")\n",
    "hf_dataset = load_dataset(\"nielsr/CelebA-faces\", split=\"train\")\n",
    "\n",
    "class CelebAWrapper(torch.utils.data.Dataset):\n",
    "    def __init__(self, hf_dataset, transform):\n",
    "        self.dataset = hf_dataset\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.dataset[idx]['image']\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, 0\n",
    "\n",
    "dataset = CelebAWrapper(hf_dataset, transform)\n",
    "print(\"Dataset loaded!\")\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=8, shuffle=True)\n",
    "print(\"loader loaded!\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 2. Instanciation & Embedding\n",
    "# diction = DictionDDPM(\"google/ddpm-cifar10-32\")\n",
    "diction= DictionDDPM(\"google/ddpm-celebahq-256\")\n",
    "\n",
    "# Embed (Retourne le mod√®le tatou√©)\n",
    "watermarked_model = diction.embed(dataloader)\n",
    "\n",
    "# 3. Extraction (Test imm√©diat)\n",
    "ber, _ = diction.extract(watermarked_model)"
   ],
   "id": "df3aef93902dd9bd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/2 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1329b7b6e9c74c57848e089d034a548d"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "An error occurred while trying to fetch /home/carbure/.cache/huggingface/hub/models--google--ddpm-cifar10-32/snapshots/267b167dc01f0e4e61923ea244e8b988f84deb80: Error no file named diffusion_pytorch_model.safetensors found in directory /home/carbure/.cache/huggingface/hub/models--google--ddpm-cifar10-32/snapshots/267b167dc01f0e4e61923ea244e8b988f84deb80.\n",
      "Defaulting to unsafe serialization. Pass `allow_pickle=False` to raise an error instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- D√©marrage Embedding DICTION (mid_block.resnets.1.conv2) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "L_Main: 0.006 | L_Wat: 0.029 | BER: 0.00: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:38<00:00,  7.90it/s]\n",
      "L_Main: 0.012 | L_Wat: 0.009 | BER: 0.00: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:36<00:00,  8.11it/s]\n",
      "L_Main: 0.027 | L_Wat: 0.004 | BER: 0.00: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:40<00:00,  7.79it/s]\n",
      "L_Main: 0.029 | L_Wat: 0.002 | BER: 0.00: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:39<00:00,  7.88it/s]\n",
      "L_Main: 0.018 | L_Wat: 0.001 | BER: 0.00: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:38<00:00,  7.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Extraction de la marque ---\n",
      "BER Extrait : 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-27T16:49:18.928516793Z",
     "start_time": "2026-01-27T16:49:18.878728117Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from diffusers import UNet2DModel, DDPMScheduler\n",
    "from torch.optim import AdamW\n",
    "from tqdm import tqdm\n",
    "\n",
    "def run_distillation_attack(diction_obj, dataloader, epochs=5, lr=1e-4):\n",
    "    \"\"\"\n",
    "    Lance une distillation Black-Box (Output only) du Teacher tatou√© vers un Student vierge.\n",
    "    Monitore le BER (err_wat) √† chaque √©poque.\n",
    "    \"\"\"\n",
    "    device = diction_obj.device\n",
    "\n",
    "    # --- 1. R√©cup√©ration du Teacher (Gel√©) ---\n",
    "    teacher_unet = diction_obj.saved_keys[\"watermarked_unet\"]\n",
    "    # teacher_pipeline = DDPMPipeline.from_pretrained(\"google/ddpm-cifar10-32\")\n",
    "    # teacher_pipeline = DDPMPipeline.from_pretrained(\"google/ddpm-celebahq-256\")\n",
    "    # teacher_unet = teacher_pipeline.unet.to(device)\n",
    "\n",
    "    teacher_unet.eval()\n",
    "    for p in teacher_unet.parameters(): p.requires_grad = False\n",
    "\n",
    "    # --- 2. Initialisation du Student (Vierge) ---\n",
    "    print(\"\\n--- Initialisation du Student ---\")\n",
    "    # On cr√©e un mod√®le avec la m√™me config mais des poids al√©atoires\n",
    "    # student_unet = UNet2DModel.from_config(teacher_unet.config).to(device)\n",
    "    # student_pipeline = DDPMPipeline.from_pretrained(\"google/ddpm-cifar10-32\")\n",
    "    student_pipeline=DDPMPipeline.from_pretrained(\"google/ddpm-celebahq-256\")\n",
    "    student_unet = student_pipeline.unet.to(device)\n",
    "    student_unet.train()\n",
    "\n",
    "    # --- 3. V√©rifications Avant Distillation (Sanity Checks) ---\n",
    "    print(\"\\n[Check 1] V√©rification du Teacher (Doit √™tre ~0.0)\")\n",
    "    ber_teacher, _ = diction_obj.extract(teacher_unet)\n",
    "    if ber_teacher > 0.05:\n",
    "        print(f\"‚ö†Ô∏è ATTENTION : Le Teacher n'est pas bien tatou√© (BER={ber_teacher:.2f})\")\n",
    "    else:\n",
    "        print(f\"‚úÖ Teacher OK (BER={ber_teacher:.2f})\")\n",
    "\n",
    "    print(\"\\n[Check 2] V√©rification du Student (Doit √™tre ~0.5 - Al√©atoire)\")\n",
    "    ber_student_start, _ = diction_obj.extract(student_unet)\n",
    "    print(f\"‚ÑπÔ∏è Student avant distillation : BER={ber_student_start:.2f} (Normal pour un mod√®le vierge)\")\n",
    "\n",
    "    # --- 4. Configuration Distillation ---\n",
    "    optimizer = AdamW(student_unet.parameters(), lr=lr)\n",
    "    # Scheduler pour g√©n√©rer le bruit d'entra√Ænement\n",
    "    noise_scheduler = diction_obj.scheduler\n",
    "\n",
    "    history = {\"loss\": [], \"ber\": []}\n",
    "\n",
    "    print(f\"\\n--- D√©marrage de la Distillation ({epochs} epochs) ---\")\n",
    "    a=0\n",
    "    for epoch in range(epochs):\n",
    "        pbar = tqdm(dataloader, desc=f\"Epoch {epoch+1}/{epochs}\")\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for clean_images, _ in pbar:\n",
    "            clean_images = clean_images.to(device)\n",
    "            bs = clean_images.shape[0]\n",
    "\n",
    "            # A. G√©n√©ration d'entr√©e (Bruit al√©atoire, PAS le trigger set)\n",
    "            noise = torch.randn_like(clean_images).to(device)\n",
    "            timesteps = torch.randint(0, noise_scheduler.config.num_train_timesteps, (bs,), device=device).long()\n",
    "            noisy_images = noise_scheduler.add_noise(clean_images, noise, timesteps)\n",
    "\n",
    "            # B. Teacher Prediction (Cible) - BLACK BOX (Juste la sortie)\n",
    "            with torch.no_grad():\n",
    "                target_pred = teacher_unet(noisy_images, timesteps).sample\n",
    "\n",
    "            # C. Student Prediction\n",
    "            student_pred = student_unet(noisy_images, timesteps).sample\n",
    "\n",
    "            # D. Loss (MSE pure sur les sorties)\n",
    "            loss = F.mse_loss(student_pred, target_pred)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            pbar.set_postfix(Loss_Distill=loss.item())\n",
    "\n",
    "        # --- E. V√©rification du Transfert de Marque (err_wat) ---\n",
    "        # On utilise la m√©thode extract de diction sur le student actuel\n",
    "        # Elle utilise le Trigger Set et le ProjNet du Teacher (les cl√©s)\n",
    "        print(f\"\\nCalcul du BER (err_wat) pour l'√©poque {epoch+1}...\")\n",
    "        current_ber, wat_ext = diction_obj.extract(student_unet)\n",
    "\n",
    "        history[\"loss\"].append(running_loss / len(dataloader))\n",
    "        history[\"ber\"].append(current_ber)\n",
    "\n",
    "        print(f\"üëâ Fin Epoch {epoch+1} | Loss: {history['loss'][-1]:.4f} | BER Student: {current_ber:.2f} | ext_wat: {nn.BCELoss()(wat_ext, diction_obj.saved_keys['target_wm']).item():.4f}\")\n",
    "\n",
    "        # Condition de succ√®s total (Si le student a parfaitement copi√© la marque)\n",
    "        if current_ber==0.0 and a>=1:\n",
    "            print(\"‚úÖ Marque r√©cup√©r√©e avec succ√®s par distillation !\")\n",
    "            break\n",
    "        elif current_ber==0.0 and a<1 :\n",
    "            a+=1\n",
    "        else:\n",
    "            a=0\n",
    "    return student_unet, history\n",
    "\n"
   ],
   "id": "70c52864caa30280",
   "outputs": [],
   "execution_count": 57
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-27T17:07:51.699589900Z",
     "start_time": "2026-01-27T16:49:22.950307372Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- Lancement du test ---\n",
    "# diction est l'objet cr√©√© dans l'√©tape pr√©c√©dente\n",
    "# dataloader est votre chargeur CIFAR-10\n",
    "\n",
    "student_distilled, stats = run_distillation_attack(diction, dataloader, epochs=1000)"
   ],
   "id": "73ffea1114591cca",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/2 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "be6c4e61fd2340bea5963bd974f1fd97"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "An error occurred while trying to fetch /home/carbure/.cache/huggingface/hub/models--google--ddpm-cifar10-32/snapshots/267b167dc01f0e4e61923ea244e8b988f84deb80: Error no file named diffusion_pytorch_model.safetensors found in directory /home/carbure/.cache/huggingface/hub/models--google--ddpm-cifar10-32/snapshots/267b167dc01f0e4e61923ea244e8b988f84deb80.\n",
      "Defaulting to unsafe serialization. Pass `allow_pickle=False` to raise an error instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Initialisation du Student ---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/2 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6668577e720f4c9b973fa1d8f1340444"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "An error occurred while trying to fetch /home/carbure/.cache/huggingface/hub/models--google--ddpm-cifar10-32/snapshots/267b167dc01f0e4e61923ea244e8b988f84deb80: Error no file named diffusion_pytorch_model.safetensors found in directory /home/carbure/.cache/huggingface/hub/models--google--ddpm-cifar10-32/snapshots/267b167dc01f0e4e61923ea244e8b988f84deb80.\n",
      "Defaulting to unsafe serialization. Pass `allow_pickle=False` to raise an error instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Check 1] V√©rification du Teacher (Doit √™tre ~0.0)\n",
      "--- Extraction de la marque ---\n",
      "BER Extrait : 0.58\n",
      "‚ö†Ô∏è ATTENTION : Le Teacher n'est pas bien tatou√© (BER=0.58)\n",
      "\n",
      "[Check 2] V√©rification du Student (Doit √™tre ~0.5 - Al√©atoire)\n",
      "--- Extraction de la marque ---\n",
      "BER Extrait : 0.58\n",
      "‚ÑπÔ∏è Student avant distillation : BER=0.58 (Normal pour un mod√®le vierge)\n",
      "\n",
      "--- D√©marrage de la Distillation (100 epochs) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/100: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:32<00:00,  8.43it/s, Loss_Distill=2.87e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calcul du BER (err_wat) pour l'√©poque 1...\n",
      "--- Extraction de la marque ---\n",
      "BER Extrait : 0.58\n",
      "üëâ Fin Epoch 1 | Loss: 0.0000 | BER Student: 0.58 | ext_wat: 4.2408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/100: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:30<00:00,  8.64it/s, Loss_Distill=3.56e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calcul du BER (err_wat) pour l'√©poque 2...\n",
      "--- Extraction de la marque ---\n",
      "BER Extrait : 0.58\n",
      "üëâ Fin Epoch 2 | Loss: 0.0000 | BER Student: 0.58 | ext_wat: 4.2371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/100: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:30<00:00,  8.69it/s, Loss_Distill=8.21e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calcul du BER (err_wat) pour l'√©poque 3...\n",
      "--- Extraction de la marque ---\n",
      "BER Extrait : 0.58\n",
      "üëâ Fin Epoch 3 | Loss: 0.0000 | BER Student: 0.58 | ext_wat: 4.2333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/100: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:30<00:00,  8.67it/s, Loss_Distill=2.49e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calcul du BER (err_wat) pour l'√©poque 4...\n",
      "--- Extraction de la marque ---\n",
      "BER Extrait : 0.58\n",
      "üëâ Fin Epoch 4 | Loss: 0.0000 | BER Student: 0.58 | ext_wat: 4.2335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/100: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:30<00:00,  8.60it/s, Loss_Distill=4.07e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calcul du BER (err_wat) pour l'√©poque 5...\n",
      "--- Extraction de la marque ---\n",
      "BER Extrait : 0.58\n",
      "üëâ Fin Epoch 5 | Loss: 0.0000 | BER Student: 0.58 | ext_wat: 4.2363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/100: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:27<00:00,  8.97it/s, Loss_Distill=1.89e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calcul du BER (err_wat) pour l'√©poque 6...\n",
      "--- Extraction de la marque ---\n",
      "BER Extrait : 0.58\n",
      "üëâ Fin Epoch 6 | Loss: 0.0000 | BER Student: 0.58 | ext_wat: 4.2340\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/100: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:27<00:00,  8.89it/s, Loss_Distill=3.35e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calcul du BER (err_wat) pour l'√©poque 7...\n",
      "--- Extraction de la marque ---\n",
      "BER Extrait : 0.58\n",
      "üëâ Fin Epoch 7 | Loss: 0.0000 | BER Student: 0.58 | ext_wat: 4.2321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/100: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:26<00:00,  9.05it/s, Loss_Distill=2.23e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calcul du BER (err_wat) pour l'√©poque 8...\n",
      "--- Extraction de la marque ---\n",
      "BER Extrait : 0.58\n",
      "üëâ Fin Epoch 8 | Loss: 0.0000 | BER Student: 0.58 | ext_wat: 4.2325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/100: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:25<00:00,  9.13it/s, Loss_Distill=1.4e-5]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calcul du BER (err_wat) pour l'√©poque 9...\n",
      "--- Extraction de la marque ---\n",
      "BER Extrait : 0.58\n",
      "üëâ Fin Epoch 9 | Loss: 0.0000 | BER Student: 0.58 | ext_wat: 4.2295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/100: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:30<00:00,  8.60it/s, Loss_Distill=3.2e-5]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calcul du BER (err_wat) pour l'√©poque 10...\n",
      "--- Extraction de la marque ---\n",
      "BER Extrait : 0.58\n",
      "üëâ Fin Epoch 10 | Loss: 0.0001 | BER Student: 0.58 | ext_wat: 4.2298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/100: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:20<00:00,  9.67it/s, Loss_Distill=5.72e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calcul du BER (err_wat) pour l'√©poque 11...\n",
      "--- Extraction de la marque ---\n",
      "BER Extrait : 0.58\n",
      "üëâ Fin Epoch 11 | Loss: 0.0001 | BER Student: 0.58 | ext_wat: 4.2341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/100: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:29<00:00,  8.72it/s, Loss_Distill=5.15e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calcul du BER (err_wat) pour l'√©poque 12...\n",
      "--- Extraction de la marque ---\n",
      "BER Extrait : 0.58\n",
      "üëâ Fin Epoch 12 | Loss: 0.0001 | BER Student: 0.58 | ext_wat: 4.2354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/100:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 375/782 [00:44<00:48,  8.43it/s, Loss_Distill=4.42e-5] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[58]\u001B[39m\u001B[32m, line 5\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;66;03m# --- Lancement du test ---\u001B[39;00m\n\u001B[32m      2\u001B[39m \u001B[38;5;66;03m# diction est l'objet cr√©√© dans l'√©tape pr√©c√©dente\u001B[39;00m\n\u001B[32m      3\u001B[39m \u001B[38;5;66;03m# dataloader est votre chargeur CIFAR-10\u001B[39;00m\n\u001B[32m----> \u001B[39m\u001B[32m5\u001B[39m student_distilled, stats = \u001B[43mrun_distillation_attack\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdiction\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdataloader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m100\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[57]\u001B[39m\u001B[32m, line 74\u001B[39m, in \u001B[36mrun_distillation_attack\u001B[39m\u001B[34m(diction_obj, dataloader, epochs, lr)\u001B[39m\n\u001B[32m     71\u001B[39m loss = F.mse_loss(student_pred, target_pred)\n\u001B[32m     73\u001B[39m optimizer.zero_grad()\n\u001B[32m---> \u001B[39m\u001B[32m74\u001B[39m \u001B[43mloss\u001B[49m\u001B[43m.\u001B[49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     75\u001B[39m optimizer.step()\n\u001B[32m     77\u001B[39m running_loss += loss.item()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/diction2/.venv/lib/python3.12/site-packages/torch/_tensor.py:525\u001B[39m, in \u001B[36mTensor.backward\u001B[39m\u001B[34m(self, gradient, retain_graph, create_graph, inputs)\u001B[39m\n\u001B[32m    515\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[32m    516\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[32m    517\u001B[39m         Tensor.backward,\n\u001B[32m    518\u001B[39m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[32m   (...)\u001B[39m\u001B[32m    523\u001B[39m         inputs=inputs,\n\u001B[32m    524\u001B[39m     )\n\u001B[32m--> \u001B[39m\u001B[32m525\u001B[39m \u001B[43mtorch\u001B[49m\u001B[43m.\u001B[49m\u001B[43mautograd\u001B[49m\u001B[43m.\u001B[49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    526\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m=\u001B[49m\u001B[43minputs\u001B[49m\n\u001B[32m    527\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/diction2/.venv/lib/python3.12/site-packages/torch/autograd/__init__.py:267\u001B[39m, in \u001B[36mbackward\u001B[39m\u001B[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[39m\n\u001B[32m    262\u001B[39m     retain_graph = create_graph\n\u001B[32m    264\u001B[39m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[32m    265\u001B[39m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[32m    266\u001B[39m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m267\u001B[39m \u001B[43m_engine_run_backward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    268\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    269\u001B[39m \u001B[43m    \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    270\u001B[39m \u001B[43m    \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    271\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    272\u001B[39m \u001B[43m    \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    273\u001B[39m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    274\u001B[39m \u001B[43m    \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    275\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/diction2/.venv/lib/python3.12/site-packages/torch/autograd/graph.py:744\u001B[39m, in \u001B[36m_engine_run_backward\u001B[39m\u001B[34m(t_outputs, *args, **kwargs)\u001B[39m\n\u001B[32m    742\u001B[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001B[32m    743\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m744\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mVariable\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_execution_engine\u001B[49m\u001B[43m.\u001B[49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[32m    745\u001B[39m \u001B[43m        \u001B[49m\u001B[43mt_outputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\n\u001B[32m    746\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[32m    747\u001B[39m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[32m    748\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m attach_logging_hooks:\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 58
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
